<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>欢迎来到Github pages</title>
    <url>/posts/7e926984/</url>
    <content><![CDATA[<h1 id="标题1-This-is-a-test-of-Markdown"><a href="#标题1-This-is-a-test-of-Markdown" class="headerlink" title="标题1 This is a test of Markdown"></a>标题1 This is a test of Markdown</h1><h2 id="标题2-欢迎进入-Welcome"><a href="#标题2-欢迎进入-Welcome" class="headerlink" title="标题2  欢迎进入 Welcome"></a>标题2  欢迎进入 Welcome</h2><h3 id="标题3-Markdown"><a href="#标题3-Markdown" class="headerlink" title="标题3 Markdown"></a>标题3 Markdown</h3><h4 id="标题4"><a href="#标题4" class="headerlink" title="标题4"></a>标题4</h4><span id="more"></span>
<p>这里是测试信息<code>test info</code></p>
<pre><code>test
test
code
code
codecode here
</code></pre>
<blockquote>
<p>block</p>
</blockquote>
<ol start="2">
<li><p>hello not in order</p>
</li>
<li><p>hello</p>
</li>
<li><p>hello</p>
</li>
<li><p>test</p>
</li>
<li><p>code</p>
</li>
<li><p>hello</p>
</li>
</ol>
<p><em>single asterisks</em></p>
<p><em>single underscores</em></p>
<p><strong>double asterisks</strong></p>
<p><strong>double underscores</strong></p>
<p>I get 10 times more traffic from <a href="http://google.com/" title="Google">Google</a> than from<br><a href="http://search.yahoo.com/" title="Yahoo Search">Yahoo</a> or <a href="http://search.msn.com/" title="MSN Search">MSN</a>.</p>
]]></content>
      <tags>
        <tag>study</tag>
      </tags>
  </entry>
  <entry>
    <title>Amazon EC2学习笔记</title>
    <url>/posts/11352d68/</url>
    <content><![CDATA[<div>
<div>LNMP环境的安装</div>
<div>[http://www.giroro.com/amazon-ec2-study-notes-2/](http://www.giroro.com/amazon-ec2-study-notes-2/)</div>
<div>[http://lnmp.org/install.html](http://lnmp.org/install.html)</div>
<div></div>
<div>在EC2上架设Proxy或VPN</div>
<div>[http://hi.baidu.com/cnjimmydong/item/f61622ed08e7a3325a7cfbe2](http://hi.baidu.com/cnjimmydong/item/f61622ed08e7a3325a7cfbe2)</div>
<div>[http://bleedfly.com/blog/ec2-openvpn.html](http://bleedfly.com/blog/ec2-openvpn.html)</div>
<div></div>
<div>到现在为止，Amazon EC2的使用已经暂告结束，其基本的一些使用与普通的VPS无异，但作为免费试用来说，还是要注意容易收费的小陷阱，毕竟Amazon EC2更多专注的是云计算平台，而不是普通的VPS！</div>
</div>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux下的动态链接库和so文件</title>
    <url>/posts/9582a957/</url>
    <content><![CDATA[<div>
<div>Linux下动态链接库默认后缀是so，大部分的系统的动态链接库文件在以下目录：</div>
<div>/lib  /usr/lib  /usr/local/lib</div>
<div>

<p>If you ever happen to want to link against installed libraries<br>in a given directory, LIBDIR, you must either use libtool, and<br>specify the full pathname of the library, or use the `-LLIBDIR’<br>flag during linking and do at least one of the following:</p>
<ul>
<li>add LIBDIR to the `LD_LIBRARY_PATH’ environment variable<br>during execution</li>
<li>add LIBDIR to the `LD_RUN_PATH’ environment variable<br>during linking</li>
<li>use the `-Wl,–rpath -Wl,LIBDIR’ linker flag</li>
<li>have your system administrator add LIBDIR to `/etc/ld.so.conf’ and run ldconfig</li>
</ul>
</div>
<div></div>
<div>See any operating system documentation about shared libraries for
more information, such as the ld(1) and ld.so(8) manual pages.</div>
</div>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>我的时刻</title>
    <url>/posts/389aa545/</url>
    <content><![CDATA[<p>目前为止，为这个小型的博客网站绑定了两个域名，一个是lmshlms.com，是我之前经常用的用户名，一个是wodeshike.com（我的时刻），都可以用来访问！</p>
<p>内容现在还比较少，以后再慢慢完善起来吧，敬请期待！</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>怪兽大学 Monster University</title>
    <url>/posts/569df042/</url>
    <content><![CDATA[<p>怪兽大学是今年很值得关注的一部电影，好莱坞在电影制作方面的水平确实一流，专门为怪兽大学制作了一个官方网站，这个不是介绍电影的网站，而是真正的大学网站哦！</p>
<p><a href="http://monstersuniversity.com/edu/index.html" title="怪兽大学官网">怪兽大学官网</a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>Ubuntu下安装配置LNMP--nginx+php+mysql</title>
    <url>/posts/20bd7c2c/</url>
    <content><![CDATA[<div>
<div>[http://hi.baidu.com/jipiao_tejia/item/114bcf388c15398bf4e4ad75](http://hi.baidu.com/jipiao_tejia/item/114bcf388c15398bf4e4ad75)</div>
<div></div>
<div>这里我们也可以使用LNMP一键安装包来搭建 Nginx+MySQL+PHP的环境，之后再在这个环境上面搭建包括WordPress在内的各种PHP应用。</div>
<div></div>
<div>[http://lnmp.org/install.html](http://lnmp.org/install.html)</div>
<div></div>
<div>这里的安装过程叙述很详细，一步一步来就行，我在几个机器的Ubuntu12.04的环境下都是一次成功，所以还是比较推荐的，终端下直接运行命令 sudo ./ubuntu.sh即可。安装脚本确实做的非常不错，对各种依赖包都有考虑，configure的配置也很准确，可以正确编译各种源码，对于搭建LNMP的新手来说，确实很实用。</div>
<div>对于爱学习的同学可以自行阅读理解一下各个安装的脚本文件，并以此作为进阶学习的基础。</div>
</div>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>jekyll bootstrap</title>
    <url>/posts/21153146/</url>
    <content><![CDATA[<h2 id="关于jekyll-bootstrap"><a href="#关于jekyll-bootstrap" class="headerlink" title="关于jekyll bootstrap"></a>关于jekyll bootstrap</h2><p>详细的内容参考<a href="http://jekyllbootstrap.com/usage/jekyll-quick-start.html">官方帮助文档</a></p>
<p>这里列出比较常用的命令：</p>
<pre><code>jekyll --server //在本地启动服务
rake post title=&quot;Hello World&quot; //新建一个小文章，标题为Hello World
rake page name=&quot;about.md&quot; //新建一个页面about.md
</code></pre>
<p><a href="http://octopress.org/">Octopress</a>也是很不错的一个框架，有时间可以尝试一下。</p>
]]></content>
      <tags>
        <tag>jekyll</tag>
      </tags>
  </entry>
  <entry>
    <title>制定计划-继续前行</title>
    <url>/posts/116348a/</url>
    <content><![CDATA[<h2 id="制定计划"><a href="#制定计划" class="headerlink" title="制定计划"></a>制定计划</h2><p>最近面临的问题很多，接下来要一个一个解决，直接列在下面的计划列表里面好了。</p>
<ol>
<li>小论文的选题</li>
<li>毕设论文项目的进展</li>
<li>各个网站的发展目标和一些设想</li>
<li>暑假的时间安排</li>
</ol>
<span id="more"></span>

<p>这几天的时间大部分都放在Web相关方面了，还是比较感兴趣的，学习了一些建站的内容，手里也搜集了几个域名，以后也许能用得上。也希望可以把Web的一些东西应用到毕设论文中去。</p>
<p>Github也逐渐用起来了，现在还很初步，还在学习的过程中。</p>
<p>另外，毕设项目没有什么特别的进展，Libevent的加入还是有许多困难，整体的改动还需要动很多代码，一直没敢下手，也没有特别好的思路，比较苦恼。</p>
<p>暑假也没有具体的安排，现在来看找实习基本是give up了，虽然挺不甘心的，但是时间上已经这样了，也没有办法，还是把时间安排到其他事情上去吧。</p>
]]></content>
      <categories>
        <category>Diary</category>
      </categories>
  </entry>
  <entry>
    <title>PHP扩展相关</title>
    <url>/posts/c5803951/</url>
    <content><![CDATA[<h2 id="PHP扩展的介绍"><a href="#PHP扩展的介绍" class="headerlink" title="PHP扩展的介绍"></a>PHP扩展的介绍</h2><p>下面的内容大部分搜集与网络，或来自书籍的翻译，由我加以整理而成。   </p>
<p>PHP取得成功的一个重要原因就是他拥有大量的可用扩展。Web开发者无论有何种需求，这种需求很有可能在PHP发行包里找到。PHP发行包包括支持各种数据库，图形文件格式，压缩，XML技术扩展在内的众多扩展。   </p>
<p>有两个理由需要自己编写PHP扩展。第一个理由是：PHP需要支持一项她还未支持的技术。这通常包括包裹一些现成的C函数库，以便提供PHP接口。例如，如果一个叫FooBase的数据库已推出市场，你需要建立一个PHP扩展帮助你从PHP里调用FooBase的C函数库。这个工作可能仅由一个人完成，然后被整个PHP社区共享（如果你愿意的话）。第二个不是很普遍的理由是：你需要从性能或功能的原因考虑来编写一些商业逻辑。  </p>
<span id="more"></span>
<p>在PHP中构建扩展模块，主要有以下三种方式：</p>
<ol>
<li><p>External Modules：外部模块，也就是编译成共享库，用dl()函数动态加载。</p>
<p> 好处：<br> (1)不需要重新编译整个PHP<br> (2)PHP体积小，因为不需要编译进PHP</p>
</li>
<li><p>Built-in Modules：编译进PHP  </p>
<p> 好处：<br> (1)不需要动态加载，模块在php脚本里面可以直接使用。<br> (2)不需要将模块编译成.so共享库，因为直接编译进PHP。</p>
<p> 缺点：<br> (1)对模块的每次小变动都需要重新编译整个PHP和重新部署，不适于生产环节。<br> (2)因为编译进PHP，所以PHP二进制文件较大，而且多占点内存.</p>
</li>
<li><p> The Zend Engine：Zend核心里实现（参考Zend API）  </p>
</li>
</ol>
<p>关于dl函数可以参考下面链接：<br><a href="http://www.php.net/manual/zh/function.dl.php">http://www.php.net/manual/zh/function.dl.php</a></p>
<p>可以不使用dl函数，而修改php.ini指定extension的加载，详细步骤如下：</p>
<ol>
<li><p>进入PHP源代码包的ext目录，使用扩展骨架(skeleton)构造器， 为扩展建立函数的第一步是写一个函数定义文件  test.proto，该函数定义文件定义了扩展对外提供的函数原形。该例中，定义函数只有一行函数原形</p>
<p> <code>int hello(int a, int b)  注意行后面没有分号</code></p>
</li>
<li><p>使用以下命令，生成对应的扩展目录test：</p>
<p> <code>./ext_skel --extname=test --proto=test.proto</code></p>
</li>
<li><p>进入test目录，修改其中的config.m4文件</p>
<p> <code>PHP_ARG_ENABLE(caleng_module, whether to enable test...</code><br> <code>[  --enable-test          Enable test support])</code><br> <code>两行，删除前面的dnl。</code></p>
</li>
<li><p>修改test.c中的相关函数：</p>
<p> <code>PHP_FUNCTION(hello)</code></p>
</li>
<li><p>编译和安装模块</p>
<p> <code>phpize</code><br> <code>./configure --with-php-config=/usr/local/php/bin/php-config</code><br> <code>make &amp; make install</code></p>
</li>
<li><p> 在PHP中启用扩展，修改配置文件/usr/local/php/etc/php.ini，<br>加入 extension=test.so， 然后需要重启PHP或php-fpm。<br>这里也可以通过在PHP代码中通过dl命令来调用该模块</p>
</li>
<li><p>测试扩展</p>
<p> <code>&lt;?php</code><br> <code>echo hello(1,2);</code><br> <code>phpinfo();</code><br> <code>?&gt;</code></p>
</li>
</ol>
]]></content>
      <categories>
        <category>php</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title>个人博客小网站建设中</title>
    <url>/posts/745f0b5e/</url>
    <content><![CDATA[<blockquote>
<p>This small blog website under construction</p>
</blockquote>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>WordPress-推荐插件</title>
    <url>/posts/e5cc4ce3/</url>
    <content><![CDATA[<p>WordPress用了有一段时间，感叹其插件功能的强大，对于很多新手或者像我这样对php代码不是很熟悉的人来说，确实节省了许多工作，这里简单介绍几个时下比较流行或者说个人比较推荐的插件：</p>
<h2 id="WordPress-SEO"><a href="#WordPress-SEO" class="headerlink" title="WordPress SEO"></a>WordPress SEO</h2><blockquote>
<p>The first true all-in-one SEO solution for WordPress, including on-page content analysis, XML sitemaps and much more.<br>功能很强大的SEO（<a href="http://en.wikipedia.org/wiki/Search_engine_optimization">Search engine optimization</a>），有中文化的版本，也有很方便的设置向导和引导，在发布文章时也可以进行SEO的分析，另外，内置了站点地图的功能，其他针对SEO的设置也很全面。</p>
</blockquote>
<h2 id="WP-Super-Cache"><a href="#WP-Super-Cache" class="headerlink" title="WP Super Cache"></a>WP Super Cache</h2><blockquote>
<p>Very fast caching plugin for WordPress.<br>必备插件之一。是当前最高效也是最灵活的 WordPress 静态缓存插件。它把博客的网页直接生成 静态HTML 文件，就不用解析PHP脚本，从而使得你的 WordPress 博客显著提速。</p>
</blockquote>
<p><strong>W3 Total Cache</strong></p>
<p>与WP Super Cache的功能比较类似，也是比较热门的一个插件，推荐使用。</p>
<p><strong>备份插件 <strong>BackWPup 与 <strong>UpdraftPlus - Backup/Restore</strong></strong></strong></p>
<p>正在使用后者，</p>
<p>**计数统计 **<strong>WP-PostViews</strong></p>
<p>WP-PostViews是一个文章计数统计插件，可以在文章中显示浏览数，还提供了一些统计功能，比如一定时间内浏览最多，评论最多等等，占用的系统资源也不多。</p>
<p><strong>Google XML Sitemaps</strong></p>
<p>Google站点地图生成工具。</p>
<p><strong>WP-PageNavi分页导航</strong></p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>NoSQL 数据库简介</title>
    <url>/posts/3bc6c284/</url>
    <content><![CDATA[<p>NoSQL 数据库的概念是相对于传统的关系型数据库（RDBMS-Relational Database Management System）而言，在近年来获得了极大的发展，被许多人认为是下一代的数据库。NoSQL数据库一般关注以下几点：</p>
<blockquote>
<p>being <strong>non-relational, distributed, open-source</strong> and <strong>horizontally scalable</strong></p>
<p><strong>非关系型，分布式，开源，水平伸缩性。</strong><br>在大数据和实时web应用方面，NoSQL技术已经很好的找到了自己的位置，并显示出了相对于传统关系型数据库的巨大优势。NoSQL在英文也常常被认为是“Not Only SQL”（不仅仅是SQL），用来强调NoSQL并不是SQL技术的对立面，它也允许类SQL查询语言的使用。<span id="more"></span></p>
</blockquote>
<h1 id="历史："><a href="#历史：" class="headerlink" title="历史："></a>历史：</h1><p>NoSQL一词最早是由Carlo Strozzi用来命名他开发的一个轻量级开源的关系型数据库，这个数据没有提供标准的SQL接口，所以就简单叫做NoSQL，他认为，现在的NoSQL运动，主要是不使用关系模型，应该叫做NoREL（非关系型）更为合适。</p>
<p>在2009年初，Eric Evans再次提出这个概念，那时Johan Oskarsson想组织一个会议来讨论开源的分布式数据库。这个名字用来标记那些越来越多的非关系型、分布式数据存储、并且不尝试提供ACID（原子性、一致性、隔离性和持久性）的数据库。</p>
<blockquote>
<p><strong>关系型数据库最大特点就是事务的一致性</strong>：传统的关系型数据库读写操作都是事务的，具有ACID（原子性Atomicity、一致性Consistency、隔离性Isolation、持久性Durability）的特点，C就是一致性（Consistency），这个特点是关系型数据库的灵魂（其他三个AID都是为其服务的），这个特性使得关系型数据库可以用于几乎所有对一致性有要求的系统中，如典型的银行系统。<br>自2009年初开始，NoSQL运动发展迅猛，现在已经有了大约150种NoSQL数据库，你可以在这个网站<a href="http://nosql-database.org/">http://nosql-database.org/</a>查看其中一些比较有代表性的NoSQL数据库。</p>
</blockquote>
<h1 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h1><p>大多数人比较认同的分类方法是根据其数据模型进行分类：</p>
<ul>
<li>  <strong>Column</strong>: <a href="http://en.wikipedia.org/wiki/HBase" title="HBase">HBase</a>, <a href="http://en.wikipedia.org/wiki/Accumulo" title="Accumulo">Accumulo</a></li>
<li>  <strong>Document</strong>: <a href="http://en.wikipedia.org/wiki/MongoDB" title="MongoDB">MongoDB</a>, <a href="http://en.wikipedia.org/wiki/Couchbase" title="Couchbase">Couchbase</a></li>
<li>  <strong>Key-value</strong> : <a href="http://en.wikipedia.org/wiki/Dynamo_(storage_system)" title="Dynamo (storage system)">Dynamo</a>, <a href="http://en.wikipedia.org/wiki/Riak" title="Riak">Riak</a>, <a href="http://en.wikipedia.org/wiki/Redis" title="Redis">Redis</a>, <a href="http://en.wikipedia.org/wiki/MemcacheDB" title="MemcacheDB">Cache</a>, <a href="http://en.wikipedia.org/wiki/Project_Voldemort" title="Project Voldemort">Project Voldemort</a></li>
<li>  <strong>Graph</strong>: <a href="http://en.wikipedia.org/wiki/Neo4J" title="Neo4J">Neo4J</a>, <a href="http://en.wikipedia.org/wiki/AllegroGraph" title="AllegroGraph">Allegro</a>, <a href="http://en.wikipedia.org/wiki/Virtuoso" title="Virtuoso">Virtuoso</a><br>初学者建议学习和使用一下MongoDB和Redis。</li>
</ul>
<p>参考阅读：</p>
<ol>
<li> 更加详细的NoSQL介绍：<a href="http://en.wikipedia.org/wiki/NoSQL">http://en.wikipedia.org/wiki/NoSQL</a></li>
<li> 要了解和学习更多的NoSQL数据库，请看：<a href="http://nosql-database.org/">http://nosql-database.org/</a></li>
<li> NoSQL相关博客：<a href="http://nosql.mypopescu.com/">http://nosql.mypopescu.com/</a></li>
<li> NoSQL相关博客：<a href="http://blog.nosqlfan.com/">http://blog.nosqlfan.com/</a></li>
<li> redis设计与实现：<a href="http://www.redisbook.com/en/latest/">http://www.redisbook.com/en/latest/</a></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World 代码示例</title>
    <url>/posts/9b8316b/</url>
    <content><![CDATA[<p>在这里测试一下代码显示插件，以下为代码内容：</p>
<pre title="Hello World" class="font:ubuntu-mono toolbar:1 lang:default decode:true">#include &lt;stdio.h&gt;

int main()
{
    printf("Hello Worldn");
    return 0;
}

......</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>响应式设计的免费测试工具</title>
    <url>/posts/d82a0fc/</url>
    <content><![CDATA[<p>原文链接： <a href="http://www.webdesignerdepot.com/2013/07/how-to-test-responsive-designs-for-free/">Steve Ralston</a>   翻译： <a href="http://blog.jobbole.com/"> 伯乐在线 </a> - <a href="http://blog.jobbole.com/author/jobbole/">伯乐在线读者</a><br>译文链接： <a href="http://blog.jobbole.com/45535/">http://blog.jobbole.com/45535/</a></p>
<h2 id="deviceponsive"><a href="#deviceponsive" class="headerlink" title="deviceponsive"></a>deviceponsive</h2><p><a href="http://deviceponsive.com/">deviceponsive</a>与Am I Responsive?非常相似，它们都简单明了的展示了你的网站，而且对设备而言，都没有可见的控制和选项。所有设备在一页长网页上同时显示。你能够通 过改变背景颜色和嵌入你自己的logo来定制这个网站的页眉，之后截屏分享出去，这十分有趣。从某种方式来说，当你向顾客分享你的截屏的时候，也就帮这个 网站打了广告。</p>
<p>该网站所提供设备及其屏幕大小： _Macbook——1280×800 _iPad portrait——768×1024 _iPad landscape——1024×768 _Kindle portrait——600×1024 _Kindle landscape——1024×600 _iPhone portrait——320×480 _iPhone landscape——480×320 _Galasy portrait——240×320 * Galaxy landscape——320×240</p>
<p>使用这些工具时，大部分情况下，滑动条会在较小的设备上显示。然而在实际的设备上，滑动条不会显示。不过为了测试试图能在不支持触控的设备上也能滑动，必须要做出一些让步。</p>
<span id="more"></span>

<h2 id="Screenfly"><a href="#Screenfly" class="headerlink" title="Screenfly"></a>Screenfly</h2><p><a href="http://quirktools.com/screenfly/">Screenfly</a> 实 实在在提升了可用系数。它提供九种比平板更大的设备，从10寸的笔记本到24寸的台式电脑都有，此外还包括五种平板，九种手机，三种电视，还能够自己定制 大小。通过另一个控制器，任何选取的设备都能被旋转成水平或者竖直的。你能够选择是否允许滚动，你还能生成一个可用于分享的链接，只需要点一个按钮就行。</p>
<p>这个网站显示分辨率的方式非常十分有益。每一个在菜单中的设备都显示了名称和分辨率，浏览器的实际分辨率在接近右上角的地方，被选中的设备的分辨率则在展示区域的页脚，跟测试网站的URL写在一起。这一个小细节在文档截图和给客户分享信息时给人非常好的感觉。</p>
<p>之前提到的这些足以使它成为一个完美的工具，但Screenfly的开发者还为它升级了代理服务器的特性，并认为非常合适。用写网站上的话来 说，”Screenfly能使用一个代理服务器，在你访问你的网站时伪装成其他设备。代理服务器模仿你所选择的设备的用户代理字符串，而不是该设备的行 为。”</p>
<p>对于其他所有工具，处理这个地方时都仅仅是利用CSS。Screenfly是唯一一个允许基于代理字符串来测试的。</p>
<p>我给一个我自己写的，提供了手机版本的网页做了基于代理字符串的测试，手机版网页的结果非常好。所有效果都跟我想的一样，所有功能也都能通过测试。测试代理字符串是保守的，这一点无可否认，不过这个网站就是这样保守的风格，而且代理服务器的特性也的确给网站带来了好处。</p>
<p>原文中列举了6个免费的测试工具，实际使用了这两个工具，可以满足一般的测试需求，那么你喜欢使用哪个工具呢？</p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>浅谈二代身份证缺陷</title>
    <url>/posts/9da8767f/</url>
    <content><![CDATA[<p>近期二代身份证“先天缺陷”的问题闹得沸沸扬扬，尤其是公安部已经做出了正式回应，要求加快推进登记指纹信息工作。那么从技术角度上来说，所谓的“先天缺陷”又是如何来的呢？</p>
<blockquote>
<p>第二代身份证的工作原理<br>第二代身份证的夹层中有芯片和线圈，当身份证阅读机发射电磁波读卡信号后，二代身份证的线圈感应了电磁波产生电流，芯片在电流的作用下开始工作，将二代身份证信息以电磁波发回给阅读机，这样阅读机就知道了二代身份证上的信息 。<br>在我国，居民生活中丢失身份证后，即使做补办（挂失）处理，但由于还没有任何注销措施，导致原身份证仍可正常使用。大量遗失、被盗身份证正通过网络进行非 法交易，并被广泛用于开办银行卡、信用卡，掩护诈骗、洗钱活动；更令人忧虑的是，由于缺乏必要的密码等基本防伪功能，若不法分子掌握与自己外貌相近的他人 真实身份证，则可“分身两人”，加大公安机关打击犯罪的难度。</p>
</blockquote>
<p>二代身份证的防伪性能不错，也就是说很难仿制出一张一样可以用的身份证，但是可以说完全没有防盗的措施，任何人捡到你的身份证都可以拿去用，相信也有不少人有多张身份证（例如户口迁移加办的）可以同时使用的经历，可见当时设计时实在考虑欠周到。</p>
<p>公安部正在大力推进的指纹加密是个很好的方法，但同时就加上了设备的需求，机读设备必须同时配备指纹读取设备，且不说成本如何，以前的设备就是个简单的IC卡读取，一下就变复杂了不少吧。这里你要仔细想想公安部其实有更深入的目的，例如，在一般情况下，只会对犯罪分子采取登记指纹的措施，这下来个全民登记，录入数据库，以后破案会有不少帮助吧，当然也可以达到其他的一些目的。<span id="more"></span></p>
<p>从技术上讲，我也想过两个方法：1，身份证信息简单加个有效时间戳，那么丢失的无效的时间戳就会比较旧，读取的时候与中心数据库做个对比就行了，但仔细一想，各个终端机读设备应该不会有直接联网到公安部数据库读取的权力，而且这样系统复杂不少，一般情况下都是直接读取身份证信息的，中心管理模型有不少好处，例如监控非法读取设备、身份证的使用情况等，有点像银行的ATM，身份证在哪一用、一登记，立马就能监控到，但是与原来系统相比改动太大；2，密码加密，设备相当简单，还是比较实用的，与指纹加密的方法相同。其实在设计之初就应该采用密码加密，逐步过渡到生物技术加密。</p>
<p>生物信息加密的好处不言而喻，按我的设想，未来的身份证应该可以直接使用人的生物信息，有点像科幻电影《少数派报告》的场景，依靠扫描人眼睛的虹膜来鉴别身份，根据虹膜信息去中央数据库比对，到处都有可以扫描虹膜的监视器去判别身份，行为无处可藏，可比登记指纹要直接的多了！</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>wordpress 子主题</title>
    <url>/posts/cc9a0d9c/</url>
    <content><![CDATA[<p>本站采用的是wordpress官方发布的TwentyEleven主题，官方会发布主题更新，但是如果你对主题文件进行了修改的话，每次更新后，原来的修改就丢失了，解决问题的最好方法就是采用子主题（Child Theme）。</p>
<h1 id="Child-Theme"><a href="#Child-Theme" class="headerlink" title="Child Theme"></a>Child Theme</h1><p>创建一个子主题是很简单的。</p>
<p>在wp-content/themes/建立新的文件夹，例如建立 twentyeleven-childen。</p>
<p>创建一个目录，将格式编写正确的 <em>style.css</em> 文件放进去，一个子主题就做成了！只需要对 HTML 和CSS 具有基本的了解，您就可以通过创建一个非常基本的子主题 来对一个父主题的样式和布局进行修改和扩展，而不需要对父主题的文件作任何修改。通过这样的方式，当父主题被更新的时候，您所做的修改就可以保存下来。</p>
<p><strong>因为这个原因，我们强烈推荐您使用子主题的方式来对主题进行修改。<span id="more"></span></strong></p>
<h2 id="必需的style-css文件"><a href="#必需的style-css文件" class="headerlink" title="必需的style.css文件"></a>必需的style.css文件</h2><p>_style.css_是一个子主题唯一<strong>必须的</strong>文件。它的头部提供的信息让WordPress辨认出子主题，并且<strong>重写父主题中的style.css文件</strong>。</p>
<p>对于任何WordPress主题，头部信息必须位于文件的顶端，唯一的区别就是子主题中的<code>Template:</code>行是必须的，因为它让WordPress知道子主题的父主题是什么。</p>
<p>下面是一个_style.css_文件的头部信息的示例：</p>
<pre>/*
Theme Name:     Twenty Ten Child
Theme URI:      http: //example.com/
Description:    Child theme for the Twenty Ten theme 
Author:         Your name here
Author URI:     http: //example.com/about/
Template:       twentyten
Version:        0.1.0
*/</pre>
<p>逐行的简单解释：</p>
<ul>
<li>  <code>Theme Name</code>. (<strong>必需</strong>) 子主题的<strong>名称</strong>。</li>
<li>  <code>Theme URI</code>. (可选) 子主题的主页。</li>
<li>  <code>Description</code>. (可选) 子主题的描述。比如：我的第一个子主题，真棒！</li>
<li>  <code>Author URI</code>. (可选) 作者主页。</li>
<li>  <code>Author</code>. (optional) 作者的名字。</li>
<li>  <code>Template</code>. (<strong>必需</strong>) 父主题的目录名，区别大小写。 <strong>注意：</strong> 当你更改子主题名字时，要先换成别的主题。</li>
<li>  <code>Version</code>. (可选) 子主题的版本。比如：0.1，1.0，等。<br><code>*/ </code>这个关闭标记的后面部分，就会按照一个常规的样式表文件一样生效，你可以把你想对WordPress应用的样式规则都写在它的后面。</li>
</ul>
<p>要注意的是，子主题的样式表会替换父主题的样式表而生效。（事实上WordPress根本就不会载入父主题的样式表。）所以，如果你想简单地改变父主题中的一些样式和结构——而不是从头开始制作新主题——你必须明确的导入父主题的样式表，然后对它进行修改。下面的例子告诉你如何使用<code>@import</code>规则完成这个。例如</p>
<pre class="">@import url("../twentyten/style.css");</pre>

<h2 id="使用-functions-php"><a href="#使用-functions-php" class="headerlink" title="使用 functions.php"></a>使用 functions.php</h2><p>不像_style.css_，子主题中的_functions.php_不会覆盖父主题中对应功能，而是将新的功能加入到父主题的_functions.php_中。（其实它会在<strong>父主题文件加载之前先载入</strong>。）</p>
<p>完整的Child Theme說明可以參考<a href="http://codex.wordpress.org/Child_Themes">英文說明</a>或<a href="http://codex.wordpress.org/zh-cn:%E5%AD%90%E4%B8%BB%E9%A1%8C">簡體中文說明</a>。</p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title>理解Git的工作流程 【转载】</title>
    <url>/posts/dd469e36/</url>
    <content><![CDATA[<p>英文原文：<a href="http://sandofsky.com/blog/git-workflow.html">Understanding the Git workflow</a>   编译： <a href="http://blog.jobbole.com/24379/">张重骐</a></p>
<p>如果你不理解Git的设计动机，那你就会处处碰壁。知道足够多的命令和参数后，你就会强行让Git按你想的来工作，而不是按Git自己的方式来。这就像把螺丝刀当锤子用；也能把活干完，但肯定干的差极了，花费很长时间，还会弄坏螺丝刀。</p>
<p>想想常见的Git工作流程是怎么失效的吧。</p>
<blockquote>
<p>从Master创建一个分支，写代码，然后把这个分支合并回Master。<br>多数时候这样做的效果会如你所愿，因为从你创建分支到合并回去之间，Master一般都会有些变动。然后，有一天当你想把一个功能 （feature）分支合并进Master的时候，而Master并没有像以往那样有变动，问题来了：这时Git不会进行合并commit，而是将 Master指向功能分支上的最新commit。（<a href="http://sandofsky.com/images/fast_forward.pdf">看图</a>）<span id="more"></span></p>
</blockquote>
<p>不幸的是，你的功能分支有用来备份代码的commit（作者称之为checkpoint commit），这些经常进行的commit对应的代码可能处于不稳定状态！而这些commit现在没法和Master上那些稳定的commit区分开来 了。当你想回滚的时候，很容易发生灾难性后果。</p>
<p>于是你就记住了：“当合并功能分支的时候，加上 -no-ff 选项强制进行一次全新的commit。”嗯，这么做好像解决问题了，那么继续。</p>
<p>然后一天你在线上环境中发现了一个严重bug，这时你需要追溯下这个bug是什么时候引入的。你运行了bisect命令，但却总是追溯到一些不稳定的commit。因此你不得不放弃，改用人肉检查。</p>
<p>最后你将bug范围缩小到一个文件。你运行blame命令查看这个文件在过去48小时里的变动。然后blame告诉你这个文件已经好几周没有被修改 过了——你知道根本不可能没有变动。哦，原来是因为blame计算变动是从第一次commit算起，而不是merge的时候。你在几周前的一次 commit中改动了这个文件，但这个变动今天才被merge回来。</p>
<p>用no-ff来救急，bisect又临时失效，blame的运作机制又那么模糊，所有这些现象都说明一件事儿，那就是你正在把螺丝刀当锤子用。</p>
<p><strong>反思版本控制</strong></p>
<p>版本控制的存在是因为两个原因。</p>
<p>首先，版本控制是用来辅助写代码的。因为你要和同事同步代码，并经常备份自己的代码。当然了，把文件压缩后发邮件也行，不过工程大了大概就不好办了。</p>
<p>其次，就是辅助配置管理工作。其中就包括并行开发的管理，比如一边给线上版本修复bug，一边开发下一个版本。配置管理也可以帮助弄清楚变动发生的具体时间，在追溯bug中是一个很好的工具。</p>
<p>一般说来，这两个原因是冲突的。</p>
<p>在开发一个功能的时候，你应该经常做备份性的commit。然而，这些commit经常会让软件没法编译。</p>
<p>理想情况是，你的版本更新历史中的每一次变化都是明确且稳定的，不会有备份性commit带来的噪声，也不会有超过一万行代码变动的超大 commit。一个清晰的版本历史让回滚和选择性merge都变得相当容易，而且也方便以后的检查和分析。然而，要维护这样一个干净的历史版本库，也许意 味着总是要等到代码完善之后才能提交变动。</p>
<p>那么，经常性的commit和干净的历史，你选择哪一个？</p>
<p>如果你是在刚起步的创业公司中，干净的历史没有太大帮助。你可以放心地把所有东西都往Master中提交，感觉不错的时候随时发布。</p>
<p>如果团队规模变大或是用户规模扩大了，你就需要些工具和技巧来做约束，包括自动化测试，代码检查，以及干净的版本历史。</p>
<p>功能分支貌似是一个不错的折中选择，能够基本的并行开发问题。当你写代码时候，可以不用怎么在意集成的问题，但它总有烦到你的时候。</p>
<p>当你的项目规模足够大的时候，简单的branch/commit/merge工作流程就出问题了。缝缝补补已经不行了。这时你需要一个干净的版本历史库。</p>
<p>Git之所以是革命性的，就是因为它能同时给你这两方面的好处。你可以在原型开发过程中经常备份变动，而<a href="http://www.amazon.cn/gp/product/B007XPTAIS/ref=as_li_qf_sp_asin_il_tl?ie=UTF8&amp;tag=vastwork-23&amp;linkCode=as2&amp;camp=536&amp;creative=3200&amp;creativeASIN=B007XPTAIS" title="搞定(套装共3册) ">搞定</a>后只需要交付一个干净的版本历史。</p>
<p>&nbsp;</p>
<p><strong>工作流程</strong></p>
<p>考虑两种分支：公共的和私有的。</p>
<p>公共分支是项目的权威性历史库。在公共分支中，每一个commit都应该确保简洁、原子性，并且有完善的提交信息。此分支应该尽可能线性，且不能更改。公共分支包括Master和发行版的分支。</p>
<p>私有分支是供你自己使用的，就像解决问题时的草稿纸。</p>
<p>安全起见，把私有分支只保存在本地。如果你确实需要push到服务器的话（比如要同步你在家和办公室的电脑），最好告诉同事这是私有的，不要基于这个分支展开工作。</p>
<p>绝不要直接用merge命令把私有分支合并到公共分支中。要先用reset、rebase、squash merges、commit amending等工具把你的分支清理一下。</p>
<p>把你自己看做一个作者，每一次的commit视为书中的一章。作者不会出版最初的草稿，就像Michael Crichton说的，“伟大的书都不是写出来——而是改出来的”。</p>
<p>如果你没接触过Git，那么修改历史对你来说好像是种禁忌。你习惯于认为提交过的所有东西都应该像刻在石头上一样不能抹去。但如果按这种逻辑，我们在文本处理软件器中也不应该使用“撤销”功能了。</p>
<p>实用主义者们直到变化变为噪音的时候才关注变化。对于配置管理来说，我们关注宏观的变化。日常commit（checkpoint commits）只是备份于云端的用于“撤销”的缓冲。</p>
<p>如果你保持公共历史版本库的简洁，那么所谓的fast-forward merge就不仅安全而且可取了，它能保证版本变更历史的线性和易于追溯。</p>
<p>关于 -no-ff 仅剩的争论就只剩“文档证明”了。人们可能会先merge再commit，以此代表最新的线上部署版本。不过，这是反模式的。用tag吧。</p>
<p>规则和例子</p>
<p>根据改变的多少、持续工作时间的长短，以及分支分叉了多远，我使用三种基本的方法。</p>
<p>1）短期工作</p>
<p>绝大多数时间，我做清理时只用squash merge命令。</p>
<p>假设我创建了一个功能分支，并且在接下来一个小时里进行了一系列的checkpoint commit。</p>
<pre class="lang:default decode:true ">git checkout -b private_feature_branch
touch file1.txt
git add file1.txt
git commit -am "WIP"</pre>
<p>完成开发后，我不是直接执行git merge命令，而是这样：</p>
<pre class="lang:default decode:true ">git checkout master
git merge --squash private_feature_branch
git commit -v</pre>
<p>然后我会花一分钟时间写个详细的commit日志。</p>
<p>2）较大的工作</p>
<p>有时候一个功能可以延续好几天，伴有大量的小的commit。</p>
<p>我认为这些改变应该被分解为一些更小粒度的变更，所以squash作为工具来说就有点儿太糙了。（根据经验我一般会问，“这样能让<a href="http://blog.jobbole.com/438/" title="Eric Lippert：阅读代码真的很难">阅读代码</a>更容易吗？”）</p>
<p>如果我的checkpoint commits之后有合理的更新，我可以使用rebase的交互模式。</p>
<p>交互模式很强大。你可以用它来编辑、分解、重新排序、合并以前的commit。</p>
<p>在我的功能分支上：</p>
<p>git rebase –interactive master</p>
<p>然后会打开一个编辑器，里边是commit列表。每一行上依次是，要执行的操作、commit的SHA1值、当前commit的注释。并且提供了包含所有可用命令列表的图例。</p>
<p>默认情况下，每个commit的操作都是“pick”，即不会修改commit。</p>
<div>`pick ccd6e62 Work on back button`</div>
<div>`pick 1c83feb Bug fixes`</div>
<div>`pick f9d0c33 Start work on toolbar`</div>
我把第二行修改为“squash”，这样第二个commit就会合并到第一个上去。
<div>`pick ccd6e62 Work on back button`</div>
<div>`squash 1c83feb Bug fixes`</div>
<div>`pick f9d0c33 Start work on toolbar
`</div>
<div></div>
保存并退出，会弹出一个新的编辑器窗口，让我为本次合并commit做注释。就这样。

<p><strong>舍弃分支</strong></p>
<p>也许我的功能分支已经存在了很久很久，我不得不将好几个分支合并进这个功能分支中，以便当我写代码时这个分支是足够新的的。版本历史让人费解。最简单的办法是创建一个新的分支。</p>
<pre class="lang:default decode:true ">git checkout master
git checkout -b cleaned_up_branch
git merge --squash private_feature_branch
git reset</pre>
<p>现在，我就有了一个包含我所有修改且不含之前分支历史的工作目录。这样我就可以手动添加和commit我的变更了。</p>
<p><strong>总结</strong></p>
<p>如果你在与Git的默认设置背道而驰，先问问为什么。</p>
<p>将公共分支历史看做不可变的、原子性的、容易追溯的。将私有分支历史看做一次性的、可编辑的。</p>
<p>推荐的工作流程是：</p>
<ol>
<li> <div>`基于公共分支创建一个私有分支。`</div></li>
<li> 经常向这个私有分支commit代码。</li>
<li> <div>`一旦你的代码完善了，就清理掉下私有分支的历史。`</div>
<div></div>
<div></div></li>
<li> <code>将干净的私有分支merge到公共分支中。</code><br>英文原文：<a href="http://sandofsky.com/blog/git-workflow.html">Understanding the Git workflow</a>   编译： <a href="http://blog.jobbole.com/24379/">张重骐</a></li>
</ol>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>develop</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>小论文 选题</title>
    <url>/posts/bdfa4fed/</url>
    <content><![CDATA[<p>在毕业之前是必须有一篇小论文必须发表的，通常情况是可以从毕业设计大论文的选题里出，但是对于太阳能控制这种工程性的问题，实在想不出什么大的研究价值，所以还是决定另选题目了。其实还是希望导师可以从一些研究方向予以指导，至少指导一下大的方向和题目的，自己做起来还是有点迷茫，而且有选择困难症。</p>
<p>下面把几个可能的方向列举一下：</p>
<ol>
<li> 推荐系统</li>
<li> 基于GPU的推荐算法（协同过滤）的加速</li>
<li> 随机数生成算法，和基于GPU的加速</li>
<li> NOSQL Database</li>
</ol>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
      <tags>
        <tag>thesis</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux内存管理详细解析</title>
    <url>/posts/6d889d72/</url>
    <content><![CDATA[<p>原文出处： <a href="http://linux.ccidnet.com/art/302/20070524/1089197_1.html">赛迪</a></p>
<div id="ad1">我是一名程序员，那么我在这里以一个程序员的角度来讲解Linux内存的使用。</div>
一提到内存管理，我们头脑中闪出的两个概念，就是虚拟内存，与物理内存。这两个概念主要来自于linux内核的支持。

<p>Linux在内存管理上份为两级，一级是线性区，类似于00c73000-00c88000，对应于虚拟内存，它实际上不占用实际物理内存；一级是具体的物理页面，它对应我们机器上的物理内存。</p>
<p>这里要提到一个很重要的概念，内存的延迟分配。Linux内核在用户申请内存的时候，只是给它分配了一个线性区（也就是虚存），并没有分配实际物理 内存；只有当用户使用这块内存的时候，内核才会分配具体的物理页面给用户，这时候才占用宝贵的物理内存。内核释放物理页面是通过释放线性区，找到其所对应 的物理页面，将其全部释放的过程。</p>
<span id="more"></span>
<pre class="lang:default decode:true ">char *p=malloc(2048) //这里只是分配了虚拟内存2048，并不占用实际内存。
strcpy(p,”123”) //分配了物理页面，虽然只是使用了3个字节，但内存还是为它分配了2048字节的物理内存。
free(p) //通过虚拟地址，找到其所对应的物理页面，释放物理页面，释放线性区。</pre>
<p>我们知道用户的进程和内核是运行在不同的级别，进程与内核之间的通讯是通过系统调用来完成的。进程在申请和释放内存，主要通过brk,sbrk,mmap,unmmap这几个系统调用，传递的参数主要是对应的虚拟内存。</p>
<p>注意一点，在进程只能访问虚拟内存，它实际上是看不到内核物理内存的使用，这对于进程是完全透明的。</p>
<h1 id="glibc内存管理器"><a href="#glibc内存管理器" class="headerlink" title="glibc内存管理器"></a>glibc内存管理器</h1><p>那么我们每次调用malloc来分配一块内存，都进行相应的系统调用呢？</p>
<p>答案是否定的，这里我要引入一个新的概念，glibc的内存管理器。</p>
<p>我们知道malloc和free等函数都是包含在glibc库里面的库函数，我们试想一下，每做一次内存操作，都要调用系统调用的话，那么程序将多么的低效。</p>
<p>实际上glibc采用了一种批发和零售的方式来管理内存。glibc每次通过系统调用的方式申请一大块内存（虚拟内存），当进程申请内存时，glibc就从自己获得的内存中取出一块给进程。</p>
<h1 id="内存管理器面临的困难"><a href="#内存管理器面临的困难" class="headerlink" title="内存管理器面临的困难"></a>内存管理器面临的困难</h1><p>我们在写程序的时候，每次申请的内存块大小不规律，而且存在频繁的申请和释放，这样不可避免的就会产生内存碎块。而内存碎块，直接会导致大块内存申 请无法满足，从而更多的占用系统资源；如果进行碎块整理的话，又会增加cpu的负荷，很多都是互相矛盾的指标，这里我就不细说了。</p>
<p>我们在写程序时，涉及内存时，有两个概念heap和stack。传统的说法stack的内存地址是向下增长的，heap的内存地址是向上增长的。</p>
<p>函数malloc和free，主要是针对heap进行操作，由程序员自主控制内存的访问。</p>
<p>在这里heap的内存地址向上增长，这句话不完全正确。</p>
<p>glibc对于heap内存申请大于128k的内存申请，glibc采用mmap的方式向内核申请内存，这不能保证内存地址向上增长；小于128k的则采用brk，对于它来讲是正确的。128k的阀值，可以通过glibc的库函数进行设置。</p>
<p>这里我先讲大块内存的申请，也即对应于mmap系统调用。</p>
<p>对于大块内存申请，glibc直接使用mmap系统调用为其划分出另一块虚拟地址，供进程单独使用；在该块内存释放时，使用unmmap系统调用将这块内存释放，这个过程中间不会产生内存碎块等问题。</p>
<p>针对小块内存的申请，在程序启动之后，进程会获得一个heap底端的地址，进程每次进行内存申请时，glibc会将堆顶向上增长来扩展内存空间，也 就是我们所说的堆地址向上增长。在对这些小块内存进行操作时，便会产生内存碎块的问题。实际上brk和sbrk系统调用，就是调整heap顶地址指针。</p>
<p>&nbsp;</p>
<h1 id="那么heap堆的内存是什么时候释放呢？"><a href="#那么heap堆的内存是什么时候释放呢？" class="headerlink" title="那么heap堆的内存是什么时候释放呢？"></a>那么heap堆的内存是什么时候释放呢？</h1><p>当glibc发现堆顶有连续的128k的空间是空闲的时候，它就会通过brk或sbrk系统调用，来调整heap顶的位置，将占用的内存返回给系统。这时，内核会通过删除相应的线性区，来释放占用的物理内存。</p>
<p>下面我要讲一个内存空洞的问题：</p>
<p>一个场景，堆顶有一块正在使用的内存，而下面有很大的连续内存已经被释放掉了，那么这块内存是否能够被释放？其对应的物理内存是否能够被释放？</p>
<p>很遗憾，不能。</p>
<p>这也就是说，只要堆顶的部分申请内存还在占用，我在下面释放的内存再多，都不会被返回到系统中，仍然占用着物理内存。为什么会这样呢？</p>
<p>这主要是与内核在处理堆的时候，过于简单，它只能通过调整堆顶指针的方式来调整调整程序占用的线性区；而又只能通过调整线性区的方式，来释放内存。所以只要堆顶不减小，占用的内存就不会释放。</p>
<p>提一个问题：</p>
<pre class="lang:default decode:true">char *p=malloc(2);
free(p)</pre>
<div></div>
为什么申请内存的时候，需要两个参数，一个是内存大小，一个是返回的指针；而释放内存的时候，却只要内存的指针呢？

<p>这主要是和glibc的内存管理机制有关。glibc中，为每一块内存维护了一个chunk的结构。glibc在分配内存时，glibc先填写chunk结构中内存块的大小，然后是分配给进程的内存。</p>
<pre class="lang:default decode:true ">chunk ------size
p------------ content</pre>
<p>在进程释放内存时，只要 指针-4 便可以找到该块内存的大小，从而释放掉。</p>
<p>注：glibc在做内存申请时，最少分配16个字节，以便能够维护chunk结构。</p>
<p>glibc提供的调试工具：</p>
<p>为了方便调试，glibc 为用户提供了 malloc 等等函数的钩子（hook），如 __malloc_hook</p>
<p>对应的是一个函数指针，</p>
<pre class="lang:default decode:true ">void *function (size_t size, const void *caller)</pre>
<p>其中 caller 是调用 malloc 返回值的接受者（一个指针的地址）。另外有 __malloc_initialize_hook函数指针，仅仅会调用一次（第一次分配动态内存时）。（malloc.h）</p>
<p>一些使用 malloc 的统计量（SVID 扩展）可以用 struct mallinfo 储存，可调用获得。</p>
<pre class="lang:default decode:true ">struct mallinfo mallinfo (void)</pre>
<p>如何检测 memory leakage？glibc 提供了一个函数</p>
<p>void mtrace (void)及其反作用void muntrace (void)</p>
<p>这时会依赖于一个环境变量 MALLOC_TRACE 所指的文件，把一些信息记录在该文件中</p>
<p>用于侦测 memory leakage，其本质是安装了前面提到的 hook。一般将这些函数用</p>
<p>#ifdef DEBUGGING 包裹以便在非调试态下减少开销。产生的文件据说不建议自己去读，</p>
<p>而使用 mtrace 程序（perl 脚本来进行分析）。下面用一个简单的例子说明这个过程，这是</p>
<p>源程序：</p>
<pre class="lang:default decode:true ">#include
#include
#include
intmain( int argc, char *argv[] )
{
  int *p, *q ;
  #ifdef DEBUGGING
  mtrace( ) ;
  #endif
  p = malloc( sizeof( int ) ) ;
  q = malloc( sizeof( int ) ) ;
  printf( "p = %pnq = %pn", p, q ) ;
  *p = 1 ;
  *q = 2 ;
  free( p ) ;
  return 0 ;
}</pre>
<p>很简单的程序，其中 q 没有被释放。我们设置了环境变量后并且 touch 出该文件</p>
<p>执行结果如下：</p>
<p><code>p = 0x98c0378q = ``0x98c0388</code></p>
<p>该文件内容如下</p>
<div>`= Start`</div>
<div>`@./test30:[``0x8048446``] + ``0x98c0378` `0x4`</div>
<div>`@./test30:[``0x8048455``] + ``0x98c0388` `0x4`</div>
<div>`@./test30:[``0x804848f``] - ``0x98c0378
`</div>
<div></div>
<div></div>
到这里我基本上讲完了，我们写程序时，数据部分内存使用的问题。

<h1 id="代码占用的内存"><a href="#代码占用的内存" class="headerlink" title="代码占用的内存"></a>代码占用的内存</h1><p>数据部分占用内存，那么我们写的程序是不是也占用内存呢？</p>
<p>在linux中，程序的加载，涉及到两个工具，linker 和loader。Linker主要涉及动态链接库的使用，loader主要涉及软件的加载。</p>
<ol>
<li> exec执行一个程序</li>
<li> elf为现在非常流行的可执行文件的格式，它为程序运行划分了两个段，一个段是可以执行的代码段，它是只读，可执行；另一个段是数据段，它是可读写，不能执行。</li>
<li> loader会启动，通过mmap系统调用，将代码端和数据段映射到内存中，其实也就是为其分配了虚拟内存，注意这时候，还不占用物理内存；只有程序执行到了相应的地方，内核才会为其分配物理内存。</li>
<li> loader会去查找该程序依赖的链接库，首先看该链接库是否被映射进内存中，如果没有使用mmap，将代码段与数据段映射到内存中，否则只是将其加入进程的地址空间。这样比如glibc等库的内存地址空间是完全一样。<br>因此一个2M的程序，执行时，并不意味着为其分配了2M的物理内存，这与其运行了的代码量，与其所依赖的动态链接库有关。</li>
</ol>
<h1 id="运行过程中链接动态链接库与编译过程中链接动态库的区别"><a href="#运行过程中链接动态链接库与编译过程中链接动态库的区别" class="headerlink" title="运行过程中链接动态链接库与编译过程中链接动态库的区别"></a>运行过程中链接动态链接库与编译过程中链接动态库的区别</h1><p>我们调用动态链接库有两种方法：一种是编译的时候，指明所依赖的动态链接库，这样loader可以在程序启动的时候，来所有的动态链接映射到内存中；一种是在运行过程中，通过dlopen和dlfree的方式加载动态链接库，动态将动态链接库加载到内存中。</p>
<p>这两种方式，从编程角度来讲，第一种是最方便的，效率上影响也不大，在内存使用上有些差别。</p>
<p>第一种方式，一个库的代码，只要运行过一次，便会占用物理内存，之后即使再也不使用，也会占用物理内存，直到进程的终止。</p>
<p>第二中方式，库代码占用的内存，可以通过dlfree的方式，释放掉，返回给物理内存。</p>
<p>这个差别主要对于那些寿命很长，但又会偶尔调用各种库的进程有关。如果是这类进程，建议采用第二种方式调用动态链接库。</p>
<h1 id="占用内存的测量"><a href="#占用内存的测量" class="headerlink" title="占用内存的测量"></a>占用内存的测量</h1><p>测量一个进程占用了多少内存，linux为我们提供了一个很方便的方法，/proc目录为我们提供了所有的信息，实际上top等工具也通过这里来获取相应的信息。</p>
<pre class="lang:default decode:true ">/proc/meminfo 机器的内存使用信息
/proc/pid/maps pid为进程号，显示当前进程所占用的虚拟地址。
/proc/pid/statm 进程所占用的内存
[root@localhost ~]# cat /proc/self/statm
654 57 44 0 0 334 0</pre>
<p>输出解释</p>
<p>CPU 以及CPU0。。。的每行的每个参数意思（以第一行为例）为：</p>
<p>参数 解释 /proc//status</p>
<pre class="lang:default decode:true ">Size (pages) 任务虚拟地址空间的大小 VmSize/4
Resident(pages) 应用程序正在使用的物理内存的大小 VmRSS/4
Shared(pages) 共享页数 0
Trs(pages) 程序所拥有的可执行虚拟内存的大小 VmExe/4
Lrs(pages) 被映像到任务的虚拟内存空间的库的大小 VmLib/4
Drs(pages) 程序数据段和用户态的栈的大小 （VmData+ VmStk ）4
dt(pages) 04</pre>
<p>查看机器可用内存</p>
<pre class="lang:default decode:true ">/proc/28248/&gt;free
total used free shared buffers cached
Mem: 1023788 926400 97388 0 134668 503688
-/+ buffers/cache: 288044 735744
Swap: 1959920 89608 1870312</pre>
<p>我们通过free命令查看机器空闲内存时，会发现free的值很小。这主要是因为，在linux中有这么一种思想，内存不用白不用，因此它尽可能的cache和buffer一些数据，以方便下次使用。但实际上这些内存也是可以立刻拿来使用的。</p>
<p>所以 空闲内存=free+buffers+cached=total-used</p>
<h1 id="查看进程使用的内存"><a href="#查看进程使用的内存" class="headerlink" title="查看进程使用的内存"></a>查看进程使用的内存</h1><p>查看一个进程使用的内存，是一个很令人困惑的事情。因为我们写的程序，必然要用到动态链接库，将其加入到自己的地址空间中，但是/proc/pid/statm统计出来的数据，会将这些动态链接库所占用的内存也简单的算进来。</p>
<p>这样带来的问题，动态链接库占用的内存有些是其他程序使用时占用的，却算在了你这里。你的程序中包含了子进程，那么有些动态链接库重用的内存会被重复计算。</p>
<p>因此要想准确的评估一个程序所占用的内存是十分困难的，通过写一个module的方式，来准确计算某一段虚拟地址所占用的内存，可能对我们有用。(T002)</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>如何评价随机数生成算法</title>
    <url>/posts/bc50611c/</url>
    <content><![CDATA[<p>部分内容转自知乎 <a href="http://www.zhihu.com/question/20222653" title="如何评价一个随机数生成算法的优劣？">http://www.zhihu.com/question/20222653</a>，在此做一个记录和总结。</p>
<p>主要的评价标准可以参考德国联邦信息安全办公室给出了随机数发生器质量评判的四个标准。</p>
<p>四个判别随机数序列质量的准则：</p>
<blockquote>
<ul>
<li>  K1 — A sequence of random numbers with a low probability of containing identical consecutive elements.</li>
<li>  K2 — A sequence of numbers which is indistinguishable from ‘true random’ numbers according to specified statistical tests.</li>
<li>  K3 — It should be impossible for any attacker (for all practical purposes) to calculate, or otherwise guess, from any given sub-sequence, any previous or future values in the sequence, nor any inner state of the generator.</li>
<li>  K4 — It should be impossible, for all practical purposes, for an attacker to calculate, or guess from an inner state of the generator, any previous numbers in the sequence or any previous inner generator states.<span id="more"></span><br>翻译如下：</li>
</ul>
</blockquote>
<ul>
<li>  K1——出现相同连续元素的随机数序列的概率较低。</li>
<li>  K2——按照特定的统计学测试，无法区分生成的随机数与真随机数。符合统计学的平均性，比如所有数字出现概率应该相同，卡方检验应该能通过，超长游程长度概略应该非常小，自相关应该只有一个尖峰，任何长度的同一数字之后别的数字出现概率应该仍然是相等的等等。</li>
<li>  K3——从一段已知随机数序列计算或者猜测出随机数发生器的内部工作状态或者上一个或下一个随机数，应该是不可能的。</li>
<li>  K4——从随机数发生器的工作状态猜测出随机数发生器以前的工作状态，或序列中前面的随机数，应该是不可能的。<br>我们一般用的随机数发生器至少要符合K1和K2，而用于加密等应用的随机数发生器则还要符合K3和K4。</li>
</ul>
<p>有一系列的测试可以判断一个随机数生成器的优劣。NIST发布了一个测试工具包专门来做这件事情。<br><a href="http://csrc.nist.gov/groups/ST/toolkit/rng/documentation_software.html">http://csrc.nist.gov/groups/ST/toolkit/rng/documentation_software.html</a></p>
<p>还有一些其他应用随机数计算与理论值对比的方法，例如用蒙特卡洛方法求高维数值积分（例如n维球的体积和面积），如果随机数生成器足够好，积分结果应该能很好地逼近理论值。用蒙特卡洛方法计算PI也可以是一种尝试。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>random number</tag>
      </tags>
  </entry>
  <entry>
    <title>前端开发工具 Bootstrap 3.0 正式版发布</title>
    <url>/posts/8b2968b1/</url>
    <content><![CDATA[<p>不久前我接触了Bootstrap 2.3.2，对于一个像我这样之前没有太多前端开发经验和网页设计经验的人来说，Bootstrap是一个很好的工具，同时基于Bootstrap还有其他扩展和类似的工具包，我也自己做了几个简单的网页（<a href="http://tracker.lei00.com/">链接</a>），页面元素加入了Google的一些风格。前不久，广受期待的3.0终于与广大开发者见面了。</p>
<p>Bootstrap是Twitter推出的一个开源的用于前端开发的工具包，包含了丰富的Web组件。根据这些组件，开发者可以快速的搭建一个漂亮、功能完备的网站。在经过Bootstrap 3 RC版的测试和改善后，Bootstrap 3.0.0于8月20日正式发布。</p>
<span id="more"></span>Bootstrap 3.0 值得关注的特性包括：

<ul>
<li>  全新设计的风格和可选主题，趋向扁平化设计和提供<a href="http://getbootstrap.com/examples/theme/">更多可选主题</a>；</li>
<li>  面向移动优先和响应式设计，更好地支持移动端设备的开发；</li>
<li>  全新定制，重新设计，用浏览器代替Heroku对其进行编译，更好的依赖支持、内置错误处理等；</li>
<li>  默认更好的盒子模型；</li>
<li>  超强的网格系统，更好地支持手机、平板电脑、台式机和大屏幕布局；</li>
<li>  重写了JavaScript插件；</li>
<li>  新的Glyphicons图标字体；</li>
<li>  导航条组件的大改进；</li>
<li>  模态对话框更好的响应式效果；</li>
<li>  组件的维护（新增和删除）；</li>
<li>  文档的完善；</li>
<li>  不再支持 IE7 和 Firefox 3.6。<br>详细的介绍请看<a href="https://github.com/twbs/bootstrap/releases">发行说明</a>。</li>
</ul>
<p>下载地址：<a href="http://blog.getbootstrap.com/2013/08/19/bootstrap-3-released/">http://blog.getbootstrap.com/2013/08/19/bootstrap-3-released/</a></p>
<p><a href="https://github.com/twbs/bootstrap/releases/download/v3.0.0/bootstrap-3.0.0-dist.zip">https://github.com/twbs/bootstrap/releases/download/v3.0.0/bootstrap-3.0.0-dist.zip</a></p>
<p>Github地址：<a href="https://github.com/twbs/bootstrap">https://github.com/twbs/bootstrap</a></p>
<p>在线演示：<a href="http://twbs.github.io/bootstrap/components/">http://twbs.github.io/bootstrap/components/</a></p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>develop</tag>
      </tags>
  </entry>
  <entry>
    <title>git 代理配置</title>
    <url>/posts/28636f68/</url>
    <content><![CDATA[<p>最近Git在国内使用时偶尔会遇到被墙的情况，今天我就遇到了，导致无法更新自己的远端Git仓库，于是使用goagent来解决，浏览器端的代理配置很简单，相关goagent的<a href="https://code.google.com/p/goagent/w/list" title="goagent wiki">wiki</a>页面也有很详细的解释。</p>
<p><a href="https://code.google.com/p/goagent/wiki/GoAgent_Linux" title="goagent使用教程">Linux/Mac系统下的goagent的使用教程</a></p>
<p>现在你应该可以在Terminal下利用Python运行goagent代理了，代理地址是 127.0.0.1:8087，下面就以使用goagent为例，介绍如何为git配置代理。</p>
<p>Git 目前支持的三种协议 <code>git://</code>、<code>ssh://</code> 和 <code>http://</code>，其代理配置各不相同：<code>core.gitproxy</code> 用于<code>git://</code> 协议，<code>http.proxy</code> 用于 <code>http://</code> 协议，<code>ssh://</code> 协议的代理需要配置 ssh 的 <code>ProxyCommand</code> 参数。<span id="more"></span></p>
<p>先从最简单的HTTP和HTTPS协议配置代理开始，在Linux下，用户可以通过编辑自己的.bash_profile或.bash_rc文件来配置全局代理，或者直接修改环境变量，使用以下命令即可：</p>
<blockquote>
<p>export http_proxy=<a href="https://127.0.0.1:8087/">https://127.0.0.1:8087</a></p>
<p>export https_proxy=<a href="https://127.0.0.1:8087/">https://127.0.0.1:8087</a></p>
</blockquote>
<p>ftp_proxy变量也是可以设置的，不过对git没用。记得在更新完.bash_profile或.bash_rc文件后运行一下：</p>
<blockquote>
<p>source .bash_profile</p>
</blockquote>
<p>另外，你也可以利用git config来单独为git配置代理，方法如下：</p>
<blockquote>
<p>git config –global https.proxy <a href="http://127.0.0.1:8087/">http://127.0.0.1:8087</a><br>git config –global http.proxy <a href="http://127.0.0.1:8087/">http://127.0.0.1:8087</a></p>
<p>&nbsp;</p>
<p>~/.gitconfig 文件 ：具体到你的用户。你可以通过传递–global 选项使Git 读或写这个特定的文件。<br>这里运行之后可以在用户目录的.gitconfig文件中看到修改效果，在那里也可以去除这些配置。</p>
</blockquote>
<p>以上方法可以解决使用HTTPS协议的代理问题，对于我自己的项目，一般使用的都是HTTPS协议，在git clone项目的时候我们可以注意后面的url，看使用的是什么类型的协议。</p>
<p>如果是git协议，可以使用git config修改core.gitproxy，这里需要为其指定一个脚本文件，来执行代理的操作，例如我们建立git-proxy.sh文件，文件内容为：</p>
<blockquote>
<p>#!/bin/sh<br>connect -S 127.0.0.1:7070 “$@”<br>如果没有connect命令的话，可以apt-get安装 proxy-connect 或者 connect-proxy 软件包即可。然后执行：<br>export GIT_PROXY_COMMAND=”/path/to/git-proxy.sh“<br>或者<br>git config –global core.gitproxy “/path/to/git-proxy.sh”<br>最后是针对SSH协议的配置，建立git-proxy-ssh.sh文件，写入：<br>#!/bin/sh<br>ssh -o ProxyCommand=”/path/to/git-proxy.sh %h %p” “$@”<br>然后配置git使用该文件：<br>export GIT_SSH=”/path/to/git-proxy-ssh.sh“<br>当然也可以直接配置 ～/.ssh/config 的 ProxyCommand，例如<br>Host github.com<br>ProxyCommand nc -X 5 -x 127.0.0.1:8087 %h %p<br>这样链接到 github.com 的 ssh 都会使用 127.0.0.1:8087 的代理，ssh 的配置可以参考 man ssh_config ，nc 命令的使用可以参考 man nc 。</p>
</blockquote>
<p>SSH 协议的代理可以是全局的（去掉 Host 那行就行了），也可以针对某个网站，但不能针对某个仓库配置。</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>WINAPI QueryPerformanceCounter的使用</title>
    <url>/posts/3c688e29/</url>
    <content><![CDATA[<p>引用自<a href="http://stackoverflow.com/questions/1739259/how-to-use-queryperformancecounter">http://stackoverflow.com/questions/1739259/how-to-use-queryperformancecounter</a></p>
<p>最近在做一个程序，要从Linux转移到windows下测试一下计算时间，我们知道在Linux下可以使用gettimeofday得到微妙级别的时间，使用方法先复习一下：</p>
<p>使用到的数据结构和函数原型如下：</p>
<pre class="lang:default decode:true">struct timeval {
    time_t      tv_sec;     /* seconds */
    suseconds_t tv_usec;    /* microseconds */
};</pre>
<pre class="lang:default decode:true">#include&lt;sys/time.h&gt;
int gettimeofday(struct timeval *tv, struct timezone *tz);</pre>
<p>在gettimeofday()函数中tv或者tz都可以为空。如果为空则就不返回其对应的结构体。在struct timeval中的tv_usec域我们可以得到微妙级别的时间。</p>
<p>函数执行成功后返回0，失败后返回-1，错误代码存于errno中。</p>
<p>接下来转入到Windows部分，利用高精度性能计数器来进行定时，具体方法如下：</p>
<p>下面两个函数是VC提供的仅供Windows 95及其后续版本使用的精确时间函数，并要求计算机从硬件上支持精确定时器。<br>QueryPerformanceFrequency()函数和QueryPerformanceCounter()函数的原型如下：</p>
<pre>BOOL  QueryPerformanceFrequency(LARGE_INTEGER ＊lpFrequency);
BOOL  QueryPerformanceCounter(LARGE_INTEGER ＊lpCount);</pre>
<span id="more"></span>数据类型ARGE_INTEGER既可以是一个8字节长的整型数，也可以是两个4字节长的整型数的联合结构，<wbr /> 其具体用法根据编译器是否支持64位而定。该类型的定义如下：
<pre class="lang:default decode:true">typedef union _LARGE_INTEGER
{
    struct
    {
        DWORD LowPart ;// 4字节整型数
        LONG  HighPart;// 4字节整型数
    };
    LONGLONG QuadPart ;// 8字节整型数
}LARGE_INTEGER ;</pre>
<p>在进行定时之前，先调用QueryPerformanceFrequency()函数获得机器内部定时器的时钟频率，<wbr /> 然后在需要严格定时的事件发生之前和发生之后分别调用QueryPerformanceCounter()函数，利用两次获得的计数之差及时钟频率，计算出事件经历的精确时间。</p>
<pre class="lang:default decode:true">#include &lt;windows.h&gt;

double PCFreq = 0.0;
__int64 CounterStart = 0;

void StartCounter(){
    LARGE_INTEGER li;
    if(!QueryPerformanceFrequency(&amp;li))
        cout &lt;&lt; "QueryPerformanceFrequency failed!n";

    PCFreq = double(li.QuadPart)/1000.0;

    QueryPerformanceCounter(&amp;li);
    CounterStart = li.QuadPart;}double GetCounter(){
    LARGE_INTEGER li;
    QueryPerformanceCounter(&amp;li);
    return double(li.QuadPart-CounterStart)/PCFreq;}

int main()
{
    StartCounter();
    Sleep(1000);
    cout &lt;&lt; GetCounter() &lt;&lt;"n";
    return 0;
}</pre>
<p>使用秒为单位，则使用：PCFreq = double(li.QuadPart);</p>
<p>使用微秒做单位，则使用：PCFreq = double(li.QuadPart)/1000000.0。</p>
<p>同时摘录一些对该API的评论：</p>
<p>windows API计时最准的是QueryPerformanceCounter，CPU计时的其他任何时间函数都是用操作系统时间片计时，多核下Windows的时间片是15毫秒，单核10毫秒，决定了你的最高精度10-15毫秒。CPU计时必须有CPU的硬件支持，ARM版WinCE也有QueryPerformanceCounter，但他的精度和时间片计时一样。</p>
<p>新的x86基本都能高精度计时。sunos是最早把高精度计时（微秒级）带入通用操作系统的，因为他的硬件封闭，sparc的CPU有高精度计时的支持。</p>
<p>Windows的GetSystemTime()、GetTickCount()、GetSystemTimeAsFileTime()等函数的值是存放在系统的固定内存区域的，每次时钟中断时由操作系统更新一次（更新周期即系统任务调度时间片，一般为5到15毫秒）。<br>Windows这么处理是基于效率考虑的，每次做真正的时间计算需要耗费一定时间（读硬件时钟、计算年月日等）。Linux的gettimeofday()比较精确，每次都做准确计算，但比较低效（一次调用要耗费1万多cpu周期）</p>
]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Practice Round China New Grad Test 2014 解题报告</title>
    <url>/posts/1109c473/</url>
    <content><![CDATA[<p>这次练习赛是Google针对2014校园招聘即将到来的一个上机测试进行的一次练习，一共三道题目，都不是很难，也主要是可以对系统有一个更好的了解。</p>
<p>先简单说一下Google CodeJam的这个系统，与我们通常的OnlineJudge主要的不同，是提交代码的方式，在我们写好解题代码后，需要下载系统随机提供的测试用例文件，利用自己的程序跑这个输入文件并得到相应的输出，然后上传自己代码和输出给系统去判断，总体来说是复杂了一些。</p>
<p>大家可以通过这个链接<a href="https://code.google.com/codejam/contest/2933486/dashboard">https://code.google.com/codejam/contest/2933486/dashboard</a>去查看这次练习的具体题目和测试用例。</p>
<p>Problem A. Bad Horse<span id="more"></span></p>
<p>题目简单来看，就是一句话：Bad Horse has decided to split the league into two departments in order to separate troublesome members. 每个测试用例呢，会给你几对人的名字，每一对人都是会互相找麻烦的那种，必须分到不同组去，那么最后能不能成功分组呢？</p>
<p>例如（1,2）（2,3）（3,4）是可以分成（1,3）（2,4）这两个集合的，而（1,2）（2,3）（1,3）则是不可以划分成功的。我对这题使用的方法略复杂，就不贴出代码了，简单说一下基本的思想：利用两个集合A，B来保存划分，对于新出现的一对，查看各个成员在A，B里面的出现情况，保证一个在A，另一个在B，如果两个在之前出现在了同一个集合中，那么结果肯定是No，如果两个都没有出现过，则先不要忙着去划分，先进行后面的，遍历完一趟之后再处理。例如（1,2）（3,4）（1,3），1放在集合A，2放在集合B，你会发现，3和4之前都没有出现过，那怎么放呢，先进行后面的（1,3），走完一趟之后再来处理（3,4）这样的对。</p>
<p>Problem B. Captain Hammer</p>
<p>这其实是一道标准的物理题。一个飞行器，从地面，给你一个斜向上的速度，那么根据角度可以计算出其竖直向上的速度和水平方向的速度，在重力加速度的影响下其最终会落回地面，由竖直向上的速度可以知道时间，那么水平方向速度乘以时间就是其在水平方向的位移。</p>
<p>题目给出初始的斜向速度和最后的水平位移，求斜向角度。</p>
<p>代码如下：</p>
<pre class="lang:default decode:true">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;math.h&gt;

#define PI 3.141592653
int main()
{
    int t;
    scanf("%d", &amp;t);
    int i;
    int speed, distance;
    for (i = 0; i &lt; t; i++) {
        scanf("%d %d", &amp;speed, &amp;distance);
        double result;
        result = (double)9.8 * distance / speed / speed;
        result = asin(result) * 180.0 / PI / 2;
        printf("Case #%d: %.7fn", i+1, result);
    }
    return 0;
}</pre>
<p>Problem C. Moist</p>
<p>这个题目有点插入排序的意思，本身意思很简单，解题思想也很简单，给你一系列的人名，最后要按字典序排序，如果一个人名需要插入到前面去，计数加1，比算移动的次数还简单。</p>
<p>代码如下：</p>
<pre class="lang:default decode:true ">#include &lt;iostream&gt;
#include &lt;string&gt;

using namespace std;

int main()
{
    int t;
    cin &gt;&gt; t;
    for (int i = 0; i &lt; t; i++) {
        int n;
        cin &gt;&gt; n;
        cin.get();
        int count = 0;
        string last;
        getline(cin, last);

        string current;
        for (int j = 1; j &lt; n; j++) {
            getline(cin, current);
            if (current.compare(last) &lt; 0)
                count++;
            else
                last.assign(current);
        }
        cout &lt;&lt;"Case #" &lt;&lt; i+1 &lt;&lt; ": " &lt;&lt; count &lt;&lt; endl;
    }
    return 0;
}</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>黑板数字擦除问题-阿里笔试题</title>
    <url>/posts/7630d0bb/</url>
    <content><![CDATA[<p>题目：</p>
<p>在黑板上写上1,2,3,4，……，50这50个数字，只要黑板上还有两个或两个以上的数字，就随机选取两个数字a和b，擦除a和b，并写上 |a - b|，问最后黑板上剩下的那个数可能是哪些？<span id="more"></span></p>
<p>这道题其实是小学奥数题。。。但是我要说，即将拿到硕士学位的我真的不会做啊。。。。。。</p>
<p>答案是范围内的奇数。解：黑板上所有数的和S＝1+2+3+……+50 是一个奇数，每操作一次，总和S减少了a+b -（a-b）=2b（假设a大于等于b），这是一个偶数，说明总和S的奇偶性不变。由于开始时S是奇数，因此终止时S仍是一个奇数。</p>
<p>参考：<a href="http://www.360doc.com/content/11/0312/12/6307578_100433348.shtml">http://www.360doc.com/content/11/0312/12/6307578_100433348.shtml</a></p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title>C++中指针与引用的区别-More Effective C++</title>
    <url>/posts/c47f27ac/</url>
    <content><![CDATA[<p>指针与引用看上去完全不同（指针用操作符“*”和“-&gt;”，引用使用操作符“. ”），但是它们似乎有相同的功能。指针与引用都是让你间接引用其他对象。你如何决定在什么时候使用指针，在什么时候使用引用呢？</p>
<p>首先，要认识到在任何情况下都不能使用指向空值的引用。一个引用必须总是指向某些对象。因此如果你使用一个变量并让它指向一个对象，但是该变量在某些时候也可能不指向任何对象，这时你应该把变量声明为指针，因为这样你可以赋空值给该变量。相反，如果变量肯定指向一个对象，例如你的设计不允许变量为空，这时你就可以把变量声明为引用。</p>
<p>“但是，请等一下”，你怀疑地问，“这样的代码会产生什么样的后果？”</p>
<pre class="lang:default decode:true">char *pc = 0;          // 设置指针为空值

char&amp; rc = *pc;        // 让引用指向空值</pre>
<p>这是非常有害的，毫无疑问。结果将是不确定的（编译器能产生一些输出，导致任何事情都有可能发生）。应该躲开写出这样代码的人，除非他们同意改正错误。如果你担心这样的代码会出现在你的软件里，那么你最好完全避免使用引用，要不然就去让更优秀的程序员去做。我们以后将忽略一个引用指向空值的可能性。<span id="more"></span></p>
<p>因为引用肯定会指向一个对象，在C＋＋里，引用应被初始化。</p>
<pre class="lang:default decode:true">string&amp; rs;             // 错误，引用必须被初始化
string s("xyzzy");
string&amp; rs = s;         // 正确，rs指向s</pre>
<p>指针没有这样的限制。</p>
<pre class="lang:default decode:true">string *ps;             // 未初始化的指针
// 合法但危险</pre>
<p>不存在指向空值的引用这个事实意味着使用引用的代码效率比使用指针的要高。因为在使用引用之前不需要测试它的合法性。</p>
<pre class="lang:default decode:true">void printDouble(const double&amp; rd)
{
    cout &lt;&lt; rd;         // 不需要测试rd,它
}                       // 肯定指向一个double值</pre>
<p>相反，指针则应该总是被测试，防止其为空：</p>
<pre class="lang:default decode:true">void printDouble(const double *pd)
{
  if (pd) {             // 检查是否为NULL
    cout &lt;&lt; *pd;
  }
}</pre>
<p>指针与引用的另一个重要的不同是指针可以被重新赋值以指向另一个不同的对象。但是引用则总是指向在初始化时被指定的对象，以后不能改变。</p>
<pre class="lang:default decode:true">string s1("Nancy");

string s2("Clancy");

string&amp; rs = s1;          // rs 引用 s1

string *ps = &amp;s1;         // ps 指向 s1

rs = s2;                 // rs 仍旧引用s1,

// 但是 s1的值现在是

// "Clancy"

ps = &amp;s2;               // ps 现在指向 s2;

// s1 没有改变</pre>
<p>总的来说，在以下情况下你应该使用指针，一是你考虑到存在不指向任何对象的可能（在这种情况下，你能够设置指针为空），二是你需要能够在不同的时刻指向不同的对象（在这种情况下，你能改变指针的指向）。如果总是指向一个对象并且一旦指向一个对象后就不会改变指向，那么你应该使用引用。</p>
<p>还有一种情况，就是当你重载某个操作符时，你应该使用引用。最普通的例子是操作符[]。这个操作符典型的用法是返回一个目标对象，其能被赋值。</p>
<pre class="lang:default decode:true">vector&lt;int&gt; v(10);       // 建立整形向量（vector），大小为10;

// 向量是一个在标准C库中的一个模板(见条款M35)

v[5] = 10;               // 这个被赋值的目标对象就是操作符[]返回的值

如果操作符[]返回一个指针，那么后一个语句就得这样写：

*v[5] = 10;</pre>
<p>但是这样会使得v看上去象是一个向量指针。因此你会选择让操作符返回一个引用。（这有一个有趣的例外，参见条款M30）</p>
<p>当你知道你必须指向一个对象并且不想改变其指向时，或者在重载操作符并为防止不必要的语义误解时，你不应该使用指针。而在除此之外的其他情况下，则应使用指针。</p>
<p>&nbsp;</p>
<p>为了进一步加深大家对指针和引用的区别，下面我从编译的角度来阐述它们之间的区别：</p>
<p>程序在编译时分别将指针和引用添加到符号表上，符号表上记录的是变量名及变量所对应地址。指针变量在符号表上对应的地址值为指针变量的地址值，而引用在符号表上对应的地址值为引用对象的地址值。符号表生成后就不会再改，因此指针可以改变其指向的对象（指针变量中的值可以改），而引用对象则不能修改。</p>
<p>最后，总结一下指针和引用的相同点和不同点：</p>
<p><strong>相同点：</strong></p>
<ul>
<li><p>  都是地址的概念；指针指向一块内存，它的内容是所指内存的地址；而引用则是某块内存的别名。</p>
</li>
<li><p><em>不同点：</em>*</p>
</li>
<li><p>  指针是一个实体，而引用仅是个别名；</p>
</li>
<li><p>  引用只能在定义时被初始化一次，之后不可变；指针可变；引用“从一而终”，指针可以“见异思迁”；</p>
</li>
<li><p>  引用没有const，指针有const，const的指针不可变；（具体指没有int&amp; const a这种形式，而const int&amp; a是有的，  前者指引用本身即别名不可以改变，这是当然的，所以不需要这种形式，后者指引用所指的值不可以改变）</p>
</li>
<li><p>  引用不能为空，指针可以为空；</p>
</li>
<li><p>  “sizeof 引用”得到的是所指向的变量(对象)的大小，而“sizeof 指针”得到的是指针本身的大小；</p>
</li>
<li><p>  指针和引用的自增(++)运算意义不一样；</p>
</li>
<li><p>  引用是类型安全的，而指针不是 (引用比指针多了类型检查)。</p>
</li>
</ul>
]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
      </tags>
  </entry>
  <entry>
    <title>游戏记录</title>
    <url>/posts/45ed9b8e/</url>
    <content><![CDATA[<p>之前用一个txt记录自己的游戏生涯，不是很方便，想想还是发布在这里吧，许多一线的大作基本都是发布后几天就通关的，像最近的《蝙蝠侠：阿甘起源》，过几天还会有《战地4》和《使命召唤》的年度终极对决。</p>
<p>早些年的记录都没有保存下来，但是像使命召唤系列都是玩了很多遍的，这里的记录也不是很全，也算比较遗憾吧！<span id="more"></span></p>
<p>2011.08 使命召唤7<br>2011.08.26 堡垒Bastion</p>
<p>2011.10.13 英雄无敌6 简体中文版 战网激活</p>
<p>2011.10.27 战地3 Battlefield3 战役通关<br>2011.10.28 战锤40K：星际战士 战役通关<br>2011.11.09 使命召唤8：现代战争3 单人战役 普通难度通关 4:25<br>2011.11.09 使命召唤8：现代战争3 单人战役 困难难度通关 7:50<br>2011.11.19 极品飞车16：亡命天涯 剧情模式 普通难度通关<br>2011.11.25 刺客信条：启示录 安装 蝙蝠侠：阿甘之城 激活<br>2011.12.07 蝙蝠侠：阿甘之城 主线通关<br>2011.12.17 Trine 2 魔幻三杰2 通关<br>2012.01.09 《刺客信条.启示录》 主线通关<br>2012.05.05 《PROTOTYPE》 虐杀原型 主线通关<br>2012.05.09 国产游戏 风卷残云 通关<br>2012.05.12 Sniper Elite V2 狙击精英2 开始通关<br>2012.05.14<br>2012.05.15 《Diablo 3》 暗黑破坏神3 上线<br>2012.07.06 《马克思佩恩3》 剧情模式 通关<br>2012.07.20 《特殊行动：一线生机》 通关<br>2012.09.03 《变形金刚：塞伯坦的陨落》战役通关<br>2012.09.25 《火炬之光2》 normal难度 通关<br>2012.10.17 《无主之地2》 普通难度 通关<br>2012.10.24 《荣誉勋章：战士》 普通难度 通关<br>2012.11.04 《DeadLight》 普通难度 通关<br>2013.01.23 《The Walking Dead》游戏 1-5章 通关<br>2013.01.25 《鬼泣DMC》<br>2013.01.29 《鬼泣DMC》 Devil Hunter难度通关<br>2013.03.09 《Tomb Raider》 古墓丽影 主剧情 通关<br>2013.03.09 《鬼泣DMC》 DLC Vergil’s Downfall 通关<br>2013.04.11 《蝙蝠侠：阿甘疯人院》 剧情通关<br>2013.05.05 《PROTOTYPE 2》 虐杀原型2 主线 普通难度 通关<br>2013.06.01 《英雄传说：空之轨迹3rd》通关<br>2013.06.06 《Remember Me》勿忘我 主线流程 普通难度通关<br>2013.07.23 《狂野西部 枪手》 Call of Juarez Gunslinger 故事模式 普通难度通关<br>2013.10.28 《蝙蝠侠：阿甘起源》主线通关                                                           2013.11.06  《使命召唤10：幽灵》战役 普通难度通关</p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>Game</tag>
      </tags>
  </entry>
  <entry>
    <title>在VPS上升级Ubuntu12.04到14.04</title>
    <url>/posts/4cbe7aa6/</url>
    <content><![CDATA[<p>前不久，Ubuntu的长期支持版LTS已经发布了14.04，本站搭建在基于Xen的Linode VPS上，最开始创建系统时选择的是Ubuntu12.04，在VPS中有rebuild的选项可以帮助你重装系统，直接安装最新的Ubuntu14.04，但是数据会丢失，备份和恢复比较费时。其实这里完全可以自己升级，Linode VPS支持我们自己升级内核和整个Linux的系统版本。对于其他的VPS，最好询问一下是否支持这样的升级。</p>
<p>为了数据安全，请在升级前对自己的数据进行完全备份。我这里采用了Linode的Backup服务，基础收费是每月5刀，可以定时或者手动对系统做快照进行备份。</p>
<p>Ubuntu的升级命令很简单，如下所示（需要sudo或root权限）：</p>
<pre class="lang:default decode:true"># apt-get update
# apt-get upgrade
# do-release-upgrade -d</pre>
<p>升级过程中请一定遵照系统的提示，例如系统会新建一个ssh daemon，防止连接中断对升级的影响。基本上按照步骤进行就可以升级成功。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>新的工作</title>
    <url>/posts/67859a57/</url>
    <content><![CDATA[<p>之前略有点偷懒，整个个人博客的更新也停止了很长时间。完成了硕士学位论文和毕业阶段，于是就很快进入了新的工作，也要为以后多作计划。</p>
<p>经过一番考虑，这一段准备更新一些之前落下的内容，例如毕设相关的一些技术知识，也准备学习一些新技术，会在这里记录一下自己的收获。OK！今天先到这里吧，继续努力！</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>大端 小端 字节序</title>
    <url>/posts/74be35a0/</url>
    <content><![CDATA[<pre class="lang:default decode:true   ">#include &lt;stdio.h&gt;
/*
    关于字节序:
对于一个整数0x12346=5678,在内存中占4个字节
从低地址开始,每个字节分别存的是 12,34,56,78就说明是大端CPU; 用于网络编程,JAVA
从低地址开始,每个字节分别存的是 78,56,34,12就说明是小端CPU; x86架构是小端
下面判断在内存的单个字节中二进位是按什么顺序排的?
*/

//定义位域
typedef struct bit_field
{
    unsigned char b0:1;  //b0指向低地址那一端的第一位,b1、b2依次排列下去
    unsigned char b1:1;
    unsigned char b2:1;
    unsigned char b3:1;
    unsigned char b4:1;
    unsigned char b5:1;
    unsigned char b6:1;
    unsigned char b7:1;
}BIT_FIELD;

int main()
{
    int i = 0xFF00001B;    //小端存放方式  1B 00 00 FF
    BIT_FIELD * p = ( BIT_FIELD * )&amp;i;  // p指向 1B

    printf("%u ",p-&gt;b0);
    printf("%u ",p-&gt;b1);
    printf("%u ",p-&gt;b2);
    printf("%u ",p-&gt;b3);
    printf("%u ",p-&gt;b4);
    printf("%u ",p-&gt;b5);
    printf("%u ",p-&gt;b6);
    printf("%un",p-&gt;b7);

    getchar();
    return 0;
}</pre>
<p>输出结果：1 1 0 1 1 0 0 0</p>
<p>在小端机器上验证得到,  在一个字节内部,  低位放在靠近低地址这个方向上。大端方式的高位靠近低地址方向存放。</p>
<p><a href="http://blog.csdn.net/ce123_zhouwei/article/details/6971544">http://blog.csdn.net/ce123_zhouwei/article/details/6971544</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
  </entry>
  <entry>
    <title>code highlighter test</title>
    <url>/posts/3be5a407/</url>
    <content><![CDATA[<pre class="lang:default decode:true ">#include &lt;stdio.h&gt;

int main()
{
    printf("Hello World\n");
    return 0;
}</pre>
<p>测试一下这个代码显示插件，Crayon Syntax Highlighter是我在wordpress使用过的最好用方便的代码插件，推荐使用。</p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
  </entry>
  <entry>
    <title>Java热部署工具-JRebel</title>
    <url>/posts/95ea9c90/</url>
    <content><![CDATA[<p>之前看了一篇文章，讲5个比较优秀的Java项目，文章虽然比较老，但是对里面的Neo4J，Gradle和JRebel都有了不少了解。</p>
<p>最近开发一个Java Web项目，经常需要部署到Tomcat上进行调试，但是每次修改代码或者配置文件后，都需要重新部署并重启Tomcat容器，实在是很浪费时间的一项操作。于是决定尝试一下JRebel，实现热部署，对程序的修改可以直接反应在部署的程序上。</p>
<p>可惜的是，JRebel是一个收费软件，个人可以申请30天的免费试用，可以使用myJRebel，<a href="https://my.jrebel.com/%EF%BC%8C%E6%98%AFJRebel%E7%9A%84%E4%B8%80%E4%B8%AA%E7%A4%BE%E5%8C%BA%E8%AE%A1%E5%88%92%EF%BC%8C%E4%BC%9A%E8%A6%81%E6%B1%82%E4%BD%A0%E5%85%81%E8%AE%B8%E5%88%86%E4%BA%AB%E4%B8%80%E4%BA%9B%E4%BD%BF%E7%94%A8%E4%BF%A1%E6%81%AF%EF%BC%8C%E5%9C%A8%E8%BF%99%E9%87%8C%E5%8F%AF%E4%BB%A5%E5%85%8D%E8%B4%B9%E7%94%B3%E8%AF%B7%E4%B8%80%E4%B8%AAkey%EF%BC%8C%E4%BD%86%E9%9C%80%E8%A6%81%E5%AE%9A%E6%9C%9F%E8%81%94%E7%BD%91%E6%BF%80%E6%B4%BB%E3%80%82">https://my.jrebel.com/，是JRebel的一个社区计划，会要求你允许分享一些使用信息，在这里可以免费申请一个key，但需要定期联网激活。</a></p>
<p>JRebel对各种IDE都有相应的插件，使用起来非常方便，具体的信息可以查看<a href="http://zeroturnaround.com/software/jrebel/learn/%E3%80%82%E9%80%89%E6%8B%A9JRebel">http://zeroturnaround.com/software/jrebel/learn/。选择JRebel</a> monitor的项目，并在Tomcat server中配置使用即可。启动Tomcat后可以看到JRebel的信息，例如</p>
<pre class="lang:default decode:true">2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  #############################################################
2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  JRebel Agent 6.1.2 (201504061000)
2015-04-30 10:26:45 JRebel:  (c) Copyright ZeroTurnaround AS, Estonia, Tartu.
2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  Over the last 6 days JRebel prevented
2015-04-30 10:26:45 JRebel:  at least 166 redeploys/restarts saving you about 6.7 hours.
2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  Licensed to Mingshan Lei (using myJRebel).
2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  
2015-04-30 10:26:45 JRebel:  #############################################################
2015-04-30 10:26:45 JRebel:</pre>
<p>使用效果确实非常好，JRebel支持许多框架，常用的Spring、myBatis、Struts等等，可以monitor这些框架的配置文件，修改之后会在控制台显示提示信息，Reload class或者Reload SQL map等，确实可以节约许多用于部署的时间。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>JS new Date in firefox</title>
    <url>/posts/618c536b/</url>
    <content><![CDATA[<p>JavaScript的new Date()，传入格式化日期参数，在Firefox中会比较严格，例如以下代码</p>
<pre class="lang:default decode:true">var date = new Date("2015-4-30");</pre>
<p>在Chrome下运行成功，在Firefox下则是“Invalid Date”。</p>
<p>显然以下代码才是标准的格式</p>
<pre class="lang:default decode:true ">var date = new Date("2015-04-30");</pre>
<p>或者</p>
<pre class="lang:default decode:true ">var date = new Date("2015/4/30");</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title>查看Linux版本号</title>
    <url>/posts/3718ad5/</url>
    <content><![CDATA[<p>查看内核版本号</p>
<pre class="lang:default decode:true ">cat /proc/version
Linux version 3.2.0-29-generic (buildd@allspice) (gcc version 4.6.3 (Ubuntu/Linaro 4.6.3-1ubuntu5) ) #46-Ubuntu SMP Fri Jul 27 17:03:23 UTC 2012</pre>
<pre class="lang:default decode:true ">uname -a
Linux 3.2.0-29-generic #46-Ubuntu SMP Fri Jul 27 17:03:23 UTC 2012 x86_64 x86_64 x86_64 GNU/Linux</pre>
<p>查看Linux发行版的相关信息</p>
<pre class="lang:default decode:true ">lsb_release-a
No LSB modules are available.
Distributor ID:    Ubuntu
Description:    Ubuntu 14.04.2 LTS
Release:    14.04
Codename:    trusty
</pre>
<pre class="lang:default decode:true ">cat /etc/issue
Ubuntu 14.04.2 LTS \n \l

</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>To Liu</title>
    <url>/posts/705d8519/</url>
    <content><![CDATA[<p>Liu Xi:<br>You will never know how many time I met with you in my dream, even like last night.<br>I really want to be together with you, just like back in my childhood. You can’t imagine,<br>when I was really bold enough to say your name in front of the class and our teacher. I<br>know what your really name is, of course I know. I can’t just mention your really name any<br>more. I’m so sorry. Even in my dream, that’s just one day.I ran after you, I know your face,<br>it’s still like 20 years ago. I really wish you could stay with me for a little longer. But<br>I can’t find you in the end and I was back at my college.</p>
<p>Still like the past, if I could choose again, I would choose to stay with you all. It’s not<br>my choise, and I could not blame my father. And now, I know you are married, you have a happy<br>life. And I know it’s better that way than with me.</p>
<p>I wish I could meet you again in my dream.</p>
<p>Best Wishes<br>Farewell</p>
<p>Yours,<br>Lei</p>
<p>2015/5/21</p>
<span id="more"></span>

<p>After so long time, I’m back here. And I know, deeply in my heart, it’s you. It’s pure emotion about you.</p>
<p>2016/3/8</p>
]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>Gradle执行外部命令</title>
    <url>/posts/8d22131f/</url>
    <content><![CDATA[<p>在Gradle的官方网站，学习的话首要看的是User Guide，其次就是<a href="http://gradle.org/docs/current/dsl/index.html">DSL Reference</a>，我觉得后者其实更加重要，前者的内容比较基础，示例也比较精简，所以推荐到DSL里去看示例。</p>
<p>例如关于任务类型Copy和Exec的介绍。</p>
<pre class="lang:default decode:true ">task stopTomcat(type:Exec) {
  workingDir '../tomcat/bin'

  //on windows:
  commandLine 'cmd', '/c', 'stop.bat'

  //on linux
  commandLine './stop.sh'

  //store the output instead of printing to the console:
  standardOutput = new ByteArrayOutputStream()

  //extension method stopTomcat.output() can be used to obtain the output:
  ext.output = {
    return standardOutput.toString()
  }
}
</pre>
<p>这个示例就很好的介绍了在Gradle中如何执行外部命令。</p>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>Gradle Check OS</title>
    <url>/posts/52e12c32/</url>
    <content><![CDATA[<p>最近使用Gradle来构建一个Spring Project，相比于传统的maven，Gradle确实有不少优点，但由于Gradle是基于Groovy语音，初用起来还是有许多不熟悉的地方，其实在简单的使用时，IDE会帮我们完成build.gradle中大多数的内容，我们也就可以直接完成构建构成了，再加上我的项目使用了Spring-boot，加上Gradle插件后，并不需要自己去写太多的脚本。总之，即使你没接触过maven，Gradle也是很容易使用和上手的。</p>
<p>今天遇到的一个问题，就是在脚本中判断你当前使用的操作系统，因为我这里要设置Tomcat的路径，在windows和Linux之间还是有很大区别的，基本方法如下：</p>
<p>利用ant</p>
<pre class="lang:default decode:true ">ant.condition(property: "os", value: "windows") { os(family: "windows") }
ant.condition(property: "os", value: "unix"   ) { os(family: "unix")    }

task checkOS &lt;&lt; {
    switch(ant.properties.os){
        case 'windows':
            println 'This is windows.'
            break
        case 'unix':
            println 'This is unix.'
            break
    }
}</pre>
<pre class="lang:default decode:true ">import org.apache.tools.ant.taskdefs.condition.Os
task checkWin() &lt;&lt; {
    if (Os.isFamily(Os.FAMILY_WINDOWS)) {
        println "WINDOWS "
    }
}</pre>
<p>利用系统属性</p>
<pre class="lang:default decode:true ">task checkOS &lt;&lt; {
    if (System.properties['os.name'].toLowerCase().contains('windows')) {
        println "it's Windows"
    } else {
        println "it's not Windows"
    }
}</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring mvc无法处理put参数的问题</title>
    <url>/posts/4ec18d47/</url>
    <content><![CDATA[<p>最近在用Spring MVC做一个Restful的Web Service，在HTTP的各类method中，除了非常常用的GET和POST之外，还有PUT、DELETE、PATCH等可以使用。这次遇到问题的是PUT方法，在REST风格中，PUT一般表示对原有资源的修改，但是在CLIENT端编程发出PUT请求后，却总是会遇到400错误，在用另外一个REST测试工具（IDEA中集成）的时候却一切正常。</p>
<p>分析了一下原因，发现几点：</p>
<span id="more"></span>
<ol>
<li><p> 使用的测试工具在发出PUT请求时，参数是带在url尾部的，而不是放在body中，类似于/users/123?name=123&amp;gender=456这样的形式，Spring mvc在处理这种形式的PUT请求时是没有问题的。</p>
</li>
<li><p> 在编写Client的过程中，发送HTTP PUT请求的时候，一般会把参数放入Request Body中，以key:value的格式发送，本质上是json string的格式，此时，在Spring mvc中，通过注解@RequestParam和@ModelAttribute都不能得到请求数据，问题的原因不在Spring，即使使用原始Servlet的request.getParameter也是得不到数据的。<br>解决方法主要有两种：</p>
</li>
<li><p> Spring mvc中处理参数时，改用注解@RequestBody，这里得到的是请求字符串，需要自己进行转换，得到对应的参数信息，Spring这里也提供了对应的转换方法，处理起来并不复杂。</p>
</li>
<li><p> 自己增加一个filter，来专门处理HTTP中的PUT请求，这里建议参考<a href="http://www.360doc.com/content/14/0306/17/15700330_358288127.shtml">该文章</a>。关键配置部分如下：</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;filter&gt;</span><br><span class="line">  &lt;filter-name&gt;httpPutFormFilter&lt;/filter-name&gt;</span><br><span class="line">  &lt;filter-class&gt;org.springframework.web.filter.HttpPutFormContentFilter&lt;/filter-class&gt;</span><br><span class="line">&lt;/filter&gt;</span><br><span class="line">&lt;filter-mapping&gt;</span><br><span class="line">  &lt;filter-name&gt;httpPutFormFilter&lt;/filter-name&gt;</span><br><span class="line">  &lt;url-pattern&gt;/*&lt;/url-pattern&gt;</span><br><span class="line">&lt;/filter-mapping&gt;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title>Gradle tomcat相关脚本</title>
    <url>/posts/8b16ca12/</url>
    <content><![CDATA[<p>初用Gradle，也学习了不少东西，相比于之前的maven（虽然用的不多），但还是感受到了Gradle的许多特点和强大之处。除了常规的添加一些依赖，也尝试着自己写一些脚本。下面的跟tomcat相关的用例，主要用于部署测试环境，也借鉴了他人的一些思路，分享出来。</p>
<pre class="lang:default decode:true ">// deploy to local tomcat server

// All extra properties must be defined through the "ext" namespace.
ext.tomcatHome = System.getenv()["CATALINA_HOME"]
ext.tomcatBin = tomcatHome + '/bin'
ext.tomcatStart = tomcatBin + '/startup'
ext.tomcatStop = tomcatBin + '/shutdown'
ext.tomcatWebapps = tomcatHome + '/webapps'

ant.condition(property: "os", value: "windows") { os(family: "windows") }
ant.condition(property: "os", value: "unix"   ) { os(family: "unix")    }

task checkTomcat &lt;&lt; {
    if (tomcatHome == null)
        throw new RuntimeException("Could not get TOMCAT home, please set CATALINA_HOME env virable first!")
    switch(ant.properties.os){
        case 'windows':
            println 'Running on windows.'
            tomcatStart += '.bat'
            tomcatStop += '.bat'
            break
        case 'unix':
            println 'Running on unix.'
            tomcatStart += '.sh'
            tomcatStop += '.sh'
            break
    }
    println "Using CATALINA_HOME: ${tomcatHome}"
    println "Using Tomcat start cmd: ${tomcatStart}"
    println "Using Tomcat stop cmd: ${tomcatStop}"
}

task deployLocal &lt;&lt; {
    println "copy war from ${buildDir}/libs into ${tomcatWebapps}"
    copy{
        from "${buildDir}/libs"
        into "${tomcatWebapps}"
        include '*.war'
    }
    //println "start tomcat !"
    //startTomcat.execute()
}

deployLocal.dependsOn checkTomcat

task startTomcat &lt;&lt; {
    exec {
        executable tomcatStart
    }
    println 'Start Tomcat server.'
    //store the output instead of printing to the console:
    standardOutput = new ByteArrayOutputStream()

    //extension method stopTomcat.output() can be used to obtain the output:
    ext.output = {
        return standardOutput.toString()
    }
    println 'Done.'
}

startTomcat.dependsOn checkTomcat

task stopTomcat &lt;&lt; {
    exec {
        executable tomcatStop
    }
    println 'Shutting down Tomcat server.'

    //store the output instead of printing to the console:
    standardOutput = new ByteArrayOutputStream()
    //extension method stopTomcat.output() can be used to obtain the output:
    ext.output = {
        return standardOutput.toString()
    }
    println 'Done.'
}

stopTomcat.dependsOn checkTomcat
</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>我的PSN ID</title>
    <url>/posts/c3c97857/</url>
    <content><![CDATA[<p>我的psn奖杯卡<br><img src="https://card.psnprofiles.com/2/lmshlms.png"></p>
<p>我的psn id是lmshlms，港服，欢迎大家加好友。</p>
]]></content>
      <categories>
        <category>游戏</category>
      </categories>
      <tags>
        <tag>Game</tag>
        <tag>PS4</tag>
      </tags>
  </entry>
  <entry>
    <title>PUT POST PATCH in HTTP</title>
    <url>/posts/8d3903c6/</url>
    <content><![CDATA[<p>In the <a href="http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol" title="Hypertext Transfer Protocol">HyperText Transfer Protocol (HTTP)</a>, idempotence and <a href="http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Safe_methods" title="Hypertext Transfer Protocol">safety</a> are the major attributes that separate <a href="http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol#Request_methods" title="Hypertext Transfer Protocol">HTTP verbs</a>.</p>
<p>Of the major HTTP verbs, GET, PUT, and DELETE are idempotent (if implemented according to the standard), but POST is not.<sup id="cite_ref-httpStd-methods_9-1" class="reference"><a href="http://en.wikipedia.org/wiki/Idempotence#cite_note-httpStd-methods-9">[9]</a></sup> These verbs represent very abstract operations in computer science: GET retrieves a resource; PUT stores content at a resource; and DELETE eliminates a resource. As in the example above, reading data usually has no side effects, so it is idempotent (in fact nullipotent). Storing a given set of content is usually idempotent, as the final value stored remains the same after each execution. And deleting something is generally idempotent, as the end result is always the absence of the thing deleted.</p>
<p>参考</p>
<p><a href="http://stackoverflow.com/questions/630453/put-vs-post-in-rest">PUT vs POST in REST</a></p>
<p><a href="http://en.wikipedia.org/wiki/Idempotence">Idempotence wiki</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>develop</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title>mybatis传入类型为Long的处理</title>
    <url>/posts/120944f4/</url>
    <content><![CDATA[<p>mybatis中如果传入类型为Long，与其他一些基本类型例如int，String的处理是不一样的，参数需要统一使用#{_parameter}，而不论你传入参数的名称是什么。</p>
<p>例如：</p>
<pre class="lang:default decode:true ">&lt;select id="getUser" parameterType="java.lang.Long" resultType="com.test.User"&gt;
    SELECT * from user
    &lt;if test = "accountId!=null"&gt;
        WHERE accountId = #{_parameter}
    &lt;/if&gt;  
&lt;/select&gt;</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>12306 AND Apache geode</title>
    <url>/posts/52302006/</url>
    <content><![CDATA[<p><a href="http://geode.incubator.apache.org/">http://geode.incubator.apache.org/</a></p>
<p>前段时间听说了分布式内存数据库Apache geode开源的消息，本来对该数据库还不甚了解，但是发现它和12306有着不少关系，不仅被采用而且经受住了重重考验，所以觉得还是有必要关注一下，先留下一篇文章吧，以后来完善。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>The measure of a man is what he does with power.</title>
    <url>/posts/b228e31a/</url>
    <content><![CDATA[<h1 id="The-measure-of-a-man-is-what-he-does-with-power"><a href="#The-measure-of-a-man-is-what-he-does-with-power" class="headerlink" title="The measure of a man is what he does with power."></a>The measure of a man is what he does with power.</h1>]]></content>
      <categories>
        <category>日志</category>
      </categories>
  </entry>
  <entry>
    <title>Rest api design</title>
    <url>/posts/ed4e4712/</url>
    <content><![CDATA[<p>最近在进行一个项目，需要设计一个Server，为移动端的client提供REST风格的服务，RESTful API是现在互联网应用程序中使用比较多、也比较成熟的一种设计理念，以HTTP协议为基础，在项目之前，只是简单听说过REST这种理念，并没有很深入的接触，在api的设计过程中，需要遵循一些原则，但是要注意的是RESTful只是一种风格，并不是标准、协议或者强制性的要求。因此，在设计过程中，我也参考了一些文章和资料，学习如何去设计一套合理规范的API。</p>
<p>在初步的设计中，根据之前的工作经验，采用了比较传统的Spring和Hibernate，根据应用的需求，也采用了许多相关技术，例如Spring-data-jpa和Hibernate Validator等，后面会根据一些具体内容进行总结。</p>
<p>下面地址是一个java轻量级restful框架，里面有不少关于RESTful的介绍和文章链接，推荐阅读。</p>
<p><a href="https://github.com/Dreampie/resty">https://github.com/Dreampie/resty</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
  </entry>
  <entry>
    <title>Java中对json的处理</title>
    <url>/posts/8b5e5a5d/</url>
    <content><![CDATA[<p>Java中有不少处理JSON格式数据的类库，在JSON的官网 <a href="http://www.json.org/">http://www.json.org/</a> 下面对应的各个语言编解码库，Java就有20多种可以使用的类库。</p>
<p>当然，其中最常使用的是json-lib，也是资格比较老的一个库，网上介绍也很多，<a href="http://json-lib.sourceforge.net/">http://json-lib.sourceforge.net/</a>，但是已经停止更新很久了，<br>最新的版本还是基于JDK1.5的，最后更新日期是2010年的12月。在Struts2中返回JSON格式的数据时，默认使用的就是json-lib。<br>但是总体上来说，现在开发程序还是不建议使用json-lib，毕竟有点太古老了。<br>推荐使用的是号称性能最快的JSON处理器Jackson，社区非常活跃，也一直在更新，功能也很强大，<a href="https://github.com/FasterXML/jackson">https://github.com/FasterXML/jackson</a>。</p>
<p>可以发现在许多其他Java开源项目中对JSON的处理都在使用Jackson，例如Spring。</p>
<p>有人专门对比了这两个类库的性能，<br><a href="http://wangym.iteye.com/blog/738933">http://wangym.iteye.com/blog/738933</a></p>
<span id="more"></span>测试总结：
<p>1、显而易见，无论是哪种形式的转换，Jackson &gt; Gson &gt; Json-lib。<br>Jackson的处理能力甚至高出Json-lib有10倍左右<br>2、JSON-lib似乎已经停止更新，最新的版本也是基于JDK15，而Jackson的社区则较为活跃；<br>3、在测试性能的同时，又以人肉方式对这三个类库转换的正确性 进行了检查 ，三者均达100%正确 ；<br>4、JSON-lib在转换诸如Date类型时较为累赘，如以下是两者的转换结果：<br>JSON-lib：<br>{“brithday”:{“date”:17,”day”:2,”hours”:9,”minutes”:24,”month”:7,”seconds”:26,”time”:1282008266398,”timezoneOffset”:-480,”year”:110}}<br>Jackson：<br>{“brithday”:1282008123101}<br>5、JSON-lib依赖commons系列的包及 ezmorph包共 5个，而Jackson除自身的以外只依赖于commons-logging<br>6、Jackson提供完整基于节点的Tree Model，以及完整的OJM数据绑定功能。<!--more--><!--more--></p>
<p>经过几项试验和测试，发现Jackson确实功能很强大，推荐还是默认用Jackson来处理JSON，算是目前Java中比较优秀的JSON处理库。</p>
<p>简单的使用方法：<br><a href="https://github.com/FasterXML/jackson-databind/">https://github.com/FasterXML/jackson-databind/</a></p>
<p>即使是处理比较复杂的JavaBean，嵌套多层并且包含自定义类，以及List等的类Profile，也可以轻松处理，不需要用户过多的配置。当然其他更强大的功能还有待以后发掘。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript的模块化编程</title>
    <url>/posts/1ce136d4/</url>
    <content><![CDATA[<p><a href="http://www.ruanyifeng.com/blog/2012/10/asynchronous_module_definition.html">http://www.ruanyifeng.com/blog/2 … ule_definition.html</a><br>为什么讲到JS的模块化编程，也是最近在应用Echarts图标库需要面对的一个问题。<br>可以参考Echarts引入的方法：<br><a href="http://echarts.baidu.com/doc/doc.html#">http://echarts.baidu.com/doc/doc.html#</a>引入ECharts<br>在之前的开发中，为了使用简便，直接采用第三种引入单文件的方式，比较简单，<br>&lt;script src=”js/echarts-all.js”&gt;&lt;/script&gt;<br>就可以了，这样就引入了Echarts所有的图标和地图数据，这个文件是900KB，也就是说，<br>无论你在页面中使用几种图表，都需要加载接近1MB大小的JS库文件，效率还是比较低下的。<br>比较推荐的方法是参考JS的模块化编程和AMD规范，当然使用模块化编程主要不是为了解决<br>加载过多的问题，对于代码的规范和质量都有比较大的帮助。<br>Echarts本身使用了require.js，在前台开发中也可以尝试自己使用require.js。<br>简单介绍：<a href="http://www.ruanyifeng.com/blog/2012/11/require_js.html">http://www.ruanyifeng.com/blog/2012/11/require_js.html</a><br>官网：<a href="http://requirejs.org/">http://requirejs.org/</a></p>
<p>建议推荐一个SeaJS 的 CMD 规范，与 AMD 非常类似，在国内的影响力非常大，也非常易于使用，是国人开发的，在 github 上的更新、互动非常频繁。<br><a href="http://seajs.org/">http://seajs.org</a><br><a href="https://github.com/seajs/seajs">https://github.com/seajs/seajs</a></p>
<p>两个的区别<br><a href="http://www.zhihu.com/question/20351507/answer/14859415">http://www.zhihu.com/question/20351507/answer/14859415</a></p>
<p><a href="http://segmentfault.com/a/1190000000733959">http://segmentfault.com/a/1190000000733959</a></p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB的数据库复制</title>
    <url>/posts/b176fc0/</url>
    <content><![CDATA[<p>在MongoDB的客户端可以使用如下命令：<br>db.copyDatabase(“abc”, “abc-tmp”, “localhost”)<br>数据库文件较大的话会需要一段时间。</p>
<p>1，复制数据库，使用copyDatabase命令完成复制数据库，<br>格式:copyDatabase(fromdb,todb,fromhost[,username,password])<br>fromdb：源数据库名称<br>todb：目标数据库名称<br>fromhost：源数据库地址，本地和远程都可以<br>username：远程数据库用户名<br>password：远程数据密码<br>例子：将本地db2库复制本地，并重命名db1<br>&gt; db.copyDatabase(“db2”,”db1”,”localhost”)<span id="more"></span><br>2，刷新磁盘：将内存中尚未写入磁盘的信息写入磁盘，并锁住对数据库更新的操作，但读操作可以使用，使用runCommand命令,这个命令只能在admin库上执行<br>格式：db.runCommand({fsync:1,async:true})<br>async：是否异步执行<br>lock:1 锁定数据库</p>
<p>3，数据压缩：mongodb的存储结构采用了预分配的机制，长期不断的操作，会留下太多的的碎片，从而导致数据库系统越来越慢。<br>repairDatabase命令是mongodb内置的一个方法，它会扫描数据库中的所有数据，并将通过导入/导出来重新整理数据集合，将碎片清理干净<br>现在看压缩前和压缩后的对比数据，如下所示：<br>PRIMARY&gt; db.t1.storageSize()<br>65232896<br>PRIMARY&gt; db.t1.totalSize()<br>81470432<br>PRIMARY&gt; db.repairDatabase()<br>{ “ok” : 1 }<br>PRIMARY&gt; db.t1.storageSize()<br>65232896<br>PRIMARY&gt; db.t1.totalSize()<br>79851584</p>
<p>4，当然也支持复制Collection，与复制Database类似。</p>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB的POJO映射</title>
    <url>/posts/b327357c/</url>
    <content><![CDATA[<p>在MongoDB数据库的Java程序开发过程中，使用了官方支持的POJO映射Morphia<br><a href="https://github.com/mongodb/morphia/wiki">https://github.com/mongodb/morphia/wiki</a>。</p>
<p>其作用，简而言之，就是完成Java Bean对象与MongoDB数据库中一条记录的映射，大家在Entity中看到的Profile就是这样一个POJO，<br>Profile中嵌套了一些子类，比较容易理解，Morphia的所有映射都可以通过注解来完成，非常简单易用，可以查看上面wiki文档中的说明。<br>另外，Morphia提供了一个基本的DAO类，org.mongodb.morphia.dao.BasicDAO&lt;T,K&gt;<br>详细信息可以查看链接<a href="https://rawgit.com/wiki/mongodb/morphia/javadoc/0.108/apidocs/index.html">https://rawgit.com/wiki/mongodb/morphia/javadoc/0.108/apidocs/index.html</a></p>
<p>该类支持基本的CRUD操作，查询也支持各种查询条件，不过在返回结果这边可定制性较弱，通常都是返回整个的POJO类的List，属于粗粒度吧。<br>BasicDAO从根本上都是对mongo-java-driver中一些api的封装，如果需要更全面的功能的话可以选用底层driver，当然这样就是直接跟MongoDB中的BSON打交道了，<br>也就用不上POJO了。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Java</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL FIND_IN_SET Usage</title>
    <url>/posts/39136b96/</url>
    <content><![CDATA[<p>MySQL手册中FIND_IN_SET函数的语法:</p>
<p>FIND_IN_SET(str, strlist)</p>
<p>Returns a value in the range of 1 to <em><code>N</code></em> if the string <em><code>str</code></em> is in the string list <em><code>strlist</code></em> consisting of <em><code>N</code></em> substrings. A string list is a string composed of substrings separated by <span class="quote">“<span class="quote"><code>,</code></span>”</span> characters. If the first argument is a constant string and the second is a column of type <a href="http://dev.mysql.com/doc/refman/5.7/en/set.html" title="11.4.5 The SET Type"><code>SET</code></a>, the <a href="http://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_find-in-set"><code>FIND_IN_SET()</code></a> function is optimized to use bit arithmetic. Returns <code>0</code> if <em><code>str</code></em> is not in <em><code>strlist</code></em> or if <em><code>strlist</code></em> is the empty string. Returns <code>NULL</code> if either argument is <code>NULL</code>. This function does not work properly if the first argument contains a comma (<span class="quote">“<span class="quote"><code>,</code></span>”</span>) character.</p>
<p>假如字符串str 在由N 子链组成的字符串列表strlist 中，则返回值的范围在 1 到 N 之间。<br>一个字符串列表就是一个由一些被‘,’符号分开的子链组成的字符串。如果第一个参数是一个常数字符串，而第二个是type SET列，则   FIND_IN_SET() 函数被优化，使用比特计算。<br>如果str不在strlist 或strlist 为空字符串，则返回值为 0 。如任意一个参数为NULL，则返回值为 NULL。这个函数在第一个参数包含一个逗号(‘,’)时将无法正常运行。<span id="more"></span></p>
<p>例如：</p>
<pre class="lang:default decode:true ">mysql&gt; SELECT FIND_IN_SET('b','a,b,c,d');
        -&gt; 2</pre>
<p><a href="http://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_substring-index"><code>SUBSTRING_INDEX(_&lt;code&gt;str</code><em>,</em><code>delim</code><em>,</em><code>count</code>_)</code></a></p>
<p>Returns the substring from string <em><code>str</code></em> before <em><code>count</code></em> occurrences of the delimiter <em><code>delim</code></em>. If <em><code>count</code></em> is positive, everything to the left of the final delimiter (counting from the left) is returned. If <em><code>count</code></em> is negative, everything to the right of the final delimiter (counting from the right) is returned. <a href="http://dev.mysql.com/doc/refman/5.7/en/string-functions.html#function_substring-index"><code>SUBSTRING_INDEX()</code></a> performs a case-sensitive match when searching for <em><code>delim</code></em>.</p>
<pre class="lang:default decode:true ">mysql&gt; SELECT SUBSTRING_INDEX('www.mysql.com', '.', 2);
        -&gt; 'www.mysql'
mysql&gt; SELECT SUBSTRING_INDEX('www.mysql.com', '.', -2);
        -&gt; 'mysql.com'</pre>
<p>This function is multibyte safe.</p>
<p>&nbsp;</p>
<p>MySQL中使用WHERE IN进行条件查询的时候，一般情况下，查询的结果和IN中值的顺序并不一致。</p>
<p>有两种方式可以对IN查询的结果进行排序。一种是ORDER BY FIND_IN_SET，另外一种是ORDER BY SUBSTRING_INDEX。</p>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu, Debian中iptables规则保存和重启自动加载</title>
    <url>/posts/7892b79a/</url>
    <content><![CDATA[<p>在Debian中iptables命令输完之后会立刻生效，但重启之后配置就会消失，Debian提供了一个iptables-save程序快速保存配置。</p>
<p>通过iptables-save和iptables-restore可以让debian自动保存并在开机时自动加载iptables规则。</p>
<h3 id="1、将iptables配置保存到-etc-iptables，这个文件名可以自己定义，与下面的配置一致即可"><a href="#1、将iptables配置保存到-etc-iptables，这个文件名可以自己定义，与下面的配置一致即可" class="headerlink" title="1、将iptables配置保存到/etc/iptables，这个文件名可以自己定义，与下面的配置一致即可"></a>1、将iptables配置保存到/etc/iptables，这个文件名可以自己定义，与下面的配置一致即可</h3><pre class="lang:default decode:true">iptables-save &gt; /etc/iptables</pre>

<h3 id="2、创建并编辑自启动配置文件，内容为启动网络时恢复iptables配置"><a href="#2、创建并编辑自启动配置文件，内容为启动网络时恢复iptables配置" class="headerlink" title="2、创建并编辑自启动配置文件，内容为启动网络时恢复iptables配置"></a>2、创建并编辑自启动配置文件，内容为启动网络时恢复iptables配置</h3><pre class="lang:default decode:true">sudo vim /etc/network/if-pre-up.d/iptables</pre>
<p>文件内容为：</p>
<pre class="lang:default decode:true ">#!/bin/sh
/sbin/iptables-restore &lt; /etc/iptables</pre>
<p>保存并退出。</p>
<p>之后系统每次启动时iptables就可以自动加载规则了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Debian</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB--mongoimport loses connection when importing big files</title>
    <url>/posts/33725cfb/</url>
    <content><![CDATA[<p>今天在新版本下进行MongoDB数据导入的时候，遇到了这样一个问题，例如使用如下命令：</p>
<pre class="lang:default decode:true">mongoimport -d test -c profile users.dat</pre>
<p>在之前使用过几次这样的导入方法都没有问题，但这次却提示：</p>
<pre class="lang:default decode:true">2016-01-20T10:05:25.228+0100    connected to: localhost
2016-01-20T10:05:25.735+0100    error inserting documents: lost connection to server
2016-01-20T10:05:25.735+0100    Failed: lost connection to server
2016-01-20T10:05:25.735+0100    imported 0 documents</pre>
<p>查看MongoDB的Log，发现出现异常的原因，如下：</p>
<pre class="lang:default decode:true ">2016-01-20T11:26:39.103+0800 I -        [conn17] Assertion: 10334:BSONObj size: 33562755 (0x2002083) is invalid. Size must be between 0 and 16793600(16MB) First element: insert: "Profile"</pre>
<p>搜索解决方案，发现这是mongo工具包在新版本下的小bug，mongorestore和mongoimport都有一样的问题，官方说明可以参考<a href="https://jira.mongodb.org/browse/TOOLS-939">https://jira.mongodb.org/browse/TOOLS-939</a>。</p>
<p>原因就是bulk write api，原来的api中批量写入的batch size最大是32MB，现在已经变为16MB了。在导入或还原数据的时候，指定选项 –batchSize=1000，指定一个较小的值即可，默认是10000。</p>
<p>参考：</p>
<ol>
<li> <a href="http://stackoverflow.com/questions/33475505/mongodb-mongoimport-loses-connection-when-importing-big-files">http://stackoverflow.com/questions/33475505/mongodb-mongoimport-loses-connection-when-importing-big-files</a></li>
<li> <a href="https://jira.mongodb.org/browse/TOOLS-939">https://jira.mongodb.org/browse/TOOLS-939</a></li>
<li> <a href="http://chenzhou123520.iteye.com/blog/1641319">http://chenzhou123520.iteye.com/blog/1641319</a></li>
</ol>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Ubuntu14.04使用ppa源安装PHP-7</title>
    <url>/posts/bf78be32/</url>
    <content><![CDATA[<p>在Ubuntu 14.04下安装PHP除了可以直接从官网下载源码编译安装，也可以PPA源安装。如果读者对编译安装的各种选项和配置方法不是很熟悉的话，则推荐使用这种方法快速安装。</p>
<p>在安装的时候，这里选择的是比较流行的一位个人作者维护的一个PPA源，具体的使用方法如下：</p>
<ol>
<li><p> 添加源。</p>
<pre class="lang:default decode:true">sudo LC_ALL=en_US.UTF-8 add-apt-repository ppa:ondrej/php</pre></li>
<li><p> 如果有之前使用apt-get方法安装的PHP，先删除后再安装PHP7。</p>
<pre class="lang:default decode:true">sudo apt-get update
sudo apt-get purge php5-common -y
sudo apt-get install php7.0 php7.0-fpm php7.0-mysql -y
sudo apt-get --purge autoremove -y</pre></li>
<li><p> 如果使用nginx，注意以下配置和相应的用户权限。</p>
<pre class="lang:default decode:true ">fastcgi_pass unix:/var/run/php/php7.0-fpm.sock;</pre></li>
</ol>
<p>参考：</p>
<ul>
<li>  <a href="https://www.digitalocean.com/community/tutorials/how-to-upgrade-to-php-7-on-ubuntu-14-04">How To Upgrade to PHP 7 on Ubuntu 14.04</a></li>
<li>  <a href="http://askubuntu.com/questions/705880/how-to-install-php-7">How to install PHP 7?</a></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>SonarQube-代码质量管理平台的安装</title>
    <url>/posts/25a76de9/</url>
    <content><![CDATA[<h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><p>JDK，数据库（以下以MySQL为例），操作系统支持Linux和Windows（文章以Linux Ubuntu 14.04为例）。</p>
<h2 id="数据库配置"><a href="#数据库配置" class="headerlink" title="数据库配置"></a>数据库配置</h2><p>终端进入mysql-client：</p>
<pre class="lang:default decode:true ">mysql -u root -p</pre>
<p>执行以下SQL语句建立数据库和相关用户：</p>
<pre class="lang:default decode:true">CREATE DATABASE sonar CHARACTER SET utf8 COLLATE utf8_general_ci;
CREATE USER 'sonar' IDENTIFIED BY 'sonar';
GRANT ALL ON sonar.* TO 'sonar'@'%' IDENTIFIED BY 'sonar';
GRANT ALL ON sonar.* TO 'sonar'@'localhost' IDENTIFIED BY 'sonar';
FLUSH PRIVILEGES;</pre>
<span id="more"></span>

<h2 id="下载并解压SonarQube安装包"><a href="#下载并解压SonarQube安装包" class="headerlink" title="下载并解压SonarQube安装包"></a>下载并解压SonarQube安装包</h2><p>在<a href="http://www.sonarqube.org/downloads/">SonarQube官网</a>获取最新的下载地址。</p>
<pre class="lang:default decode:true ">wget https://sonarsource.bintray.com/Distribution/sonarqube/sonarqube-5.3.zip
unzip sonarqube-5.3.zip
sudo mv sonarqube-5.3 /usr/local/sonar</pre>

<h2 id="编辑配置文件sonar-properties"><a href="#编辑配置文件sonar-properties" class="headerlink" title="编辑配置文件sonar.properties"></a>编辑配置文件sonar.properties</h2><p>编辑conf目录下的sonar.properties，主要修改数据库配置和web server配置，取消相应行的注释并编辑为对应的值。</p>
<pre class="lang:default decode:true ">sonar.jdbc.username=sonar
sonar.jdbc.password=sonar
sonar.jdbc.url=jdbc:mysql://localhost:3306/sonar?useUnicode=true&amp;characterEncoding=utf8&amp;rewriteBatchedStatements=true&amp;useConfigs=maxPerformance
</pre>
<p>以下的web server配置允许以下地址访问 <a href="http://127.0.0.1:9000/sonar">http://127.0.0.1:9000/sonar</a></p>
<pre class="lang:default decode:true ">sonar.web.host=127.0.0.1 #默认是0.0.0.0，绑定本机所有ip地址
sonar.web.context=/sonar #默认是空
sonar.web.port=9000</pre>

<h2 id="配置Service运行"><a href="#配置Service运行" class="headerlink" title="配置Service运行"></a>配置Service运行</h2><p>参考<a href="http://docs.sonarqube.org/display/SONAR/Running+SonarQube+as+a+Service+on+Linux">官方文档</a></p>
<p>新建/etc/init.d/sonar文件并编辑如下。</p>
<pre class="lang:default decode:true ">#!/bin/sh
#
# rc file for SonarQube
#
# chkconfig: 345 96 10
# description: SonarQube system (www.sonarsource.org)
#
### BEGIN INIT INFO
# Provides: sonar
# Required-Start: $network
# Required-Stop: $network
# Default-Start: 3 4 5
# Default-Stop: 0 1 2 6
# Short-Description: SonarQube system (www.sonarsource.org)
# Description: SonarQube system (www.sonarsource.org)
### END INIT INFO

/usr/bin/sonar $*</pre>
<p>运行以下命令安装服务并运行，注意bin子目录的32位64位区别。</p>
<pre class="lang:default decode:true">sudo ln -s $SONAR_HOME/bin/linux-x86-64/sonar.sh /usr/bin/sonar
sudo chmod 755 /etc/init.d/sonar
sudo update-rc.d sonar defaults
sudo service sonar start</pre>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SonarQube</tag>
      </tags>
  </entry>
  <entry>
    <title>Gradle与SonarQube的应用</title>
    <url>/posts/68467f3f/</url>
    <content><![CDATA[<p>首先是<a href="http://docs.sonarqube.org/display/SONAR/Analyzing+with+SonarQube+Scanner+for+Gradle">官方文档</a>。这里使用的是新的Gradle SonarQube plugin，注意与以往的Gradle Sonar和Runner插件区分，官方不推荐使用旧插件。</p>
<p><a href="https://plugins.gradle.org/plugin/org.sonarqube">SonarQube插件说明</a></p>
<p>Github示例可以参考<a href="https://github.com/SonarSource/sonar-examples/tree/master/projects/languages/java/gradle/java-gradle-simple">java-gradle-simple</a>，注意里面build.gradle脚本的写法，以及如何执行SonarQube的Task。</p>
<p>&nbsp;</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Gradle</tag>
        <tag>SonarQube</tag>
      </tags>
  </entry>
  <entry>
    <title>Jenkins SonarQube的搭配使用</title>
    <url>/posts/7a61ee38/</url>
    <content><![CDATA[<p>Jenkins在Ubuntu环境下的安装配置都比较简单，在安装好Java JDK之后，使用</p>
<pre class="">sudo apt-get install jenkins</pre>
<p>即可安装。因为没有用到后台数据库，配置过程一般就是配置端口号，以及Nginx或Apache server的代理即可。</p>
<p>详细方法可以参考<a href="https://wiki.jenkins-ci.org/display/JENKINS/Installing+Jenkins+on+Ubuntu">官方安装指南</a>。</p>
<p>接下来就是与代码质量分析平台SonarQube的结合使用，前面已经说明了SonarQube的安装，然后就是利用Jenkins在进行持续集成的过程中，进行代码质量分析、代码覆盖率分析，并将相关数据和报告通知给SonarQube。</p>
<p>在Jenkins中的“系统管理”-“管理插件”中搜索安装SonarQube Plugin，因为我使用的是Java Gradle工程和JaCoCo测试报告，所以之前也安装了Gradle Plugin和JaCoCo Plugin，这里大家可以根据自己具体的项目选择。<span id="more"></span></p>
<p>在安装好SonarQube Plugin之后，记得在系统设置中配置SonarQube服务器的相关信息，可以参考下图进行。</p>
<p><a href="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Plugin.jpg"><img src="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Plugin-300x91.jpg" alt="SonarQube Plugin"></a></p>
<p>另外注意配置SonarQube scanner，这里可以选择自动安装，或者选择自己安装的目录位置。</p>
<p><a href="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Runner.jpg"><img src="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Runner-300x51.jpg" alt="SonarQube Runner"></a></p>
<p>服务器配置好之后，然后就是在具体的项目中配置构建过程，选择“增加构建步骤”中的Invoke Standalone SonarQube Analysis，参考下图。</p>
<p><a href="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Analysis.jpg"><img src="http://www.leimingshan.com/wp-content/uploads/2016/03/SonarQube-Analysis-300x131.jpg" alt="SonarQube Analysis"></a></p>
<p>具体的配置如下：</p>
<pre class="lang:default decode:true "># required metadata
sonar.projectKey=pminer:MongoDB-ImportXMLProfile
sonar.projectName=MongoDB-ImportXMLProfile
sonar.projectVersion=1.0

# path to source directories (required)
sonar.sources=src/main/java
# path to test source directories (optional)
sonar.tests=src/test/java

sonar.java.binaries=build/classes

sonar.language=java

#Tells SonarQube where the unit tests execution reports are
sonar.junit.reportsPath=reports/tests

#Tells SonarQube where the unit tests code coverage report is
sonar.jacoco.reportPath=build/jacoco/test.exec

# Encoding of the source files
sonar.sourceEncoding=UTF-8</pre>
<p>注意以上的配置要根据自己具体的项目路径配置。</p>
<p>这样在下次的构建中，就会之前SonarQube的分析任务，并将结果发送给SonarQube服务器，然后访问服务器平台就能看到代码的质量报告。</p>
<p>参考：<a href="http://docs.sonarqube.org/display/PLUG/Code+Coverage+by+Unit+Tests+for+Java+Project">http://docs.sonarqube.org/display/PLUG/Code+Coverage+by+Unit+Tests+for+Java+Project</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>SonarQube</tag>
        <tag>Jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>本站开始启用全站Https</title>
    <url>/posts/cf97a194/</url>
    <content><![CDATA[<p>从今天起本Blog开始启用全站Https。<br>未来的大趋势嘛，哈哈！</p>
<p><img src="https://i.loli.net/2018/09/06/5b90c99433408.jpg" alt="30-021604_546.jpg"></p>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL database character set encoding</title>
    <url>/posts/f528791e/</url>
    <content><![CDATA[<p>使用MySQL的时候很可能遇到字符集编码相关的问题，尤其是涉及到数据和程序中有中文字符的时候，如果不注意，可能遇到乱码或一些其他的错误。</p>
<p>本文详细解释MySQL相关的字符集编码设置和排序规则相关的问题。</p>
<h1 id="MySQL-Server的默认字符集配置"><a href="#MySQL-Server的默认字符集配置" class="headerlink" title="MySQL Server的默认字符集配置"></a>MySQL Server的默认字符集配置</h1><p>在默认安装MySQL的时候，MySQL Server使用的是英文字符集，服务端的默认配置一般是</p>
<p><span style="text-decoration: underline;">character-set-server=latin1</span></p>
<p><span style="text-decoration: underline;">collation-server =latin1_swedish_ci</span></p>
<p>注意latin1字符集是不支持中文的。第一行的character-set当然是指字符集，第二行的collation是指对应该字符集的比较和排序规则。</p>
<p><a href="http://dev.mysql.com/doc/refman/5.7/en/charset-server.html">charset-server参考手册</a><span id="more"></span></p>
<p>通过MySQL命令</p>
<pre class="lang:mysql decode:true">mysql&gt; SHOW VARIABLES LIKE 'character%';</pre>
<p>可以查看当前服务端的默认配置。</p>
<p>如果在新建数据库的时候不指定character-set和collation，那么就会采用以上的服务器端默认值，所以还是推荐大家手动指定。示例如下：</p>
<pre class="lang:mysql decode:true ">CREATE DATABASE mydb
  DEFAULT CHARACTER SET utf8
  DEFAULT COLLATE utf8_general_ci;</pre>
<p>使用utf8和utf8_general_ci是在中英文应用环境下比较常用的一种设置，排序规则还有utf8_unicode_ci，另外还有编码utf8mb4和对应的排序规则，具体区别会在后面的文章说明。<!--more--></p>
<h1 id="修改已有数据库的字符编码"><a href="#修改已有数据库的字符编码" class="headerlink" title="修改已有数据库的字符编码"></a>修改已有数据库的字符编码</h1><p>如果之前已经建立好了数据库，需要修改当前数据库的编码，可以使用ALTER DATABASE命令。</p>
<p>首先查看当前数据库的编码和排序规则；</p>
<pre class="lang:mysql decode:true ">mysql&gt; USE mydb;
Database changed
mysql&gt; SHOW VARIABLES LIKE 'character_set_database';
+------------------------+-------+
| Variable_name          | Value |
+------------------------+-------+
| character_set_database | utf8  |
+------------------------+-------+
1 row in set (0.00 sec)

mysql&gt; mysql&gt; SHOW VARIABLES LIKE 'collation_database';
+--------------------+-----------------+
| Variable_name      | Value           |
+--------------------+-----------------+
| collation_database | utf8_general_ci |
+--------------------+-----------------+
1 row in set (0.01 sec)

mysql&gt; 
</pre>
<p>然后就可以根据情况修改为自己需要的编码设置了；</p>
<pre class="lang:mysql decode:true">mysql&gt; ALTER DATABASE databasename CHARACTER SET utf8 COLLATE utf8_general_ci;</pre>
<p>参考：</p>
<ul>
<li>  <a href="https://dev.mysql.com/doc/refman/5.7/en/charset-database.html">数据库的字符集</a></li>
<li>  修改具体table编码的方法，<a href="https://dev.mysql.com/doc/refman/5.7/en/charset-unicode-upgrading.html">charset-unicode-upgrading参考手册</a>。</li>
</ul>
<h1 id="修改MySQL的服务端配置"><a href="#修改MySQL的服务端配置" class="headerlink" title="修改MySQL的服务端配置"></a>修改MySQL的服务端配置</h1><p>修改my.cnf配置文件可以修改MySQL Server的默认字符集等设置。以配置文件在/etc/my.cnf（可能根据具体安装情况不同）为例，修改以下几项即可：</p>
<pre class="lang:default decode:true">[client]
default-character-set = utf8

[mysql]
default-character-set = utf8

[mysqld]
init-connect = 'SET NAMES utf8'
character-set-server = utf8
collation-server = utf8_unicode_ci</pre>
<p>参考</p>
<ul>
<li>  配置方法：<a href="http://stackoverflow.com/questions/3513773/change-mysql-default-character-set-to-utf-8-in-my-cnf">http://stackoverflow.com/questions/3513773/change-mysql-default-character-set-to-utf-8-in-my-cnf</a></li>
<li>  <a href="https://dev.mysql.com/doc/refman/5.7/en/charset-connection.html">SET NAMES的官方解释</a><br>&nbsp;</li>
</ul>
]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Bug Tracker</title>
    <url>/posts/ca051d68/</url>
    <content><![CDATA[<p>最近在尝试使用一些项目管理工具，之前的文章里提到的代码质量分析工具SonarQube，比较符合使用的期望，效果也不错，还有比较早使用的持续集成工具Jenkins，</p>
<p>然后是缺陷跟踪工具，Bug Tracker System，比较常用的有：</p>
<ol>
<li> Redmine <a href="http://www.redmine.org/">http://www.redmine.org/</a> 网站本身就是Redmine示例。</li>
<li> Mantis <a href="http://www.mantisbt.org/">http://www.mantisbt.org/</a> demo：<a href="http://www.mantisbt.org/bugs/my_view_page.php">http://www.mantisbt.org/bugs/my_view_page.php</a>。</li>
<li> Atlassian JIRA <a href="https://www.atlassian.com/software/jira/">https://www.atlassian.com/software/jira/</a> 应用广泛，有云服务版。</li>
<li> Bugzilla <a href="https://www.bugzilla.org/">https://www.bugzilla.org/</a><br>类似的工具还有许多，可以查看wiki百科汇总 <a href="https://en.wikipedia.org/wiki/Comparison_of_issue-tracking_systems">https://en.wikipedia.org/wiki/Comparison_of_issue-tracking_systems</a>。</li>
</ol>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
  </entry>
  <entry>
    <title>Gradle使用代理服务器</title>
    <url>/posts/4fdca764/</url>
    <content><![CDATA[<p>在国内使用Gradle的时候，由于依赖管理时经常需要从mavenCentral（maven中央仓库）和jCenter中下载lib，速度不稳定，有时还会导致build长时间卡住，有一种方法是使用Gradle的Offline模式，但前提是你已经cache了项目的依赖在本地，不然可能会Build失败，另外就是使用代理服务器，也是一种不错的选择。</p>
<p><strong>在Gradle中使用代理服务器的方法：</strong></p>
<ol>
<li> <strong>使用以下命令行参数指定代理服务器。</strong><pre class="lang:default decode:true">gradle -Dhttp.proxyHost=yourProxy -Dhttp.proxyPort=yourPort -Dhttp.proxyUser=usernameProxy -Dhttp.proxyPassword=yourPassoword</pre>
<span id="more"></span></li>
<li> <strong>修改Gradle用户配置文件。</strong>可以在GRADLE_USER_HOME下新建文件gradle.properties，然后设置代理。GRADLE_USER_HOME的路径一般如下:<br>/home/&lt;username&gt;/.gradle/ (Linux)<br>/Users/&lt;username&gt;/.gradle/ (Mac)<br>C:\Users&amp;lt;username&gt;.gradle\ (Windows)<pre class="lang:default decode:true "># Http Proxy
systemProp.http.proxyHost=www.somehost.org
systemProp.http.proxyPort=8080
systemProp.http.proxyUser=userid
systemProp.http.proxyPassword=password
systemProp.http.nonProxyHosts=*.nonproxyrepos.com|localhost</li>
</ol>
<h1 id="Https-Proxy"><a href="#Https-Proxy" class="headerlink" title="Https Proxy"></a>Https Proxy</h1><p>systemProp.https.proxyHost=<a href="http://www.somehost.org/">www.somehost.org</a><br>systemProp.https.proxyPort=8080<br>systemProp.https.proxyUser=userid<br>systemProp.https.proxyPassword=password<br>systemProp.https.nonProxyHosts=*.nonproxyrepos.com|localhost</pre><br>参考：</p>
<ol>
<li> <a href="https://docs.gradle.org/current/userguide/build_environment.html">https://docs.gradle.org/current/userguide/build_environment.html</a></li>
</ol>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Gradle</tag>
      </tags>
  </entry>
  <entry>
    <title>工作一年的技术成长总结</title>
    <url>/posts/4d806b6d/</url>
    <content><![CDATA[<p>工作一年多以来，学了不少东西，也尝试了许多新东西，也成长了不少，也许只是一个粗略的记录，也希望提醒自己，还是取得了一些成绩吧，但不能骄傲，还有许多不足之处，技术永无止境，还需要更多的努力。</p>
<span id="more"></span>

<p>工作初始，接触的是C语言网络编程和后台编程的项目，承担的是整体系统中的一部分，加上之前对Redis的了解，也比较适合在这里使用，在设计的时候也就用上了。因为的自己负责调研的部分，所以许多都可以自己设计，还是很高兴的，在使用Redis的过程中，也简单分析了Redis的代码，以及在Linux下编程的技巧，包括学习Redis的Makefile，对错误和消息的处理等。使用Redis作为缓存队列，也实现了自己想要的效果，当然这里会有更优的解决方案，但是作为自己在项目中的第一个设计，还是基本满意的。</p>
<p>再后来的项目，大部分的经历就转到Java语言项目和Java Web方面了，也接触了一些项目的框架，修改功能代码等。独当一面的是另外一个基于大数据的演示性项目，将来会把这个搭建在服务器上。这个项目里，我独立完成了项目的Java Web后台设计，使用了包括Spring，Struts，MongoDB，Morphia等技术，独立设计前台HTML和JS等，使用了Bootstrap，Echarts，JQuery，Semantic-ui等。项目的时间比较久，后来还有一些改进方案没来得及实施，但是从我的角度来说，是我的一个大作品。</p>
]]></content>
      <categories>
        <category>Diary</category>
      </categories>
  </entry>
  <entry>
    <title>Hexo启用Https后设置腾讯公益404的问题</title>
    <url>/posts/da5ea02e/</url>
    <content><![CDATA[<h2 id="新建页面"><a href="#新建页面" class="headerlink" title="新建页面"></a>新建页面</h2><p>执行<br>hexo new page 404</p>
<h2 id="修改source-404-index-md"><a href="#修改source-404-index-md" class="headerlink" title="修改source/404/index.md"></a>修改source/404/index.md</h2><p>一些老的页面会出现问题，因为启用了Https后，去加载Http的样式表和JS会失败，所以要使用以下的页面代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 404</span><br><span class="line">date: 2018-08-30 14:40:55</span><br><span class="line">---</span><br><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang=&quot;zh-cn&quot;&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">  &lt;meta charset=&quot;UTF-8&quot; /&gt;</span><br><span class="line">  &lt;title&gt;404&lt;/title&gt;</span><br><span class="line">&lt;/head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">  &lt;script type=&quot;text/javascript&quot; src=&quot;//qzonestyle.gtimg.cn/qzone/hybrid/app/404/search_children.js&quot; homePageName=&quot;返回宝贝回家&quot; homePageUrl=&quot;https://www.baobeihuijia.com&quot;&gt;&lt;/script&gt;</span><br><span class="line">&lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
  </entry>
  <entry>
    <title>Docker-Basic</title>
    <url>/posts/a02e5c6b/</url>
    <content><![CDATA[<p>鉴于生产环境的上线部署，都依赖于镜像构建、制作、部署上线运行等操作，作为一名合格的RD，当然不能只局限于在上线平台上进行一顿鼠标操作了，一定要弄懂这些基础设施内部到底在干嘛。因此，对Docker的相关学习也是很有必要的。</p>
<h1 id="基础信息"><a href="#基础信息" class="headerlink" title="基础信息"></a>基础信息</h1><p><a href="http://dockone.io/article/783">http://dockone.io/article/783</a></p>
<p><a href="http://merrigrove.blogspot.com/2015/10/visualizing-docker-containers-and-images.html">http://merrigrove.blogspot.com/2015/10/visualizing-docker-containers-and-images.html</a></p>
<p>两篇文章分别是中文和英文原版，建议初学者多读几遍，收获非常大。<br>尤其是对镜像只读层和读写层的理解，非常重要，还有docker各个命令对各层的影响。</p>
<span id="more"></span>
<h1 id="Docker-run"><a href="#Docker-run" class="headerlink" title="Docker run"></a>Docker run</h1><p><a href="https://docs.docker.com/engine/reference/commandline/run/">https://docs.docker.com/engine/reference/commandline/run/</a></p>
<p>docker run [OPTIONS] IMAGE [COMMAND] [ARG…]</p>
<p>常用选项：</p>
<ul>
<li>–detach , -d        Run container in background and print container ID</li>
<li>–tty , -t        Allocate a pseudo-TTY</li>
<li>–interactive , -i        Keep STDIN open even if not attached</li>
<li>–publish , -p        Publish a container’s port(s) to the host</li>
<li>–volume , -v        Bind mount a volume</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">// sshd -D 将 sshd 作为前台进程运行，而不是脱离控制台成为后台守护进程。主要用于调试。</span><br><span class="line">// -it 通常一起使用，可以开启一个终端进去交互模式，调试时很有用。</span><br><span class="line">docker run -d -p 2222:22 tomcat:centos /usr/sbin/sshd -D</span><br><span class="line"></span><br><span class="line">docker run -ti -v ~/Downloads:/Downloads tomcat:centos /bin/bash</span><br><span class="line"></span><br><span class="line">docker run -d -p 8000:8080 -p 1098:1099 tomcat:centos /usr/local/sbin/tomcat.sh</span><br><span class="line"></span><br><span class="line">docker run -it -p 8000:8080 -p 1098:1099 tomcat:centos /usr/local/sbin/tomcat.sh</span><br></pre></td></tr></table></figure>

<h1 id="其他Docker命令"><a href="#其他Docker命令" class="headerlink" title="其他Docker命令"></a>其他Docker命令</h1><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><ul>
<li>docker version</li>
<li>docker info</li>
<li>docker stop $(docker ps -aq)</li>
<li>docker rm $(docker ps -aq)</li>
<li>docker pull</li>
<li>docker login</li>
<li>docerk rmi</li>
<li>docker images</li>
</ul>
<h2 id="镜像类"><a href="#镜像类" class="headerlink" title="镜像类"></a>镜像类</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 检索image</span><br><span class="line">$docker search image_name</span><br><span class="line"></span><br><span class="line"># 下载image</span><br><span class="line">$docker pull image_name</span><br><span class="line"></span><br><span class="line"># 列出镜像列表; -a, --all=false Show all images; --no-trunc=false Don&#x27;t truncate output; -q, --quiet=false Only show numeric IDs</span><br><span class="line">$docker images</span><br><span class="line"></span><br><span class="line"># 删除一个或者多个镜像; -f, --force=false Force; --no-prune=false Do not delete untagged parents</span><br><span class="line">$docker rmi image_name</span><br><span class="line"></span><br><span class="line"># 显示一个镜像的历史; --no-trunc=false Don&#x27;t truncate output; -q, --quiet=false Only show numeric IDs</span><br><span class="line">$docker history image_name</span><br></pre></td></tr></table></figure>

<h2 id="容器类"><a href="#容器类" class="headerlink" title="容器类"></a>容器类</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 列出当前所有正在运行的container</span><br><span class="line">$docker ps</span><br><span class="line"># 列出所有的container</span><br><span class="line">$docker ps -a</span><br><span class="line"># 列出最近一次启动的container</span><br><span class="line">$docker ps -l</span><br><span class="line"></span><br><span class="line"># 保存对容器的修改; -a, --author=&quot;&quot; Author; -m, --message=&quot;&quot; Commit message  </span><br><span class="line">$docker commit ID new_image_name</span><br><span class="line"></span><br><span class="line"># 删除所有容器</span><br><span class="line">$docker rm `docker ps -a -q`</span><br><span class="line">  </span><br><span class="line"># 删除单个容器; -f, --force=false; -l, --link=false Remove the specified link and not the underlying container; -v, --volumes=false Remove the volumes associated to the container</span><br><span class="line">$docker rm Name/ID</span><br><span class="line"></span><br><span class="line"># 停止、启动、杀死一个容器</span><br><span class="line">$docker stop Name/ID</span><br><span class="line">$docker start Name/ID</span><br><span class="line">$docker kill Name/ID</span><br><span class="line"></span><br><span class="line"># 从一个容器中取日志; -f, --follow=false Follow log output; -t, --timestamps=false Show timestamps</span><br><span class="line">$docker logs Name/ID</span><br><span class="line">  </span><br><span class="line"># 列出一个容器里面被改变的文件或者目录，list列表会显示出三种事件，A 增加的，D 删除的，C 被改变的</span><br><span class="line">$docker diff Name/ID</span><br><span class="line">  </span><br><span class="line"># 显示一个运行的容器里面的进程信息</span><br><span class="line">$docker top Name/ID</span><br><span class="line"></span><br><span class="line"># 从容器里面拷贝文件/目录到本地一个路径  </span><br><span class="line">$docker cp Name:/container_path to_path</span><br><span class="line">$docker cp ID:/container_path to_path</span><br><span class="line"></span><br><span class="line"># 重启一个正在运行的容器; -t, --time=10 Number of seconds to try to stop for before killing the container, Default=10</span><br><span class="line">$docker restart Name/ID</span><br><span class="line"></span><br><span class="line"># 附加到一个运行的容器上面; --no-stdin=false Do not attach stdin; --sig-proxy=true Proxify all received signal to the process  </span><br><span class="line">$docker attach ID</span><br></pre></td></tr></table></figure>

<h1 id="Dockerfile"><a href="#Dockerfile" class="headerlink" title="Dockerfile"></a>Dockerfile</h1><p>to be continued</p>
]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title>Jackson转换Json的严格字母序</title>
    <url>/posts/4147250/</url>
    <content><![CDATA[<p>经常使用Jackson的同学肯定知道这个注解，<br>@JsonPropertyOrder(alphabetic = true)<br>放在类定义上，可以在该类对象序列化的时候，字段按照字母序排序。<br>全局的话，可以这样配置Jackson的mapper：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MAPPER.configure(MapperFeature.SORT_PROPERTIES_ALPHABETICALLY, true);</span><br><span class="line">MAPPER.configure(SerializationFeature.ORDER_MAP_ENTRIES_BY_KEYS, true);</span><br></pre></td></tr></table></figure>

<p>问题来了，<br>如果类中的字段是不确定类型的（或者说是Object类型），该类型的字段中又可以嵌套其他不确定类型，这样就不好办了，<br>而我要达到的需求是，所有嵌套结构内部也要按照字母序，或者叫严格的字母序。</p>
<p>经验证，在不使用JsonNode的情况下，MAPPER的configure可以满足大多数需求。那么，为什么要用JsonNode呢？</p>
<p>在数据交换的时候，例如反序列化的时候，不知道某个字段的具体类型，是否有嵌套等，用JsonNode会比Map这种好很多，Map不太好处理嵌套的情况。<br>也有同学提出直接使用Object也可以呀，那就会丢失太多的类型信息，内部字段和深层嵌套就更没法处理了。<br>使用JsonNode可以构建出树状结构，很方便的获取属性值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">JsonNode node = MAPPER.valueToTree(obj);</span><br><span class="line">final Object obj = MAPPER.treeToValue(node, Object.class);</span><br><span class="line">String json = MAPPER.writeValueAsString(obj);</span><br></pre></td></tr></table></figure>

<p>参考文档：<br><a href="https://stackoverflow.com/questions/18952571/jackson-jsonnode-to-string-with-sorted-keys#">https://stackoverflow.com/questions/18952571/jackson-jsonnode-to-string-with-sorted-keys#</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>MongoDB-ObjectId</title>
    <url>/posts/397fc4ba/</url>
    <content><![CDATA[<p>对于分布式唯一ID的生成，有几种比较好的思路，划分命名空间并行生成，是现在比较流行的一种方式，例如Twitter提出的非常有名的<br>Snowflake算法。与之类似的是，在很早之前，MongoDB的ObjectId生成算法就是类似的这种思路，在MongoDB的0.9.10(2009年8月24日发布)版本中就已经采用。</p>
<p>在最新的MongoDB-Java-Driver文档中，可以看到ObjectId的相关API说明。参考资料如下：<br><a href="http://mongodb.github.io/mongo-java-driver/3.8/javadoc/org/bson/types/ObjectId.html">Class ObjectId</a><br><a href="https://github.com/mongodb/mongo-java-driver/blob/master/bson/src/main/org/bson/types/ObjectId.java">Source code - ObjectId.java</a></p>
<span id="more"></span>

<p>具体来说，12字节的MongoDB ObjectId的结构是</p>
<ul>
<li>a 4-byte value representing the seconds since the Unix epoch</li>
<li>a 3-byte machine identifier</li>
<li>a 2-byte process id</li>
<li>a 3-byte counter, starting with a random value</li>
</ul>
<p>可以看出，最小的划分粒度是 秒*进程实例，<br>对于单个进程来说，每秒的ID容量是最后一个字段的3个字节，24bit，即大约16777216个ID，这个容量已经可以满足大部分情况下的ID生成需求了。</p>
]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis常用开发应用规范</title>
    <url>/posts/1113160e/</url>
    <content><![CDATA[<p>Redis在日常开发中可以说是非常常用的服务了，提供了灵活的数据结构、高效率、方便的lua script等多种功能。<br>在开发运用过程中，有一些点是需要特别注意的，也是对Redis的一种比较正确的使用方式，简单总结如下：</p>
<ol>
<li>KEY的格式要规范，可读性要强，注意控制KEY的长度。</li>
<li>VALUE的大小限制。Redis限制每个String类型value大小不超过512MB，<br>实际开发中，不要超过10KB，否则会对CPU和网卡造成极大负载。<br>hash、list、set、zset元素个数不要超过5000。<span id="more"></span></li>
<li>选择合适的数据类型，而不是一味的用string类型。建议多用hash，有压缩算法，可以降低开销。<blockquote>
<blockquote>
<p>hash类型特别适合用于存储对象。在field的数量在限制的范围内以及value的长度小于指定的字节数，那么此时的hash类型是用zipmap存储的，所以会比较节省内存。可以在配置文件里面修改配置项来控制field的数量和value的字节数大小。<br> hash-max-zipmap-entries 512 #配置字段最多512个<br> hash-max-zipmap-value 64 #配置value最大为64字节。<br>必须满足以上两个条件，那么该key会被压缩。否则就是按照正常的hash结构来存储hash类型的key。</p>
</blockquote>
</blockquote>
</li>
<li>设置过期时间，减少内存占用。</li>
<li>禁用KEYS命令。查找效率是O(N)，很可能阻塞正常请求，而且CPU负载过大。</li>
<li>禁用flushall，flushdb命令，过于危险。</li>
<li>建议使用批量操作提供效率<blockquote>
<blockquote>
<p>原生命令：例如mget、mset。<br>非原生命令：可以使用pipeline提高效率。</p>
</blockquote>
</blockquote>
</li>
</ol>
<p>参考文档：<br><a href="https://blog.csdn.net/glx490676405/article/details/79580748">阿里云Redis开发规范</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>基于Redis实现的Rate limiter (限流器)</title>
    <url>/posts/9e983597/</url>
    <content><![CDATA[<p>首先建议大家好好阅读一下官方文章，如何利用incr命令实现一些应用模式（Pattern）。<br><a href="https://redis.io/commands/incr">INCR命令的介绍与应用</a></p>
<p>本文不对原文进行大段翻译，主要讲下自己的理解。</p>
<h1 id="模式：计数器"><a href="#模式：计数器" class="headerlink" title="模式：计数器"></a>模式：计数器</h1><p>Redis原子性自增操作，最明显的应用就是计数器了，类似Java的AtomicInteger。<br>可以结合EXPIRE，INCRBY，GET，SET，DECR等操作做很多很多事情。<br>多命令的情况下要注意事务或者使用Lua script哦。</p>
<h1 id="模式：Rate-limiter-限流器"><a href="#模式：Rate-limiter-限流器" class="headerlink" title="模式：Rate limiter 限流器"></a>模式：Rate limiter 限流器</h1><h2 id="限流器的应用"><a href="#限流器的应用" class="headerlink" title="限流器的应用"></a>限流器的应用</h2><p>限流器的应用非常广泛，比如Github对外提供了非常丰富的API，但考虑到数据安全和系统资源，对匿名用户和经过认证的用户的请求API频率都是要有限制的。<br>可以看看Github API的<a href="https://developer.github.com/v3/#rate-limiting">Rate limiting</a>。<br>认证的用户每小时请求次数是5000，没认证的用户每小时只能请求60次，依靠原始IP来区分未认证用户。</p>
<p>上面介绍了一个很典型的应用场景，如果一个系统对我提供服务，开放API的话，为了防刷和系统资源的平衡，限流器的应用是很有必要的。<br>调用Github API返回结果的时候，response的Header里面都会带有限流的信息，这是一个非常好的设计，大致如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">curl -i https://api.github.com/users/octocat</span><br><span class="line">HTTP/1.1 200 OK</span><br><span class="line">Date: Mon, 01 Jul 2013 17:27:06 GMT</span><br><span class="line">Status: 200 OK</span><br><span class="line">X-RateLimit-Limit: 60</span><br><span class="line">X-RateLimit-Remaining: 56</span><br><span class="line">X-RateLimit-Reset: 1372700873</span><br></pre></td></tr></table></figure>
<p>我在做网关设计中也借鉴过这种设计方式，另外也参考过spring-cloud-zuul微服务网关中的一个<a href="https://github.com/marcosbarbero/spring-cloud-zuul-ratelimit">API限流库</a>的代码，里面Filter的设计还是很不错的。</p>
<span id="more"></span>

<h2 id="提出问题"><a href="#提出问题" class="headerlink" title="提出问题"></a>提出问题</h2><p>针对每个来访IP，限制每秒只能访问10次。</p>
<h2 id="模式1：最直接的实现"><a href="#模式1：最直接的实现" class="headerlink" title="模式1：最直接的实现"></a>模式1：最直接的实现</h2><p>KEY值的设计会决定你的解决方案。<br>一种是KEY是IP+当前秒数（UNIX时间戳），那么在该秒内的所有访问，都会对这个KEY执行INCR命令，这个KEY在当前秒之后就没用了其实，设置过期时间大于1秒即可。<br>该方案的伪码表示如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FUNCTION LIMIT_API_CALL(ip)</span><br><span class="line">ts = CURRENT_UNIX_TIME()</span><br><span class="line">keyname = ip+&quot;:&quot;+ts</span><br><span class="line">current = GET(keyname)</span><br><span class="line">IF current != NULL AND current &gt; 10 THEN</span><br><span class="line">    ERROR &quot;too many requests per second&quot;</span><br><span class="line">ELSE</span><br><span class="line">    MULTI</span><br><span class="line">        INCR(keyname,1)</span><br><span class="line">        EXPIRE(keyname,10)</span><br><span class="line">    EXEC</span><br><span class="line">    PERFORM_API_CALL()</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>显而易见的，该方案的缺点是系统访问量大时，比如当前秒有10000个IP来访问，Redis中就会出现10000个KEY，虽然有Redis的过期删除，10秒过期就会导致10秒<br>内的所有IP访问的KEY堆积，大量占用Redis的内存。</p>
<h2 id="模式2：IP为KEY"><a href="#模式2：IP为KEY" class="headerlink" title="模式2：IP为KEY"></a>模式2：IP为KEY</h2><p>这种设计也很直接啊，IP为KEY，过期时间1秒，有IP访问就自增，超过1秒，该KEY就会过期，后面的访问重新生成KEY。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FUNCTION LIMIT_API_CALL(ip):</span><br><span class="line">current = GET(ip)</span><br><span class="line">IF current != NULL AND current &gt; 10 THEN</span><br><span class="line">    ERROR &quot;too many requests per second&quot;</span><br><span class="line">ELSE</span><br><span class="line">    value = INCR(ip)</span><br><span class="line">    IF value == 1 THEN</span><br><span class="line">        EXPIRE(ip,1)</span><br><span class="line">    END</span><br><span class="line">    PERFORM_API_CALL()</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>官网很明确的指出了这里面的竞争条件，假如多个线程访问，都进入了ELSE进行了自增，ip的值就变为2或更大，EXPIRE没有执行，这个KEY就泄露了，永远保存在Redis中，<br>只有后面又遇到相同IP地址的访问。<br>因为有IF判断语句，所以这里不能使用MULTI-EXEC事务，必须使用lua脚本，提升了设计复杂度。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">local current</span><br><span class="line">current = redis.call(&quot;incr&quot;,KEYS[1])</span><br><span class="line">if tonumber(current) == 1 then</span><br><span class="line">    redis.call(&quot;expire&quot;,KEYS[1],1)</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<h2 id="模式3：新思路使用list"><a href="#模式3：新思路使用list" class="headerlink" title="模式3：新思路使用list"></a>模式3：新思路使用list</h2><p>直接上lua script好了。KEYS[1]就是访问IP，ARGV[2]是超时时间的ms值，这里是1000，ARGV[1]比较随意，可以是访问时间的ms。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then </span><br><span class="line">    redis.call(&#x27;rpush&#x27;, KEYS[1], ARGV[1]);</span><br><span class="line">    return redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); </span><br><span class="line">else</span><br><span class="line">    return redis.call(&#x27;rpushx&#x27;, KEYS[1], ARGV[1]); </span><br><span class="line">end; </span><br></pre></td></tr></table></figure>
<p>先执行LLEN(KEY)，如果超过限制则返回，否则执行LUA脚本。</p>
<p>之前有个小同事在这里用了KEYS IP*的方式，类似模式1，这里大家要注意，在很多Redis的线上系统中是会禁用KEYS的，因为KEYS会造成系统CPU的使用率骤增，<br>会导致系统不稳定。我直接改成了这个lua script的用法，现在运行的也很不错。</p>
<p>这个LUA脚本解决了官网说的竞争问题，官网的伪代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FUNCTION LIMIT_API_CALL(ip)</span><br><span class="line">current = LLEN(ip)</span><br><span class="line">IF current &gt; 10 THEN</span><br><span class="line">    ERROR &quot;too many requests per second&quot;</span><br><span class="line">ELSE</span><br><span class="line">    IF EXISTS(ip) == FALSE</span><br><span class="line">        MULTI</span><br><span class="line">            RPUSH(ip,ip)</span><br><span class="line">            EXPIRE(ip,1)</span><br><span class="line">        EXEC</span><br><span class="line">    ELSE</span><br><span class="line">        RPUSHX(ip,ip)</span><br><span class="line">    END</span><br><span class="line">    PERFORM_API_CALL()</span><br><span class="line">END</span><br></pre></td></tr></table></figure>
<p>简单解释下，这里的竞争在IF EXISTS，多个线程同时判断了IF，都进入了IF，准备执行MULTI-EXEC，<br>当然这里只能顺序执行，一个线程执行完之后，另一个线程也执行，EXPIRE以最后执行的线程为准，由于过期时间的改变，会有略微不准确的情况。</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式系统下的唯一ID生成问题</title>
    <url>/posts/8a9934c8/</url>
    <content><![CDATA[<h1 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h1><p>在一个应用中会产生大量的业务数据，这些数据往往需要一个ID来标记，在关系型数据库中，主键往往就是这个作用。<br>在大多数数据库中，自增的64bit long类型主键，就是用来解决这个问题的。有时，我们必须在应用层控制ID的生成，<br>这时我们就要缓存下最近生成的ID是多少，以此来跟踪生成的序列。</p>
<p>如果数据库中的数据做了分片（shard，分库分表），那么在一个表中自增的64bit long主键显然不能适用，多个节点下<br>必然会发生碰撞问题。与此类似，当应用分布在多个节点运行的时候，简单在内存缓存最近的一个ID，也同样不能满足需要。</p>
<span id="more"></span>

<h1 id="分布式环境下的解决方案"><a href="#分布式环境下的解决方案" class="headerlink" title="分布式环境下的解决方案"></a>分布式环境下的解决方案</h1><h2 id="中心式"><a href="#中心式" class="headerlink" title="中心式"></a>中心式</h2><h3 id="数据库的中心化自增"><a href="#数据库的中心化自增" class="headerlink" title="数据库的中心化自增"></a>数据库的中心化自增</h3><p><a href="http://code.flickr.net/2010/02/08/ticket-servers-distributed-unique-primary-keys-on-the-cheap/">Flickr的Ticket Server方案</a><br>MySQL的自增显然不能在多库多表的情况下使用，那使用单库单表呢？</p>
<p>活用MySQL的REPLACE INTO。</p>
<blockquote>
<p>REPLACE works exactly like INSERT, except that if an old row in the table has the same value as a new row for a PRIMARY KEY or a UNIQUE index, the old row is deleted before the new row is inserted.</p>
</blockquote>
<p>新建两张表，Tickets32 for 32-bit IDs, and Tickets64 for 64-bit IDs.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CREATE TABLE `Tickets64` (</span><br><span class="line">  `id` bigint(20) unsigned NOT NULL auto_increment,</span><br><span class="line">  `stub` char(1) NOT NULL default &#x27;&#x27;,</span><br><span class="line">  PRIMARY KEY  (`id`),</span><br><span class="line">  UNIQUE KEY `stub` (`stub`)</span><br><span class="line">) ENGINE=MyISAM</span><br></pre></td></tr></table></figure>

<p>当需要一个新的64bit唯一ID时，执行以下SQL：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">REPLACE INTO Tickets64 (stub) VALUES (&#x27;a&#x27;);</span><br><span class="line">SELECT LAST_INSERT_ID();</span><br></pre></td></tr></table></figure>

<p>因为是单库，怎么解决单点故障问题呢？把ID的数值分成奇数和偶数，在两台数据库服务器上部署。<br>配置如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TicketServer1:</span><br><span class="line">auto-increment-increment = 2</span><br><span class="line">auto-increment-offset = 1</span><br><span class="line"></span><br><span class="line">TicketServer2:</span><br><span class="line">auto-increment-increment = 2</span><br><span class="line">auto-increment-offset = 2</span><br></pre></td></tr></table></figure>


<h3 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h3><p>若系统中已经依赖了Redis，使用Redis也是很好的选择，加上现在Redis已经有了集群化的高可用方案。<br>Redis的INCR命令，可以直接获取增加后的值。如果需要定制更复杂点的生成算法，使用lua脚本结合多个命令即可，lua脚本可以保证原子性。<br>缺点就是依赖Redis啦，每次获取都有一次远程调用，如果很担忧效率的话，可以一次获取批量的ID。</p>
<h3 id="Zookeeper"><a href="#Zookeeper" class="headerlink" title="Zookeeper"></a>Zookeeper</h3><p>zookeeper主要通过其znode数据版本来生成序列号，可以生成32位和64位的数据版本号，客户端可以使用这个版本号来作为唯一的序列号。<br>很少会使用zookeeper来生成唯一ID。性能方面会不太理想，但也算一种思路。</p>
<h3 id="其他的分布式集群协调器"><a href="#其他的分布式集群协调器" class="headerlink" title="其他的分布式集群协调器"></a>其他的分布式集群协调器</h3><p>在不使用数据库的情况下，通过一个后台服务对外提供高可用的、固定步长标识生成，则需要分布式的集群协调器进行。</p>
<p>一般的，主流协调器有两类：</p>
<ul>
<li>以强一致性为目标的：ZooKeeper为代表</li>
<li>以最终一致性为目标的：Consul为代表</li>
</ul>
<p>ZooKeeper的强一致性，是由Paxos协议保证的；Consul的最终一致性，是由Gossip协议保证的。</p>
<p>在步长累计型生成算法中，最核心的就是保持一个累计值在整个集群中的「强一致性」。同时，这也会为唯一性标识的生成带来新的形成瓶颈。</p>
<p>参考：<a href="https://juejin.im/entry/57fe1be1bf22ec0064ad96ce">https://juejin.im/entry/57fe1be1bf22ec0064ad96ce</a></p>
<h2 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h2><p>Universally unique identifier (UUID)，有时也被称为globally unique identifier(GUID)。<br>拥有RFC标准，应用非常广泛。</p>
<p>在微软的相关类库中，直接找GUID就可以了。<br>在Java语言中，可以直接使用java.util.UUID类的randomUUID()静态方法，直接可以得到一个类型4的UUID，<br>这也是最常用最简单的生成方法。</p>
<p>那么什么是类型4呢，是基于伪随机生成UUID的一种方法类型，具体可以学习下UUID的<a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">Wiki</a>。</p>
<p>标准UUID的优势：</p>
<ul>
<li>各大编程语言自带实现，编码简单，直接使用。没有其他依赖限制。</li>
<li>性能好。</li>
<li>全球唯一，碰撞率极小。</li>
</ul>
<p>缺点：</p>
<ul>
<li>没有顺序性。</li>
<li>字符串存储，一般需要36个字符表示，比较占用存储空间。</li>
<li>随机生成，可读性较低。</li>
<li>用作数据库主键或作为索引的话，查询效率会比较低。<a href="https://medium.com/@varuntayal/re-design-primary-keys-and-ids-9b9776d442b">UUID与自增64bit long ID的数据库效率比较</a></li>
</ul>
<p>建议仔细阅读以下文档：<br><a href="http://www.ietf.org/rfc/rfc4122.txt">RFC4122</a><br><a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID Wiki</a></p>
<h2 id="Snowflake算法"><a href="#Snowflake算法" class="headerlink" title="Snowflake算法"></a>Snowflake算法</h2><p>Twitter贡献的开源分布式ID生成算法，可以生成一个64bit long型ID。<br><img src="https://i.loli.net/2018/09/06/5b90cb6499eff.png" alt="1081851-20161216164125479-1591675346.png"><br>由于该算法依赖于Twitter的一系列基础设施，已经不再维护了。如果要使用的话，可能需要进行一些改造。</p>
<p><a href="https://github.com/twitter/snowflake">Source code</a><br><a href="https://segmentfault.com/a/1190000011282426">看完这一篇就深入理解了</a></p>
<p><a href="http://darktea.github.io/notes/2013/12/08/Unique-ID">其他一些变种的flake算法</a></p>
<h2 id="MongoDB的ObjectId"><a href="#MongoDB的ObjectId" class="headerlink" title="MongoDB的ObjectId"></a>MongoDB的ObjectId</h2><p>和Snowflake算法类似。它设计成轻量型的，不同的机器都能用全局唯一的同种方法方便地生成。<br>MongoDB从一开始就设计用来作为分布式数据库，处理多个节点是一个核心要求，在分布式环境中也很容易应用。</p>
<p>其他参考文章：<br><a href="https://medium.com/@varuntayal/what-does-it-take-to-generate-cluster-wide-unique-ids-in-a-distributed-system-d505b9eaa46e">What does it take to generate cluster wide unique ID’s in a distributed system</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>develop</tag>
      </tags>
  </entry>
  <entry>
    <title>MAC &amp; HMAC</title>
    <url>/posts/19e9c6b0/</url>
    <content><![CDATA[<p>在前一段做安全接入的时候，结合了多种安全和密码学的算法，设计了一套敏感数据传输方案。今天主要介绍的是其中用到的消息认证码（Message authentication code，缩写为MAC）。这里的MAC并不是网卡物理地址的那个MAC，注意区分。</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>在密码学中，MAC是一小段字节信息，用于验证发送消息的完整性(data integrity)，以及消息的身份认证(确定消息的发送者的身份 - its authenticity)。<br>另一方面来说，MAC可以做到识别内容篡改和内容伪造。<br>回忆一下，Hash算法例如SHA256、MD5等，也可以完成消息完整性的验证，数字签名算法(其实内部也结合了消息散列函数)也可以达到MAC的这两项作用。</p>
<h1 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h1><p>MAC（生成tag）由三个算法组成：</p>
<ul>
<li>密钥key生成算法。从密钥空间中选择出来的key是均匀和随机的。</li>
<li>签名算法。给定Key和消息，生成唯一的tag。</li>
<li>验证算法。给定Key，tag和消息，验证是否符合。</li>
</ul>
<h1 id="安全"><a href="#安全" class="headerlink" title="安全"></a>安全</h1><p>MAC方法必须能够抵御chosen-plaintext attacks。<br>简单解释一下：<br>Alice和Bob约定一个只有他们两个知道的MAC key。Eve在监视他们的通信，并且可以获取到他们通信的信息和对应的tags。<br>但是Eve根据得到的这些对应信息，并不能推算出其他消息的有效tag。<br>即使Eve可以说服Alice和Bob发送一些指定的信息，也依旧不能推算出来。<br>在Eve看来，tag是完全随机的字节。</p>
<span id="more"></span>

<p>MAC与数字签名的主要不同点，在于MAC在生成和验证阶段使用的是相同的key，接收者和发送者必须实现约定相同的key，才能使用MAC方法进行通信。<br>数字签名则是使用的非对称的公钥和私钥机制，使用私钥进行签名，公钥验证签名。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><p>HMAC是MAC方法的一种具体实现，使用key和一些特点的Hash函数来生成MAC，常见的有Hmac_MD5，Hmac_SHA1，Hmac_SHA256，Hmac_SHA384，Hmac_SHA512.</p>
<p>Java代码示例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">private static final String HMAC_ALGORITHM = &quot;HmacSHA256&quot;;</span><br><span class="line">private static final int HMAC_KEY_LENGTH_BITS = 256;</span><br><span class="line"></span><br><span class="line">public static SecretKey getSecretKey() throws Exception &#123;</span><br><span class="line">    KeyGenerator keyGenerator = KeyGenerator.getInstance(HMAC_ALGORITHM);</span><br><span class="line">    return keyGenerator.generateKey();</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">private static byte[] randomBytes(int length) &#123;</span><br><span class="line">    SecureRandom random = new SecureRandom();</span><br><span class="line">    byte[] b = new byte[length];</span><br><span class="line">    random.nextBytes(b);</span><br><span class="line">    return b;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * Generate the mac based on HMAC_ALGORITHM</span><br><span class="line"> *</span><br><span class="line"> * @param integrityKey   The key used for hmac</span><br><span class="line"> * @param byteCipherText the cipher text</span><br><span class="line"> *</span><br><span class="line"> * @return A byte array of the HMAC for the given key and ciphertext</span><br><span class="line"> *</span><br><span class="line"> * @throws NoSuchAlgorithmException</span><br><span class="line"> * @throws InvalidKeyException</span><br><span class="line"> */</span><br><span class="line">public static byte[] generateMac(byte[] byteCipherText, SecretKey integrityKey)</span><br><span class="line">        throws NoSuchAlgorithmException, InvalidKeyException &#123;</span><br><span class="line">    // Now compute the mac for later integrity checking</span><br><span class="line">    Mac sha256HMAC = Mac.getInstance(HMAC_ALGORITHM);</span><br><span class="line">    sha256HMAC.init(integrityKey);</span><br><span class="line">    return sha256HMAC.doFinal(byteCipherText);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>参考：<br><a href="https://en.wikipedia.org/wiki/Message_authentication_code">https://en.wikipedia.org/wiki/Message_authentication_code</a><br><a href="https://en.wikipedia.org/wiki/Chosen-plaintext_attack">https://en.wikipedia.org/wiki/Chosen-plaintext_attack</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>develop</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>RBAC简要设计</title>
    <url>/posts/5969db7a/</url>
    <content><![CDATA[<p>Role-Based-Access-Control System Design.<br>比较常见的基于角色的访问控制系统，这次是主要了解和简单设计，不涉及到特别复杂的功能。</p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>参考文档：<a href="https://blog.csdn.net/yangwenxue_admin/article/details/73936803">https://blog.csdn.net/yangwenxue_admin/article/details/73936803</a></p>
<p>RBAC（Role-Based Access Control，基于角色的访问控制），就是用户<strong>通过角色与权限进行关联</strong>。</p>
<p>其主要特点如下：</p>
<p>一个用户拥有若干角色，每一个角色拥有若干权限。这样，就构造成“用户-角色-权限”的授权模型。<br>这种模型中，用户与角色之间，角色与权限之间，一般是多对多的关系。<br>在此基础上，可以扩展出用户组等实体类型。<br>根据实际需求，可以考虑增加用户组，并对具体权限的类型进行了细分。</p>
<span id="more"></span>
<h1 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h1><p>角色是什么？可以理解为一定数量的权限的集合，权限的载体。例如：一个论坛系统，“超级管理员”、“版主”都是角色。版主可管理版内的帖子、可管理版内的用户等，这些是权限。要给某个用户授予这些权限，不需要直接将权限授予用户，可将“版主”这个角色赋予该用户。  </p>
<h1 id="用户组"><a href="#用户组" class="headerlink" title="用户组"></a>用户组</h1><p>当用户的数量非常大时，要给系统每个用户逐一授权（授角色），是件非常烦琐的事情。这时，就需要给用户分组，每个用户组内有多个用户。</p>
<p>除了可给用户授权外，还可以给用户组授权。这样一来，用户拥有的所有权限，就是用户个人拥有的权限与该用户所在用户组拥有的权限之和。</p>
<h1 id="权限类型"><a href="#权限类型" class="headerlink" title="权限类型"></a>权限类型</h1><p>权限细分出“权限类型”，我们根据它的取值来区分是哪一类权限，进而与特定的表进行关联。如“MENU”表示菜单的访问权限、“RESOURCE”表示可供访问的URL、“FILE”表示文件的修改权限等。 </p>
<p>这样设计的好处有二：</p>
<ul>
<li>不需要区分哪些是权限操作，哪些是资源，（实际上，有时候也不好区分，如菜单，把它理解为资源呢还是功能模块权限呢？）。</li>
<li>方便扩展，当系统要对新的内容或实体进行权限控制时，我只需要建立一个新的关联表“权限XX关联表”，并确定这类权限的权限类型字符串。</li>
</ul>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Elasticsearch-nested-query</title>
    <url>/posts/3f81b35b/</url>
    <content><![CDATA[<p>Elasticsearch嵌套查询，具体可参考<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-nested-query.html">Nested Query</a>.</p>
<p>建议还是要多看多熟悉Elasticsearch的官方文档，比到处去搜强多了。</p>
<p>简而言之，在对ES doc的多层嵌套对象进行查询的时候，要使用Nested Query，常规查询无效。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;query&quot;: &#123;</span><br><span class="line">        &quot;nested&quot; : &#123;</span><br><span class="line">            &quot;path&quot; : &quot;obj&quot;,</span><br><span class="line">            &quot;query&quot; : &#123;</span><br><span class="line">                &quot;bool&quot; : &#123;</span><br><span class="line">                    &quot;must&quot; : [</span><br><span class="line">                        &#123; &quot;match&quot; : &#123;&quot;obj.info.name&quot; : &quot;zhangsan&quot;&#125; &#125;</span><br><span class="line">                    ]</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
]]></content>
      <tags>
        <tag>elasticsearch</tag>
      </tags>
  </entry>
  <entry>
    <title>推荐计算机科学书籍</title>
    <url>/posts/ba7b25c0/</url>
    <content><![CDATA[<p>值得一读的高分计算机书籍：<br><a href="https://www.douban.com/doulist/37472347/?start=0&amp;sort=seq&amp;playable=0&amp;sub_type=">https://www.douban.com/doulist/37472347/?start=0&amp;sort=seq&amp;playable=0&amp;sub_type=</a></p>
<p>从我的角度来看呢，高级程序员推荐必读</p>
<h1 id="计算机基础"><a href="#计算机基础" class="headerlink" title="计算机基础"></a>计算机基础</h1><p><a href="https://book.douban.com/subject/5407246/">深入理解计算机系统（英文版·第2版）</a></p>
<h1 id="网络相关"><a href="#网络相关" class="headerlink" title="网络相关"></a>网络相关</h1><p><a href="https://book.douban.com/subject/10746113/">HTTP权威指南</a></p>
<p><a href="https://book.douban.com/subject/25863515/">图解HTTP</a></p>
<p><a href="https://book.douban.com/subject/1088054/">TCP/IP详解 卷1：协议</a></p>
<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><p><a href="https://book.douban.com/subject/27096665/">现代操作系统（原书第4版）</a></p>
<p><a href="http://pages.cs.wisc.edu/~remzi/OSTEP/#book-chapters">Operating Systems</a> 在线免费版本</p>
<h1 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h1><p><a href="https://book.douban.com/subject/23008813/">高性能MySQL</a></p>
<h1 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h1><p><a href="https://book.douban.com/subject/19952400/">算法（第4版）</a></p>
<p><a href="https://book.douban.com/subject/20432061/">算法导论（原书第3版）</a></p>
<h1 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h1>]]></content>
  </entry>
  <entry>
    <title>JDK11-ZGC</title>
    <url>/posts/769720f0/</url>
    <content><![CDATA[<p>JDK 11即将于09/25正式发布，包含了诸多新的特性，主要的新特性JEP(JDK Enhancement Proposal 特性增强提议)有17个，参见下表</p>
<ul>
<li>181: Nest-Based Access Control</li>
<li>309: Dynamic Class-File Constants</li>
<li>315: Improve Aarch64 Intrinsics</li>
<li>318: Epsilon: A No-Op Garbage Collector</li>
<li>320: Remove the Java EE and CORBA Modules</li>
<li>321: HTTP Client (Standard)</li>
<li>323: Local-Variable Syntax for Lambda Parameters</li>
<li>324: Key Agreement with Curve25519 and Curve448</li>
<li>327: Unicode 10</li>
<li>328: Flight Recorder</li>
<li>329: ChaCha20 and Poly1305 Cryptographic Algorithms</li>
<li>330: Launch Single-File Source-Code Programs</li>
<li>331: Low-Overhead Heap Profiling</li>
<li>332: Transport Layer Security (TLS) 1.3</li>
<li>333: ZGC: A Scalable Low-Latency Garbage Collector(Experimental)</li>
<li>335: Deprecate the Nashorn JavaScript Engine</li>
<li>336: Deprecate the Pack200 Tools and API</li>
</ul>
<p>其中，非常值得大家关注的是JEP-333，ZGC，一个可扩展的低延迟垃圾回收器。ZGC目前仍处于实验阶段，不建议在生产环境使用。<br>目前使用ZGC需要添加JVM参数：-XX:+UnlockExperimentalVMOptions -XX:+UseZGC</p>
<span id="more"></span>

<p>ZGC的目标：</p>
<ul>
<li>GC停顿(Stop the wordld)时间不会超过10ms</li>
<li>能够处理从几百MB到几TB大小的JAVA堆</li>
<li>与G1相比，吞吐量下降不超过15%</li>
<li>为未来的GC功能和优化利用有色对象指针(colored oops)和加载屏障(load barriers)奠定基础</li>
<li>初始只支持Linux/x64</li>
</ul>
<p>ZGC可以并发执行以下GC任务/阶段：</p>
<ul>
<li>标记（Marking）</li>
<li>引用处理（Reference processing）</li>
<li>重新分配集的选择（Relocation set selection）</li>
<li>重分配/压缩（Relocation/Compaction）</li>
</ul>
<p>ZGC的特点描述：</p>
<ul>
<li>concurrent</li>
<li>single-generation</li>
<li>region-based</li>
<li>NUMA-aware</li>
</ul>
<p>GC是Java的主要优势之一。然而，当GC停顿太长，就会开始影响应用的响应时间。消除或者减少GC停顿时长，Java将在更广泛的应用场景中成为一个更有吸引力的平台。<br>此外，现代操作系统中可用内存不断增长，用户和程序员都希望JVM能够以高效的方式充分利用这些内存，并且无需长时间的GC暂停时间。</p>
<p>ZGC一个并发，基于region，压缩型的垃圾收集器，只有root扫描阶段会STW，因此GC停顿时间不会随着堆的增长和存活对象的增长而变长。</p>
<p>ZGC的核心设计原则是使用负载屏障（load barrier）与有色指针对象（colored object pointers，colored oops）组合。这使得ZGC能够进行并发操作，比如对象的重定位，Java应用程序线程正在运行时，从Java线程的角度，在Java对象中加载引用字段的行为是会受到负载障碍的影响。除了对象地址以外，有色对象指针包含负载障碍所需的其他信息，用来确定Java线程在使用指针之前是否需要执行某些操作，例如，该对象可能已被重新定位，负载屏障将检测到这种情况并采取合适的行为。</p>
<p>A core design principle/choice in ZGC is the use of load barriers in combination with colored object pointers (i.e., colored oops). This is what enables ZGC to do concurrent operations, such as object relocation, while Java application threads are running. From a Java thread’s perspective, the act of loading a reference field in a Java object is subject to a load barrier. In addition to an object address, a colored object pointer contains information used by the load barrier to determine if some action needs to be taken before allowing a Java thread to use the pointer. For example, the object might have been relocated, in which case the load barrier will detect the situation and take appropriate action.</p>
<p>参考文档：<br><a href="http://openjdk.java.net/projects/jdk/11/">JDK 11</a><br><a href="http://openjdk.java.net/jeps/333">JEP 333: ZGC: A Scalable Low-Latency Garbage Collector</a><br><a href="https://wiki.openjdk.java.net/display/zgc/Main">OpenJDK Wiki About ZGC</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo进阶设置</title>
    <url>/posts/a62b0c3d/</url>
    <content><![CDATA[<h1 id="静态代码压缩"><a href="#静态代码压缩" class="headerlink" title="静态代码压缩"></a>静态代码压缩</h1><p>因为Blog中都是静态页面，基本都可以压缩优化，针对html，css，js，图片进行。<br>这里没必要用gulp去压缩，配置太繁琐，也没法自动化。<br>直接使用<a href="https://github.com/chenzhutian/hexo-all-minifier">hexo-all-minifier</a>这个模块，<br>安装：</p>
<blockquote>
<p>npm install hexo-all-minifier –save</p>
</blockquote>
<p>增加配置：</p>
<blockquote>
<p>all_minifier: true</p>
</blockquote>
<p>搞定！</p>
<h1 id="文章唯一链接"><a href="#文章唯一链接" class="headerlink" title="文章唯一链接"></a>文章唯一链接</h1><p>hexo-abbrlink</p>
<h1 id="文章字数统计和阅读时长"><a href="#文章字数统计和阅读时长" class="headerlink" title="文章字数统计和阅读时长"></a>文章字数统计和阅读时长</h1><p><a href="https://github.com/theme-next/hexo-symbols-count-time">hexo-symbols-count-time</a><br>可以替代老的hexo-wordcount。</p>
<h1 id="SEO-搜索引擎收录和优化"><a href="#SEO-搜索引擎收录和优化" class="headerlink" title="SEO-搜索引擎收录和优化"></a>SEO-搜索引擎收录和优化</h1><p>利用插件生成sitemap，hexo自带的两个插件，百度搜索要使用单独的一个。</p>
<span id="more"></span>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-sitemap --save     </span><br><span class="line">npm install hexo-generator-baidu-sitemap --save</span><br></pre></td></tr></table></figure>
<p>修改根目录中的_config.yml，url必须要修改成对应的，会体现在sitemap.xml里的url里。增加配置项。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Sitemap</span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br><span class="line">baidusitemap:</span><br><span class="line">  path: baidusitemap.xml</span><br></pre></td></tr></table></figure>
<p>之后hexo重新生成部署，就可以看到两个站点地图的xml文件了。</p>
<h2 id="Google收录"><a href="#Google收录" class="headerlink" title="Google收录"></a>Google收录</h2><p>Google站点平台：<a href="https://www.google.com/webmasters/">https://www.google.com/webmasters/</a><br>验证站点可以用html文件的方式，html文件放在hexo的source目录后，一定要在开头添加</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">layout: false</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>这样hexo才可以正确处理该文件。</p>
<p>之后提交sitemap即可，配置比较简单，不再赘述。</p>
<p>参考资料：</p>
<ul>
<li><a href="http://muyunyun.cn/posts/f55182c5/">http://muyunyun.cn/posts/f55182c5/</a></li>
<li><a href="https://blog.csdn.net/sunshine940326/article/details/70936988">https://blog.csdn.net/sunshine940326/article/details/70936988</a></li>
</ul>
]]></content>
      <categories>
        <category>网站</category>
      </categories>
      <tags>
        <tag>web</tag>
      </tags>
  </entry>
  <entry>
    <title>自建Git服务的几个选择</title>
    <url>/posts/a9253739/</url>
    <content><![CDATA[<p>两年前比较早的时候，git刚流行起来，私服方案记得只有一个，就是gitlab，gitlab自己提供累死github的公有服务器，也提供自己搭建<br>服务的功能，现在官方还有了docker image，可以说是非常方便了。</p>
<p>Gitlab的特点：</p>
<ul>
<li>优点：功能很全，自带CI持续集成和Issue tracking。</li>
<li>缺点：比较重，配置要求高。建议独立部署，内存需求比较大。</li>
</ul>
<p>最近偶尔看到了几个非常轻量的自建git服务，这里简单记录一下，以后也许会用得到：</p>
<ol>
<li>Gogs。<a href="https://gogs.io/%E3%80%82GO%E8%AF%AD%E8%A8%80%E5%BC%80%E5%8F%91%EF%BC%8C%E8%B7%A8%E5%B9%B3%E5%8F%B0%EF%BC%8C%E6%94%AF%E6%8C%81docker%E3%80%82">https://gogs.io/。GO语言开发，跨平台，支持docker。</a></li>
<li>Gitea。Gogs的社区开发维护版本。<a href="https://gitea.io/zh-cn/%E3%80%82">https://gitea.io/zh-cn/。</a></li>
</ol>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title>JDK11已正式发布</title>
    <url>/posts/df008f1/</url>
    <content><![CDATA[<h1 id="正式发布"><a href="#正式发布" class="headerlink" title="正式发布"></a>正式发布</h1><p>9月25日，Oracle官方宣布Java11(18.9 LTS)正式发布，可在生产环境中使用！<br>Java11是Oracle在2017年宣布新的JDK发布时间表之后，第一个长期支持 - Long Term Support(LTS)版本，非常值得大家关注。<br>如果说之前的Java9和Java10关注度都比较小，基本都被大家忽略的话，Java11可是绝对不容错过的。<br>作为新版发布路线的第一个LTS版本，其重要性和对后面版本的影响都不言而喻，<br>Oracle直到2023年9月都会为Java 11提供技术支持，而补丁和安全警告等扩展支持将持续到2026年。<br>LTS版本每三年发布一次，根据后续的发布计划，下一个LTS版本，应该是Java17，要在3年后的2021年才会与大家见面。</p>
<p>为了更快地迭代，以及跟进社区反馈，自2018年起，Java的版本发布周期变更为每六个月一次 —— 每半年发布一个大版本，每个季度发布一个中间特性版本，并且承诺不会跳票。<br>通过这样的方式，开发团队可以把一些关键特性尽早合并到JDK之中，以快速得到开发者反馈，在一定程度上避免出现像Java 9这样两次被迫延迟发布的窘况。</p>
<p>按照官方的说法，新的发布周期会严格遵循时间点，将于每年的3月份和9月份发布。所以Java 11的版本号是18.9(LTS)。</p>
<p>不过与Java 9和Java 10这两个被称为“功能性版本”不同（两者均只提供半年的技术支持），Java 11不仅提供了长期支持服务，还将作为Java平台的参考实现，并技术支持到2023年9月。</p>
<span id="more"></span>
<h1 id="下载地址"><a href="#下载地址" class="headerlink" title="下载地址"></a>下载地址</h1><p><a href="https://www.oracle.com/technetwork/java/javase/downloads/jdk11-downloads-5066655.html">https://www.oracle.com/technetwork/java/javase/downloads/jdk11-downloads-5066655.html</a> Oracle的商业许可<br><a href="http://jdk.java.net/11">http://jdk.java.net/11</a> OpenJDK, GPLv2 with the Classpath Exception</p>
<h1 id="License"><a href="#License" class="headerlink" title="License"></a>License</h1><p>在Oracle JDK11的下载页面，有明显的提示信息，指出了Oracle JDK11的<a href="https://www.oracle.com/technetwork/java/javase/terms/license/javase-license.html">许可证</a>情况，需要注意的是</p>
<blockquote>
<blockquote>
<p>You may not:<br>  use the Programs for any data processing or any commercial, production, or internal business purposes other than developing, testing, prototyping, and demonstrating your Application;</p>
</blockquote>
</blockquote>
<p>不允许进行数据处理、商用或在产线使用。只可以用于开发、测试、原型、和应用的演示用途。Oracle JDK已经是商业版本，不是随意免费使用的，若要用在产线环境，需要取得相应授权。</p>
<p>OpenJDK版本应该是基于GPLv2许可的，也是许多Linux发行版默认使用的，看来以后要拥抱OpenJDK了。</p>
<h1 id="技术文档"><a href="#技术文档" class="headerlink" title="技术文档"></a>技术文档</h1><p><a href="https://docs.oracle.com/en/java/javase/11/">https://docs.oracle.com/en/java/javase/11/</a></p>
<h1 id="版本支持情况"><a href="#版本支持情况" class="headerlink" title="版本支持情况"></a>版本支持情况</h1><p>Oracle Java SE的支持路线图，感兴趣的同学可以在<a href="https://www.oracle.com/technetwork/java/javase/eol-135779.html">https://www.oracle.com/technetwork/java/javase/eol-135779.html</a> 查看。<br>对于普通用户和Oracle的商业客户都有些区别，简单了解下就好。</p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>Java Unsafe的应用与发展</title>
    <url>/posts/7d6ac8a1/</url>
    <content><![CDATA[<h1 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h1><p>sun.misc.Unsafe至少从2004年Java1.4开始就存在于Java中了。<br>在Java9发布之前，有传闻说Oracle会在Java9正式发布时移除sun.misc.Unsafe，引起了激烈的争论。<br>因为有不少重要的Java开发库都在底层使用了sum.misc.Unsafe，例如Netty，Neo4J，Spring Framework，Apache Kafka，Apache Storm等。<br>新的替代API成熟之前，直接移除Unsafe是很冒险的一项做法。</p>
<p><a href="http://openjdk.java.net/jeps/260">JEP 260</a>是Java9中一项重要内容，意在封装那些JDK内部使用的API，而不再提供给外部应用使用。<br>鉴于类似Unsafe这类非常关键而广泛使用的API，目前也没有非常有效的替代方案，暂时得到了保留，因此在JDK9中，我们仍然可以使用Unsafe类，目前没有被内部封装。<br>在JDK9中jdk.internal.misc中也可以找到Unsafe类。</p>
<p>JDK9中没有被封装的关键内部类有：</p>
<ul>
<li>sun.misc.{Signal,SignalHandler}</li>
<li>sun.misc.Unsafe （许多功能可以通过variable handles实现，后面介绍）</li>
<li>sun.reflect.ReflectionFactory</li>
<li>com.sun.nio.file.{ExtendedCopyOption,ExtendedOpenOption, ExtendedWatchEventModifier,SensitivityWatchEventModifier}</li>
</ul>
<p>这些类在以后的版本中可能被移除或封装。而非关键类例如sun.misc.BASE64Encoder和sun.misc.BASE64Decoder则直接被移除了。</p>
<span id="more"></span>

<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>Unsafe类名的意思就是“不安全的”，警告开发者们一定要慎重使用该类。</p>
<p>我们知道，Java语言是不能直接访问底层硬件的，但为了解决某些问题，还不得不访问底层硬件，Java提供了JNI技术（JNI是Java Native Interface的缩写，它提供了若干的API实现了Java和其他语言的通信）使我们可以通过C、C++这类语言去访问底层硬件。</p>
<p>Unsafe类通过JNI封装了一些较为底层的方法，但就如它的类名表达的含义一样，警告使用者使用它里面的方法是不安全的、是很危险的。使用Unsafe直接操作内存，是绕过了JVM的内存分配机制的，需要自己手动分配回收内存（熟悉C语言的同学一定很熟悉），以及内存屏障（store load barrier）和CAS这些操作，都是非常危险的操作。所以默认情况下，Unsafe只提供给可信任代码（被BootstrapClassLoader加载的类，也就是说只能被rt.jar包里面的类）使用。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><p>开发者自己编写的类是由AppClassLoader加载的，如果尝试调用Unsafe.getUnsafe()来获得Unsafe的实例的话，你会遇到一个SecurityException的异常，因为前面提到，只有可信任代码（例如JDK中的Atomic相关类）才能这样直接获取Unsafe实例。<br>JDK8之前只能通过反射获取实例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Field f = Unsafe.class.getDeclaredField(&quot;theUnsafe&quot;);</span><br><span class="line">f.setAccessible(true);</span><br><span class="line">Unsafe unsafe = (Unsafe) f.get(null);</span><br></pre></td></tr></table></figure>

<p>JDK9中其实已经没有了上述限制，参考Unsafe源码对比。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package jdk.internal.misc;</span><br><span class="line"></span><br><span class="line">import jdk.internal.HotSpotIntrinsicCandidate;</span><br><span class="line">import jdk.internal.vm.annotation.ForceInline;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.Field;</span><br><span class="line">import java.security.ProtectionDomain;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> */</span><br><span class="line">public final class Unsafe &#123;</span><br><span class="line"></span><br><span class="line">    private static native void registerNatives();</span><br><span class="line">    static &#123;</span><br><span class="line">        registerNatives();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private Unsafe() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    private static final Unsafe theUnsafe = new Unsafe();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Provides the caller with the capability of performing unsafe</span><br><span class="line">     * operations.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;The returned &#123;@code Unsafe&#125; object should be carefully guarded</span><br><span class="line">     * by the caller, since it can be used to read and write data at arbitrary</span><br><span class="line">     * memory addresses.  It must never be passed to untrusted code.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;Most methods in this class are very low-level, and correspond to a</span><br><span class="line">     * small number of hardware instructions (on typical machines).  Compilers</span><br><span class="line">     * are encouraged to optimize these methods accordingly.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;Here is a suggested idiom for using unsafe operations:</span><br><span class="line">     *</span><br><span class="line">     * &lt;pre&gt; &#123;@code</span><br><span class="line">     * class MyTrustedClass &#123;</span><br><span class="line">     *   private static final Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line">     *   ...</span><br><span class="line">     *   private long myCountAddress = ...;</span><br><span class="line">     *   public int getCount() &#123; return unsafe.getByte(myCountAddress); &#125;</span><br><span class="line">     * &#125;&#125;&lt;/pre&gt;</span><br><span class="line">     *</span><br><span class="line">     * (It may assist compilers to make the local variable &#123;@code final&#125;.)</span><br><span class="line">     */</span><br><span class="line">    public static Unsafe getUnsafe() &#123;</span><br><span class="line">        return theUnsafe;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>JDK1.9之前的sun.misc.Unsafe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">package sun.misc;</span><br><span class="line"></span><br><span class="line">import jdk.internal.vm.annotation.ForceInline;</span><br><span class="line">import jdk.internal.misc.VM;</span><br><span class="line">import jdk.internal.ref.Cleaner;</span><br><span class="line">import jdk.internal.reflect.CallerSensitive;</span><br><span class="line">import jdk.internal.reflect.Reflection;</span><br><span class="line">import sun.nio.ch.DirectBuffer;</span><br><span class="line"></span><br><span class="line">import java.lang.reflect.Field;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">public final class Unsafe &#123;</span><br><span class="line"></span><br><span class="line">    static &#123;</span><br><span class="line">        Reflection.registerMethodsToFilter(Unsafe.class, &quot;getUnsafe&quot;);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    private Unsafe() &#123;&#125;</span><br><span class="line"></span><br><span class="line">    private static final Unsafe theUnsafe = new Unsafe();</span><br><span class="line">    private static final jdk.internal.misc.Unsafe theInternalUnsafe = jdk.internal.misc.Unsafe.getUnsafe();</span><br><span class="line"></span><br><span class="line">    /**</span><br><span class="line">     * Provides the caller with the capability of performing unsafe</span><br><span class="line">     * operations.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;The returned &#123;@code Unsafe&#125; object should be carefully guarded</span><br><span class="line">     * by the caller, since it can be used to read and write data at arbitrary</span><br><span class="line">     * memory addresses.  It must never be passed to untrusted code.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;Most methods in this class are very low-level, and correspond to a</span><br><span class="line">     * small number of hardware instructions (on typical machines).  Compilers</span><br><span class="line">     * are encouraged to optimize these methods accordingly.</span><br><span class="line">     *</span><br><span class="line">     * &lt;p&gt;Here is a suggested idiom for using unsafe operations:</span><br><span class="line">     *</span><br><span class="line">     * &lt;pre&gt; &#123;@code</span><br><span class="line">     * class MyTrustedClass &#123;</span><br><span class="line">     *   private static final Unsafe unsafe = Unsafe.getUnsafe();</span><br><span class="line">     *   ...</span><br><span class="line">     *   private long myCountAddress = ...;</span><br><span class="line">     *   public int getCount() &#123; return unsafe.getByte(myCountAddress); &#125;</span><br><span class="line">     * &#125;&#125;&lt;/pre&gt;</span><br><span class="line">     *</span><br><span class="line">     * (It may assist compilers to make the local variable &#123;@code final&#125;.)</span><br><span class="line">     *</span><br><span class="line">     * @throws  SecurityException if the class loader of the caller</span><br><span class="line">     *          class is not in the system domain in which all permissions</span><br><span class="line">     *          are granted.</span><br><span class="line">     */</span><br><span class="line">    @CallerSensitive</span><br><span class="line">    public static Unsafe getUnsafe() &#123;</span><br><span class="line">        Class&lt;?&gt; caller = Reflection.getCallerClass();</span><br><span class="line">        if (!VM.isSystemDomainLoader(caller.getClassLoader()))</span><br><span class="line">            throw new SecurityException(&quot;Unsafe&quot;);</span><br><span class="line">        return theUnsafe;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h1 id="未来的替代者Variable-Handles"><a href="#未来的替代者Variable-Handles" class="headerlink" title="未来的替代者Variable Handles"></a>未来的替代者Variable Handles</h1><p><a href="https://www.voxxed.com/2016/11/java-9-series-variable-handles/">https://www.voxxed.com/2016/11/java-9-series-variable-handles/</a><br>java.lang.invoke.VarHandle</p>
<h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><p><a href="https://www.jianshu.com/p/54cc20a87502">https://www.jianshu.com/p/54cc20a87502</a><br><a href="https://blog.csdn.net/luzheqi/article/details/79097682">https://blog.csdn.net/luzheqi/article/details/79097682</a><br><a href="http://ifeve.com/java-9-sun-misc-unsafe/comment-page-1/">http://ifeve.com/java-9-sun-misc-unsafe/comment-page-1/</a><br><a href="https://www.zybuluo.com/kiraSally/note/867462">https://www.zybuluo.com/kiraSally/note/867462</a><br><a href="https://docs.oracle.com/javase/9/migrate/toc.htm#JSMIG-GUID-F7696E02-A1FB-4D5A-B1F2-89E7007D4096">https://docs.oracle.com/javase/9/migrate/toc.htm#JSMIG-GUID-F7696E02-A1FB-4D5A-B1F2-89E7007D4096</a></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title>CAPTCHA简介与Java实现</title>
    <url>/posts/c8f51018/</url>
    <content><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><p>CAPTCHA(Completely Automated Public Turing test to tell Computers and Humans Apart，简称CAPTCHA)，俗称验证码，是一种区分用户是计算机或人的公共全自动程序。在CAPTCHA测试中，作为服务器的计算机会自动生成一个问题由用户来解答。这个问题可以由计算机生成并评判，但是必须只有人类才能解答。由于计算机无法解答CAPTCHA的问题，所以回答出问题的用户就可以被认为是人类。</p>
<p>目前验证码被广泛应用于网站登录、注册、防刷等处，用于识别和防止自动化程序恶意获取服务和数据。</p>
<h1 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h1><p>目前大家常见的几类验证码有：</p>
<ul>
<li>标准验证码（图片），图片中一般是随机组合的字母和数字，对背景和内容进行扭曲，增加噪点和曲线，使程序难以识别</li>
<li>根据界面图形，进行鼠标、手指（移动端）交互操作（滑动拼图验证，点选验证）</li>
<li>No CAPTCHA （Google新一代reCAPTCHA，升级的风险分析技术可以智能无感知的判断人类与机器）</li>
<li>语音验证（播放一段音频给用户，用户获取信息后提交比对）</li>
<li>短信、邮箱验证<span id="more"></span></li>
</ul>
<h1 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h1><p>采集用户所处环境信息以及操作信息，提交这些信息给后端服务器进行判断。<br>采集的信息多有：</p>
<ul>
<li>插件</li>
<li>User-agent</li>
<li>屏幕分辨率</li>
<li>在captcha的iframe中进行鼠标、键盘、触摸操作的次数和记录</li>
<li>渲染canvas图像</li>
<li>Cookies</li>
<li>用户输入内容</li>
</ul>
<p>服务端利用的技术，目前高端的验证码服务，大多会引入海量样本数据，引入深度学习来识别机器与人的行为模式。</p>
<p>Google的reCAPTCHA首先检测客户端环境，判断使用者是否处于人类的操作环境中。如果检测结果在容错范围内则直接通过测试，否则弹出验证码进行二次认证。</p>
<p>滑动验证的核心并不是简单的拼接成功就可以过，也不是简单的算一下偏移量就能破解。<br>新的滑块验证码方案，验证码后台针对用户产生的行为轨迹数据进行机器学习建模，结合访问频率、地理位置、历史记录等多个维度信息，快速、准确的返回人机判定结果。</p>
<p>滑动拼图验证码、图中点选验证码、智能无感知等，其背后的原理除了对滑块起始位置的认知、图中文字及其顺序的认知外，实际还会基于在页面上的操作行为、操作轨迹，以及当前设备的指纹、所运行的环境等维度进行大数据分析，并利用有监督和无监督的机器学习手段，不断升级和优化模型，不断提高破解的成本，保证人机识别的效果。</p>
<h1 id="验证码服务平台"><a href="#验证码服务平台" class="headerlink" title="验证码服务平台"></a>验证码服务平台</h1><p>极验验证 <a href="http://www.geetest.com/type/">http://www.geetest.com/type/</a><br>网易云 易盾 <a href="http://dun.163.com/trial/sense">http://dun.163.com/trial/sense</a><br>腾讯验证码 <a href="http://open.captcha.qq.com/cap_web/experience-slidepass.html">http://open.captcha.qq.com/cap_web/experience-slidepass.html</a><br>Google reCAPTCHA <a href="https://www.google.com/recaptcha/intro/v3beta.html#">https://www.google.com/recaptcha/intro/v3beta.html#</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>develop</tag>
        <tag>Java</tag>
        <tag>CAPTCHA</tag>
      </tags>
  </entry>
  <entry>
    <title>docker attach的使用与正确退出</title>
    <url>/posts/7d17a93a/</url>
    <content><![CDATA[<h1 id="Sample-Dockerfile"><a href="#Sample-Dockerfile" class="headerlink" title="Sample Dockerfile"></a>Sample Dockerfile</h1><p>后面的讲解，以该Dockerfile构建的镜像为例说明。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FROM openjdk:8-jre-alpine</span><br><span class="line"></span><br><span class="line">MAINTAINER leimingshan</span><br><span class="line"></span><br><span class="line">ADD xxl-sso-server-0.1.1-SNAPSHOT.jar app.jar</span><br><span class="line">EXPOSE 8080</span><br><span class="line">ENTRYPOINT [&quot;java&quot;,&quot;-jar&quot;,&quot;/app.jar&quot;]</span><br></pre></td></tr></table></figure>

<p>xxl-sso-server-0.1.1-SNAPSHOT.jar是Spring Boot打包生成的可执行jar，内嵌tomcat容器，直接使用java -jar启动内嵌<br>的tomcat容器并监听8080端口，这里是最简单的一种制作Spring Boot程序镜像的方法，java -jar就是容器内的主进程，如果该<br>进程终止，容器也就相应退出。</p>
<p>另外一种常见的镜像制作方法，就是加入supervisor来管理进程，稍微重一些，适合管理容器内的多个进程，此时，java等进程是supervisord的子进程，Dockerfile中的命令也要变成</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ENTRYPOINT [&quot;/usr/bin/supervisord&quot;, &quot;-n&quot;, &quot;-c&quot;, &quot;/etc/supervisord.conf&quot;] </span><br></pre></td></tr></table></figure>
<p>supervisord也是容器内的进程命令，只要supervisord不退出，容器就不会退出。</p>
<p>Spring Boot相关的内容大家可以自行学习下，这里就不详述了。</p>
<h1 id="Detached-vs-foreground"><a href="#Detached-vs-foreground" class="headerlink" title="Detached vs foreground"></a>Detached vs foreground</h1><p>Docker run命令运行一个容器的时候，有一个-d选项</p>
<blockquote>
<blockquote>
<p>-d=false: Detached mode: Run container in the background, print new container id</p>
</blockquote>
</blockquote>
<p>detached的意思是让容器在后台运行，同时与你当前终端的STDIN，STDOUT，STDERR分离，然后告诉你一个容器id。<br>执行该命令之后，我们只会看到一个容器id。</p>
<p>默认不指定-d选项的时候，即-d=false，容器在前台运行，此时容器<br>处于attached状态，或者说是foreground前台模式，容器内进程（一般是ENTRYPOINT指定的运行命令）的STDIN，STDOUT，STDERR<br>会与你当前的命令行终端连接，你就可以直接看到容器内进程执行时候的输出，而你的输入也会重定向到容器内进程。以示例镜像运行产生的容器来说，你的所有输入输出都是和java -jar进程关联的。</p>
<p>参考：<a href="https://docs.docker.com/engine/reference/run/#detached-vs-foreground">https://docs.docker.com/engine/reference/run/#detached-vs-foreground</a></p>
<span id="more"></span>

<h1 id="docker-attach-command"><a href="#docker-attach-command" class="headerlink" title="docker attach command"></a>docker attach command</h1><p>attach命令可以让你attach到一个处于detached状态的容器。<br>以示例来说，我们会重新连接到java -jar进程的输入输出，看到该进程打印到STDOUT和STDERR的内容，如果此时，你属于了CTRL-c，也就是SIGKILL信号会发送给容器，java进程退出，容器也相应退出。</p>
<p>此处往往让大家感到困惑，我也遇到了这个问题。大多数情况下，我们按CTRL-c，是想结束docker attach这个进程，并不是想结束我们正在运行的attach到的这个容器啊。我们还是想让容器继续运行的呀。</p>
<p>官方文档说，CTRL-p CTRL-q 按键序列可以实现这个功能啊，其实就是同时按CTRL+p+q，但我发现没用啊。<br>此时我们想detach容器，使容器重新回到detached状态，我这边却无法实现。</p>
<p>重点来了：<br><a href="https://stackoverflow.com/questions/20145717/how-to-detach-from-a-docker-container">https://stackoverflow.com/questions/20145717/how-to-detach-from-a-docker-container</a></p>
<p>docker run -t -i → can be detached with ^P^Q and reattached with docker attach<br>docker run -i → cannot be detached with ^P^Q; will disrupt stdin<br>docker run → cannot be detached with ^P^Q; can SIGKILL client; can reattach with docker attach</p>
<p>参考：<a href="https://docs.docker.com/engine/reference/commandline/attach/">https://docs.docker.com/engine/reference/commandline/attach/</a></p>
<p>这里就很明显的，只有在run的时候用了-it，才可以用CTRL-p CTRL-q的按键序列进行detach。</p>
<p>原因是什么呢，这里就涉及到tty和docker tty的许多知识了，后面的文章再详细解释吧。</p>
<h1 id="docker-logs"><a href="#docker-logs" class="headerlink" title="docker logs"></a>docker logs</h1><p>想看到容器的STDOUT和STDERR，并不需要attach到容器上，docker logs命令完全可以满足需求。</p>
<p>参考：<a href="https://docs.docker.com/engine/reference/commandline/logs/">https://docs.docker.com/engine/reference/commandline/logs/</a></p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title>JavaScript RSA encrypt 公钥加密</title>
    <url>/posts/725aae6c/</url>
    <content><![CDATA[<p>在前端与后端交互的过程中，很可能会遇到使用RSA公钥加密，然后用私钥解密的情况，<br>RSA的私钥签名，公钥验签同样也很常用，这里简单介绍一下 JavaScript 语言RSA算法的一些解决方案。</p>
<h1 id="NodeJs环境"><a href="#NodeJs环境" class="headerlink" title="NodeJs环境"></a>NodeJs环境</h1><p>可以直接引入NodeJs自带的crypto模块，基于RSA/ECB/PKCS1Padding加密，用法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">const crypto = require(&#x27;crypto&#x27;);</span><br><span class="line">private RSAEncrypt(rsakey:string, text:string)&#123;</span><br><span class="line">    let encrypted = crypto.publicEncrypt(&#123;key:rsakey,</span><br><span class="line">        padding:crypto.constants.RSA_PKCS1_PADDING&#125;,new Buffer(text)).toString(&#x27;base64&#x27;);</span><br><span class="line">    return encrypted;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中rsakey为pem格式的公钥，可以从文件读取，或者指定字符串，字符串格式如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rsakey=&#x27;-----BEGIN PUBLIC KEY-----\nMIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCm5IN1uRvak0Kod3YviD/b67dj\nzP/ubU+8RgbCnm1HUVYBAVGnvg5epMfGunXKFXSb1ehOvQ2K+fEJLa+pKy2uLZLd\n/6gbUGJn+q8wGiFKfu0U0H3E+2yH6eFX+IPXx5OJNwUE6yqKR6hOBz5qR/AtVRfM\n6aAcDLIR7wE06SnHVQIDAQAB\n-----END PUBLIC KEY-----\n&#x27;</span><br></pre></td></tr></table></figure>

<p>text就是准备加密的字符串了，直接调用该方法就可以完成加密过程。</p>
<p>参考：<a href="https://nodejs.org/docs/latest-v8.x/api/crypto.html#crypto_crypto_publicencrypt_key_buffer">https://nodejs.org/docs/latest-v8.x/api/crypto.html#crypto_crypto_publicencrypt_key_buffer</a></p>
<h1 id="JavaScript-native-or-a-web-browser"><a href="#JavaScript-native-or-a-web-browser" class="headerlink" title="JavaScript native or a web browser"></a>JavaScript native or a web browser</h1><p>如果是单纯的浏览器环境，推荐<a href="https://github.com/digitalbazaar/forge">forge.js</a>。<br>代码示例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!doctype html&gt;</span><br><span class="line">&lt;html&gt;</span><br><span class="line">  &lt;head&gt;</span><br><span class="line">    &lt;title&gt;JavaScript RSA Encryption&lt;/title&gt;</span><br><span class="line">    &lt;script src=&quot;http://code.jquery.com/jquery-1.8.3.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/node-forge@0.7.0/dist/forge.min.js&quot;&gt;&lt;/script&gt;</span><br><span class="line">    &lt;script type=&quot;text/javascript&quot;&gt;</span><br><span class="line"></span><br><span class="line">      // Call this code when the page is done loading.</span><br><span class="line">      $(function() &#123;</span><br><span class="line"></span><br><span class="line">        // Run a quick encryption/decryption when they click.</span><br><span class="line">        $(&#x27;#testme&#x27;).click(function() &#123;</span><br><span class="line"></span><br><span class="line">          var publicKey = forge.pki.publicKeyFromPem($(&#x27;#pubkey&#x27;).val());</span><br><span class="line"></span><br><span class="line">          // convert string to UTF-8 encoded bytes</span><br><span class="line">          var buffer = forge.util.createBuffer($(&#x27;#input&#x27;).val());</span><br><span class="line">          var bytes = buffer.getBytes();</span><br><span class="line"></span><br><span class="line">          // encrypt data with a public key using RSAES PKCS#1 v1.5</span><br><span class="line">          var encrypted = publicKey.encrypt(bytes, &#x27;RSAES-PKCS1-V1_5&#x27;);</span><br><span class="line"></span><br><span class="line">          // base64-encode encrypted data to send to server</span><br><span class="line">          var b64Encoded = forge.util.encode64(encrypted);</span><br><span class="line">          console.log(b64Encoded);</span><br><span class="line">          alert(b64Encoded);</span><br><span class="line">        &#125;);</span><br><span class="line">      &#125;);</span><br><span class="line">    &lt;/script&gt;</span><br><span class="line">  &lt;/head&gt;</span><br><span class="line">  &lt;body&gt;</span><br><span class="line">    &lt;label for=&quot;pubkey&quot;&gt;Public Key&lt;/label&gt;&lt;br/&gt;</span><br><span class="line">    &lt;textarea id=&quot;pubkey&quot; rows=&quot;15&quot; cols=&quot;65&quot;&gt;-----BEGIN PUBLIC KEY-----</span><br><span class="line">MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQDY08fkt9d32KHV1JapaZGtk+fL</span><br><span class="line">a7wvxMAdZ0oENhx6HgBisSlDwCgBfRtN5l2iOjKm+eByp7Od24JqIOwgDF6FZ/ol</span><br><span class="line">CQbnXjzPhG0EOeLnu3AXntzhu9A0yS7b3p+pxGR7EvhIz1xkOS4bNABsAgF7Y5Zu</span><br><span class="line">B1RpsOZZdxNHGeStBwIDAQAB</span><br><span class="line">-----END PUBLIC KEY-----&lt;/textarea&gt;&lt;br/&gt;</span><br><span class="line">    &lt;label for=&quot;input&quot;&gt;Text to encrypt:&lt;/label&gt;&lt;br/&gt;</span><br><span class="line">    &lt;textarea id=&quot;input&quot; name=&quot;input&quot; type=&quot;text&quot; rows=4 cols=70&gt;Hello World!&lt;/textarea&gt;&lt;br/&gt;</span><br><span class="line">    &lt;input id=&quot;testme&quot; type=&quot;button&quot; value=&quot;RSA Encrypt&quot; /&gt;&lt;br/&gt;</span><br><span class="line">  &lt;/body&gt;</span><br><span class="line">&lt;/html&gt;</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://github.com/digitalbazaar/forge">https://github.com/digitalbazaar/forge</a></li>
<li><a href="https://github.com/digitalbazaar/forge/issues/407">https://github.com/digitalbazaar/forge/issues/407</a></li>
</ul>
<span id="more"></span>

<h1 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h1><p>最后以我最熟悉的JAVA举例，直接使用java.security的几个相关类即可，列举几个关键的方法吧。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">public static final String CIPHER_TRANSFORMATION = &quot;RSA/ECB/PKCS1Padding&quot;;</span><br><span class="line">public static final String CIPHER_ALGORITHM = &quot;RSA&quot;;</span><br><span class="line"></span><br><span class="line">Cipher cipher = Cipher.getInstance(CIPHER_TRANSFORMATION);</span><br><span class="line">cipher.init(Cipher.ENCRYPT_MODE, getRSAPublicKeyFromStr(publicKeyStr));</span><br><span class="line">byte[] encryptedData = cipher.doFinal(data);</span><br><span class="line"></span><br><span class="line">String encryptedStr = Base64.getEncoder().encodeToString(encryptedData);</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JavaScript</tag>
        <tag>NodeJs</tag>
      </tags>
  </entry>
  <entry>
    <title>NodeJS - How to update packages by npm</title>
    <url>/posts/595239dd/</url>
    <content><![CDATA[<h1 id="NVM安装新版本node之后的-global-packages-迁移"><a href="#NVM安装新版本node之后的-global-packages-迁移" class="headerlink" title="NVM安装新版本node之后的 global packages 迁移"></a>NVM安装新版本node之后的 global packages 迁移</h1><p>NVM安装新版本node之后，全局的package需要迁移，注意使用以下命令，这样就不用手动一个个安装global package了。<br>例如我今天安装了v8.12.0的node，之前的版本是v8.11.3，那么执行以下命令就可以了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nvm install v8.12.0</span><br><span class="line">nvm reinstall-packages v8.11.3  # 把在v8.11.3版本node下安装的全部global package安装到新的node下面</span><br><span class="line">nvm uninstall v8.11.3</span><br><span class="line">nvm install-latest-npm          # 顺便更新一下npm</span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h1 id="更新-global-packages"><a href="#更新-global-packages" class="headerlink" title="更新 global packages"></a>更新 global packages</h1><p>npm update -g</p>
<p>参考：<a href="https://docs.npmjs.com/getting-started/updating-global-packages">https://docs.npmjs.com/getting-started/updating-global-packages</a></p>
<h1 id="更新-local-packages"><a href="#更新-local-packages" class="headerlink" title="更新 local packages"></a>更新 local packages</h1><p>npm outdated 会列出所有可更新的 node_modules。<br>npm update 更新命令，只能按照package.js中标注的版本号，进行更新，所以每次都要改下package.js中的版本号为最新才能够更新，太麻烦。<br>那还有没有更好的办法呢，当然有，就是借助升级插件npm-check-updates</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g npm-check-updates</span><br><span class="line">ncu     # 查看全部需要更新的包和最新版本</span><br><span class="line">ncu -a  # 更新全部依赖到最新版本，并覆盖package.js</span><br></pre></td></tr></table></figure>

<p>参考：</p>
<ul>
<li><a href="https://docs.npmjs.com/getting-started/updating-local-packages">https://docs.npmjs.com/getting-started/updating-local-packages</a></li>
<li><a href="https://www.npmjs.com/package/npm-check-updates">https://www.npmjs.com/package/npm-check-updates</a></li>
</ul>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>NodeJs</tag>
      </tags>
  </entry>
  <entry>
    <title>Redis Lua script</title>
    <url>/posts/5ba98ff9/</url>
    <content><![CDATA[<h1 id="Redis-Lua脚本的几种应用场景"><a href="#Redis-Lua脚本的几种应用场景" class="headerlink" title="Redis Lua脚本的几种应用场景"></a>Redis Lua脚本的几种应用场景</h1><h2 id="批量删除符合某种pattern的keys"><a href="#批量删除符合某种pattern的keys" class="headerlink" title="批量删除符合某种pattern的keys"></a>批量删除符合某种pattern的keys</h2><p>bin/redis-cli eval “return redis.call(“del”,unpack(redis.call(“keys”,ARGV[1])))” 0 “HelloWorld*”<br>该命令会删除所有以HelloWorld开头的keys。</p>
<h2 id="迁移db-index的lua脚本"><a href="#迁移db-index的lua脚本" class="headerlink" title="迁移db index的lua脚本"></a>迁移db index的lua脚本</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">local result=&#123;&#125;;</span><br><span class="line"></span><br><span class="line">local keys =redis.call(&quot;keys&quot;,&quot;*&quot;);</span><br><span class="line"></span><br><span class="line">for i = 1, #keys do</span><br><span class="line">  local val= redis.call(&quot;move&quot;, keys[i], 0);</span><br><span class="line">end</span><br><span class="line">return  result;</span><br></pre></td></tr></table></figure>

<p>以上也是很常见的一种脚本范式，先根据需要查询获取到所有的key，再遍历这些key进行想要的操作，例如move, del, rename等等。</p>
]]></content>
      <categories>
        <category>开发</category>
      </categories>
      <tags>
        <tag>NoSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo Basic Usage</title>
    <url>/posts/f49afeaf/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<span id="more"></span>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>Linux新手非常有用的20个命令</title>
    <url>/posts/4f41333e/</url>
    <content><![CDATA[<p>原文出处： <a href="http://www.tecmint.com/useful-linux-commands-for-newbies/">Tecmit</a>   译文出处： <a href="http://www.oschina.net/translate/useful-linux-commands-for-newbies">oschina</a></p>
<div id="ad1"></div>
你打算从Windows换到Linux上来，还是你刚好换到Linux上来？哎哟！！！我说什么呢，是什么原因你就出现我的世界里了。从我以往的经 验来说，当我刚使用Linux，命令，终端啊什么的，吓了我一跳。我担心该记住多少命令，来帮助我完成所有任务。毫无疑问，在线文档，书籍，man pages以及社区帮了我一个大忙，但是我还是坚信有那么一篇文章记录了如何简单学习和理解命令的秘籍。这激发了我掌握Linux和使它容易使用的积极 性。本文就是通往那里的阶梯。

<h1 id="1-ls命令"><a href="#1-ls命令" class="headerlink" title="1. ls命令"></a>1. ls命令</h1><p>ls命令是列出目录内容(List Directory Contents)的意思。运行它就是列出文件夹里的内容，可能是文件也可能是文件夹。</p>
<pre class="lang:default decode:true">root@tecmint:~# ls

Android-Games                     Music
Pictures                          Public
Desktop                           Tecmint.com
Documents                         TecMint-Sync
Downloads                         Templates</pre>
<p>“ls -l”命令已详情模式(long listing fashion)列出文件夹的内容。</p>
<pre class="lang:default decode:true ">root@tecmint:~# ls -l

total 40588
drwxrwxr-x 2 ravisaive ravisaive     4096 May  8 01:06 Android Games
drwxr-xr-x 2 ravisaive ravisaive     4096 May 15 10:50 Desktop
drwxr-xr-x 2 ravisaive ravisaive     4096 May 16 16:45 Documents
drwxr-xr-x 6 ravisaive ravisaive     4096 May 16 14:34 Downloads
drwxr-xr-x 2 ravisaive ravisaive     4096 Apr 30 20:50 Music
drwxr-xr-x 2 ravisaive ravisaive     4096 May  9 17:54 Pictures
drwxrwxr-x 5 ravisaive ravisaive     4096 May  3 18:44 Tecmint.com
drwxr-xr-x 2 ravisaive ravisaive     4096 Apr 30 20:50 Templates</pre>
<p>&nbsp;</p>
<p>“ls -a”命令会列出文件夹里的所有内容，包括以”.”开头的隐藏文件。</p>
<p>注意：在Linux中，文件以“.”开头的就是隐藏文件，并且每个文件，文件夹，设备或者命令都是以文件对待。ls -l 命令输出：</p>
<ol>
<li> d (代表了是目录).</li>
<li> rwxr-xr-x 是文件或者目录对所属用户，同一组用户和其它用户的权限。</li>
<li> 上面例子中第一个ravisaive 代表了文件文件属于用户ravisaive</li>
<li> 上面例子中的第二个ravisaive代表了文件文件属于用户组ravisaive</li>
<li> 4096 代表了文件大小为4096字节.</li>
<li> May 8 01:06 代表了文件最后一次修改的日期和时间.</li>
<li> 最后面的就是文件/文件夹的名字<br>更多”ls”例子请查看 <a href="http://www.tecmint.com/15-basic-ls-command-examples-in-linux/">15 linux中ls命令实例</a></li>
</ol>
<span id="more"></span>

<h1 id="2-lsblk命令"><a href="#2-lsblk命令" class="headerlink" title="2. lsblk命令"></a>2. lsblk命令</h1><p>“lsblk”就是列出块设备。除了RAM外，以标准的树状输出格式，整齐地显示块设备。</p>
<pre class="lang:default decode:true ">root@tecmint:~# lsblk

NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda      8:0    0 232.9G  0 disk
├─sda1   8:1    0  46.6G  0 part /
├─sda2   8:2    0     1K  0 part
├─sda5   8:5    0   190M  0 part /boot
├─sda6   8:6    0   3.7G  0 part [SWAP]
├─sda7   8:7    0  93.1G  0 part /data
└─sda8   8:8    0  89.2G  0 part /personal
sr0     11:0    1  1024M  0 rom</pre>
<p>“lsblk -l”命令以列表格式显示块设备(而不是树状格式)。</p>
<pre class="lang:default decode:true ">root@tecmint:~# lsblk -l

NAME MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT
sda    8:0    0 232.9G  0 disk
sda1   8:1    0  46.6G  0 part /
sda2   8:2    0     1K  0 part
sda5   8:5    0   190M  0 part /boot
sda6   8:6    0   3.7G  0 part [SWAP]
sda7   8:7    0  93.1G  0 part /data
sda8   8:8    0  89.2G  0 part /personal
sr0   11:0    1  1024M  0 rom</pre>
<p>注意：lsblk是最有用和最简单的方式来了解新插入的USB设备的名字，特别是当你在终端上处理磁盘/块设备时。</p>
<h1 id="3-md5sum命令"><a href="#3-md5sum命令" class="headerlink" title="3. md5sum命令"></a>3. md5sum命令</h1><p>“md5sum”就是计算和检验MD5信息签名。md5 checksum(通常叫做哈希)使用匹配或者验证文件的文件的完整性，因为文件可能因为传输错误，磁盘错误或者无恶意的干扰等原因而发生改变。</p>
<pre class="lang:default decode:true ">root@tecmint:~# md5sum teamviewer_linux.deb

47790ed345a7b7970fc1f2ac50c97002  teamviewer_linux.deb</pre>
<p>注意：用户可以使用官方提供的和md5sum生成签名信息匹对以此检测文件是否改变。Md5sum没有sha1sum安全，这点我们稍后讨论。</p>
<h1 id="4-dd命令"><a href="#4-dd命令" class="headerlink" title="4. dd命令"></a>4. dd命令</h1><p>“dd”命令代表了转换和复制文件。可以用来转换和复制文件，大多数时间是用来复制iso文件(或任何其它文件)到一个usb设备(或任何其它地方)中去，所以可以用来制作USB启动器。</p>
<pre class="lang:default decode:true">root@tecmint:~# dd if=/home/user/Downloads/debian.iso of=/dev/sdb1 bs=512M; sync</pre>
<p>注意：在上面的例子中，usb设备就是sdb1（你应该使用lsblk命令验证它，否则你会重写你的磁盘或者系统），请慎重使用磁盘的名，切忌。</p>
<p>dd 命令在执行中会根据文件的大小和类型 以及 usb设备的读写速度，消耗几秒到几分钟不等。</p>
<h1 id="5-uname命令"><a href="#5-uname命令" class="headerlink" title="5. uname命令"></a>5. uname命令</h1><p>“uname”命令就是Unix Name的简写。显示机器名，操作系统和内核的详细信息。</p>
<pre class="lang:default decode:true ">root@tecmint:~# uname -a

Linux tecmint 3.8.0-19-generic #30-Ubuntu SMP Wed May 1 16:36:13 UTC 2013 i686 i686 i686 GNU/Linux</pre>
<p>注意： uname显示内核类别， uname -a显示详细信息。上面的输出详细说明了uname -a</p>
<ol>
<li> “Linux“: 机器的内核名</li>
<li> “tecmint“: 机器的分支名</li>
<li> “3.8.0-19-generic“: 内核发布版本</li>
<li> “#30-Ubuntu SMP“: 内核版本</li>
<li> “i686“: 处理器架构</li>
<li> “GNU/Linux“: 操作系统名</li>
</ol>
<h1 id="6-history命令"><a href="#6-history命令" class="headerlink" title="6. history命令"></a>6. history命令</h1><p>“history”命令就是历史记录。它显示了在终端中所执行过的所有命令的历史。</p>
<pre class="lang:default decode:true ">root@tecmint:~# history

 1  sudo add-apt-repository ppa:tualatrix/ppa
 2  sudo apt-get update
 3  sudo apt-get install ubuntu-tweak
 4  sudo add-apt-repository ppa:diesch/testing
 5  sudo apt-get update
 6  sudo apt-get install indicator-privacy
 7  sudo add-apt-repository ppa:atareao/atareao
 8  sudo apt-get update
 9  sudo apt-get install my-weather-indicator
 10 pwd
 11 cd &amp;&amp; sudo cp -r unity/6 /usr/share/unity/
 12 cd /usr/share/unity/icons/
 13 cd /usr/share/unity</pre>
<p>&nbsp;</p>
<p>注意：按住“CTRL + R”就可以搜索已经执行过的命令，它可以你写命令时自动补全。</p>
<h1 id="7-sudo命令"><a href="#7-sudo命令" class="headerlink" title="7. sudo命令"></a>7. sudo命令</h1><p>“sudo”(super user do)命令允许授权用户执行超级用户或者其它用户的命令。通过在sudoers列表的安全策略来指定。</p>
<p>root@tecmint:~# sudo add-apt-repository ppa:tualatrix/ppa</p>
<p>注意：sudo 允许用户借用超级用户的权限，然而”su”命令实际上是允许用户以超级用户登录。所以sudo比su更安全。<br>并不建议使用sudo或者su来处理日常用途，因为它可能导致严重的错误如果你意外的做错了事，这就是为什么在linux社区流行一句话：</p>
<blockquote>
<p>“To err is human, but to really foul up everything, you need root password.”<br>“人非圣贤孰能无过，但是拥有root密码就真的万劫不复了。”</p>
</blockquote>
<h3 id="8-mkdir命令"><a href="#8-mkdir命令" class="headerlink" title="8. mkdir命令"></a>8. mkdir命令</h3><p>“mkdir”(Make directory)命令在命名路径下创建新的目录。然而如果目录已经存在了，那么它就会返回一个错误信息”不能创建文件夹，文件夹已经存在了”(“cannot create folder, folder already exists”)</p>
<p><code>root@tecmint:~``# mkdir tecmint</code></p>
<p>注意：目录只能在用户拥有写权限的目录下才能创建。mkdir：不能创建目录<code>tecmint</code>，因为文件已经存在了。（上面的输出中不要被文件迷惑了，你应该记住我开头所说的-在linux中，文件，文件夹，驱动，命令，脚本都视为文件）</p>
<h1 id="9-touch-命令"><a href="#9-touch-命令" class="headerlink" title="9. touch 命令"></a>9. touch 命令</h1><p>“touch”命令代表了将文件的访问和修改时间更新为当前时间。touch命令只会在文件不存在的时候才会创建它。如果文件已经存在了，它会更新时间戳，但是并不会改变文件的内容。</p>
<p><code>root@tecmint:~``# touch tecmintfile</code></p>
<p>注意：touch 可以用来在用户拥有写权限的目录下创建不存在的文件。</p>
<h1 id="10-chmod-命令"><a href="#10-chmod-命令" class="headerlink" title="10. chmod 命令"></a>10. chmod 命令</h1><p>“chmod”命令就是改变文件的模式位。chmod会根据要求的模式来改变每个所给的文件，文件夹，脚本等等的文件模式（权限）。</p>
<p>在文件(文件夹或者其它，为了简单起见，我们就使用文件)中存在3中类型的权限</p>
<div>`Read (r)=4`</div>
<div>`Write(w)=2`</div>
<div>`Execute(x)=1
`</div>
<div></div>
<div></div>
所以如果你想给文件只读权限，就设置为’4′;只写权限，设置权限为’2′;只执行权限，设置为1; 读写权限，就是4+2 = 6, 以此类推。

<p>现在需要设置3种用户和用户组权限。第一个是拥有者，然后是用户所在的组，最后是其它用户。</p>
<p>rwxr-x–x   abc.sh</p>
<p>这里root的权限是 <strong>rwx（</strong>读写和执行权限<strong>），</strong></p>
<p>**　　**所属用户组权限是 **r-x (**只有读写权限, 没有写权限)<strong>，</strong></p>
<p>**　　**对于其它用户权限是 -<strong>x</strong>(只有只执行权限)</p>
<p>为了改变它的权限，为拥有者，用户所在组和其它用户提供读，写，执行权限。</p>
<p><code>root@tecmint:~``# chmod 777 abc.sh</code></p>
<p>三种都只有读写权限</p>
<p><code>root@tecmint:~``# chmod 666 abc.sh</code></p>
<p>拥有者用户有读写和执行权限，用户所在的组和其它用户只有可执行权限</p>
<p><code>root@tecmint:~``# chmod 711 abc.sh</code></p>
<p>注意：对于系统管理员和用户来说，这个命令是最有用的命令之一了。在多用户环境或者服务器上，对于某个用户，如果设置了文件不可访问，那么这个命令就可以解决，如果设置了错误的权限，那么也就提供了为授权的访问。</p>
<h1 id="11-chown命令"><a href="#11-chown命令" class="headerlink" title="11. chown命令"></a>11. chown命令</h1><p>“chown”命令就是改变文件拥有者和所在用户组。每个文件都属于一个用户组和一个用户。在你的目录下，使用”ls -l”,你就会看到像这样的东西。</p>
<pre class="lang:default decode:true ">root@tecmint:~# ls -l

drwxr-xr-x 3 server root 4096 May 10 11:14 Binary
drwxr-xr-x 2 server server 4096 May 13 09:42 Desktop</pre>
<p>在这里，目录Binary属于用户”server”,和用户组”root”,而目录”Desktop”属于用户“server”和用户组”server”</p>
<p>“chown”命令用来改变文件的所有权，所以仅仅用来管理和提供文件的用户和用户组授权。</p>
<pre class="lang:default decode:true ">root@tecmint:~# chown server:server Binary

drwxr-xr-x 3 server server 4096 May 10 11:14 Binary
drwxr-xr-x 2 server server 4096 May 13 09:42 Desktop</pre>
<p>注意：“chown”所给的文件改变用户和组的所有权到新的拥有者或者已经存在的用户或者用户组。</p>
<h1 id="12-apt命令"><a href="#12-apt命令" class="headerlink" title="12. apt命令"></a>12. apt命令</h1><p>Debian系列以“apt”命令为基础，“apt”代表了Advanced Package Tool。APT是一个为Debian系列系统（Ubuntu，Kubuntu等等）开发的高级包管理器，在Gnu/Linux系统上，它会为包自动地， 智能地搜索，安装，升级以及解决依赖。</p>
<div></div>
<div></div>
<div></div>
注意：上面的命令会导致系统整体的改变，所以需要root密码（查看提示符为”#”，而不是“$”）.和yum命令相比，Apt更高级和智能。

<p>见名知义，apt-cache用来搜索包中是否包含子包mplayer, apt-get用来安装，升级所有的已安装的包到最新版。</p>
<p>关于apt-get 和 apt-cache命令更多信息，请查看 <a href="http://www.tecmint.com/useful-basic-commands-of-apt-get-and-apt-cache-for-package-management/">25 APT-GET和APT-CACHE命令</a></p>
<h1 id="13-tar命令"><a href="#13-tar命令" class="headerlink" title="13. tar命令"></a>13. tar命令</h1><p>“<strong>tar</strong>”命令是磁带归档(Tape Archive)，对创建一些文件的的归档和它们的解压很有用。</p>
<p><code>root@tecmint:~# tar -zxvf abc.tar.gz (记住``&#39;z&#39;``代表了.tar.gz)</code></p>
<p><code>root@tecmint:~# tar -jxvf abc.tar.bz2 (记住``&#39;j&#39;``代表了.tar.bz2)</code></p>
<p>root@tecmint:~# tar -cvf archieve.tar.gz(.bz2) /path/to/folder/abc</p>
<div></div>
<div></div>
注意： “**tar.gz**“代表了使用gzip归档，“**bar.bz2**”使用bzip压缩的，它压缩的更好但是也更慢。

<p>了解更多”tar 命令”的例子，请查看 <a href="http://www.tecmint.com/18-tar-command-examples-in-linux/">18 Tar命名例子</a></p>
<h1 id="14-cal-命令"><a href="#14-cal-命令" class="headerlink" title="14. cal 命令"></a>14. cal 命令</h1><p>“cal”（Calender），它用来显示当前月份或者未来或者过去任何年份中的月份。</p>
<pre class="lang:default highlight:0 decode:true ">root@tecmint:~# cal

May 2013       
Su Mo Tu We Th Fr Sa 
          1  2  3  4 
 5  6  7  8  9 10 11 
12 13 14 15 16 17 18 
19 20 21 22 23 24 25 
26 27 28 29 30 31</pre>
<p>&nbsp;</p>
<p>显示已经过去的月份，1835年2月</p>
<pre class="lang:default highlight:0 decode:true ">root@tecmint:~# cal 02 1835

   February 1835
Su Mo Tu We Th Fr Sa 
 1  2  3  4  5  6  7
 8  9 10 11 12 13 14
15 16 17 18 19 20 21
22 23 24 25 26 27 28</pre>
<p>显示未来的月份，2145年7月。</p>
<pre class="lang:default highlight:0 decode:true ">root@tecmint:~# cal 07 2145

     July 2145
Su Mo Tu We Th Fr Sa 
             1  2  3
 4  5  6  7  8  9 10
11 12 13 14 15 16 17
18 19 20 21 22 23 24
25 26 27 28 29 30 31</pre>
<p>&nbsp;</p>
<p>注意： 你不需要往回调整日历50年，既不用复杂的数据计算你出生那天，也不用计算你的生日在哪天到来，[因为它的最小单位是月，而不是日]。</p>
<h1 id="15-date命令"><a href="#15-date命令" class="headerlink" title="15. date命令"></a>15. date命令</h1><p>“date”命令使用标准的输出打印当前的日期和时间，也可以深入设置。</p>
<div>`root@tecmint:~# date`</div>
<div></div>
<div>`Fri May ``17` `14``:``13``:``29` `IST ``2013`</div>
<div></div>
<div>
<div>`root@tecmint:~# date --``set``=``'14 may 2013 13:57'`</div>
<div></div>
<div>`Mon May ``13` `13``:``57``:``00` `IST ``2013
`</div>
</div>
<div></div>
<div></div>
注意：这个命令在脚本中十分有用，以及基于时间和日期的脚本更完美。而且在终端中改变日期和时间，让你更专业！！！（当然你需要root权限才能操作这个，因为它是系统整体改变）

<h1 id="16-cat命令"><a href="#16-cat命令" class="headerlink" title="16. cat命令"></a>16. cat命令</h1><p>“cat”代表了连结（Concatenation），连接两个或者更多文本文件或者以标准输出形式打印文件的内容。</p>
<p>root@tecmint:~# cat a.txt b.txt c.txt d.txt abcd.txt</p>
<pre class="lang:default highlight:0 decode:true ">root@tecmint:~# cat abcd.txt
....
contents of file abcd
...</pre>
<p>注意：“&gt;&gt;”和“&gt;”调用了追加符号。它们用来追加到文件里，而不是显示在标准输出上。“&gt;”符号会删除已存在的文件，然后创建一个新的文件。所以因为安全的原因，建议使用“&gt;&gt;”，它会写入到文件中，而不是覆盖或者删除。</p>
<p>在深入探究之前，我必须让你知道通配符(你应该知道通配符，它出现在大多数电视选秀中)。通配符是shell的特色，和任何GUI文件管理器相比， 它使命令行更强大有力！如你所看到那样，在一个图形文件管理器中，你想选择一大组文件，你通常不得不使用你的鼠标来选择它们。这可能觉得很简单，但是事实 上，这种情形很让人沮丧！</p>
<p>例如，假如你有一个有很多很多各种类型的文件和子目录的目录，然后你决定移动所有文件名中包含“Linux”字样的HTML文件到另外一个目录。如何简单的完成这个？如果目录中包含了大量的不同名的HTML文件，你的任务很巨大，而不是简单了。</p>
<p>在LInux CLI中，这个任务就很简单，就好像只移动一个HTML文件，因为有shell的通配符，才会如此简单。这些是特殊的字符，允许你选择匹配某种字符模式的 文件名。它帮助你来选择，即使是大量文件名中只有几个字符，而且在大多数情形中，它比使用鼠标选择文件更简单。</p>
<p>这里就是常用通配符列表：</p>
<div>`Wildcard Matches`</div>
<div>`   ``*            零个或者更多字符`</div>
<div>`   ``?            恰好一个字符`</div>
<div>`[abcde]             恰好列举中的一个字符`</div>
<div>` ``[a-e]          恰好在所给范围中的一个字符`</div>
<div>`[!abcde]        任何字符都不在列举中 `</div>
<div>`[!a-e]          任何字符都不在所给的范围中`</div>
<div>`{debian,linux}      恰好在所给选项中的一整个单词
`</div>
<div></div>
<div></div>
! 叫做非，带’！’的反向字符串为真

<p>更多请阅读Linux cat 命令的实例 <a href="http://www.tecmint.com/13-basic-cat-command-examples-in-linux/">13 Linux中cat命令实例</a></p>
<h1 id="17-cp-命令"><a href="#17-cp-命令" class="headerlink" title="17. cp 命令"></a>17. cp 命令</h1><p>“copy”就是复制。它会从一个地方复制一个文件到另外一个地方。</p>
<p><code>root@tecmint:~# cp /home/user/Downloads abc.tar.gz /home/user/Desktop (Return ``0</code> <code>when sucess)</code></p>
<p>注意： <strong>cp</strong>，在shell脚本中是最常用的一个命令，而且它可以使用通配符（在前面一块中有所描述），来定制所需的文件的复制。</p>
<h1 id="18-mv-命令"><a href="#18-mv-命令" class="headerlink" title="18. mv 命令"></a>18. mv 命令</h1><p>“mv”命令将一个地方的文件移动到另外一个地方去。</p>
<p><code>root@tecmint:~# mv /home/user/Downloads abc.tar.gz /home/user/Desktop (Return ``0</code> <code>when sucess)</code></p>
<p>注意：mv 命令可以使用通配符。mv需谨慎使用，因为易懂系统的或者未授权的文件不但会导致安全性问题，而且可能系统崩溃。</p>
<h1 id="19-pwd-命令"><a href="#19-pwd-命令" class="headerlink" title="19. pwd 命令"></a>19. pwd 命令</h1><p>“pwd”（print working directory），在终端中显示当前工作目录的全路径。</p>
<div>`root@tecmint:~# pwd `</div>
<div></div>
<div>`/home/user/Desktop
`</div>
<div></div>
<div></div>
注意： 这个命令并不会在脚本中经常使用，但是对于新手，当从连接到nux很久后在终端中迷失了路径，这绝对是救命稻草。

<h1 id="20-cd-命令"><a href="#20-cd-命令" class="headerlink" title="20. cd 命令"></a>20. cd 命令</h1><p>最后，经常使用的“cd”命令代表了改变目录。它在终端中改变工作目录来执行，复制，移动，读，写等等操作。</p>
<p>root@tecmint:~# cd /home/user/Desktop</p>
<p>注意： 在终端中切换目录时，cd就大显身手了。“cd ～”会改变工作目录为用户的家目录，而且当用户发现自己在终端中迷失了路径时，非常有用。“cd ..”从当前工作目录切换到(当前工作目录的)父目录。</p>
<p>这些命令肯定会让你在Linux上很舒服。但是这并不是结束。不久，我就会写一些其它的针对于中级用户的有用命令。例如，如果你熟练使用这些命令， 欢呼吧，少年，你会发现你已从小白级别提升为了中级用户了。在下篇文章，我会介绍像“kill”,”ps”,”grep”等等命令，期待吧，我不会让你失 望的。</p>
<p>// 参与翻译_(2人)_：Lesus, 赵亮-碧海情天</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title>I am back</title>
    <url>/posts/1a3b783e/</url>
    <content><![CDATA[<h1 id="我回来了"><a href="#我回来了" class="headerlink" title="我回来了"></a>我回来了</h1><p>不知不觉离开了好久呀，2年半的时间，跟我在蚂蚁工作的时间一样长，这两年经历了很多，其实有很多可以分享记录一下，所以趁现在记忆还清晰，最近会留下一些小思考，记录一下自己的成长吧。</p>
<p>分享一段罗翔老师的话，读《小王子》有感：<br>在芸芸众生之中，我们看似自己选择。但其实是被命运之手安排。<br>我们爱上了一个人，我们选择了或者说我们被选择了，在一个具体的个体身上投放我们的时间，通过各种的仪式，我驯化了她，她也驯化了我。<br>我们开始经营，在经营的过程中是会被刺伤的，是会流泪的是会痛苦的。</p>
<p>但是有一天，我们爱上了，那风吹麦浪的声音，我们看到了她的与众不同，正是因为这种美好、我们愿意为我们所驯服的对象负责，即便，让我们像小王子那样，为了找回那朵玫瑰他甚至不惜牺牲自己的生命，也许这就是爱吧。</p>
<p>爱肯定不是一个单纯的欲望的满足，因为欲望的满足，会让人觉得无限的空虚，爱一定是在一个具体的个体身上。投入你的感情，你的时间，所以感恩，我们能够与我们爱的人相遇，我们也感恩在我们爱的人的身上，我们愿意活出我们的美好。不是吗？</p>
<p>玫瑰花是我能看见的，这是一个具体，但是看不见美丽，那是抽象的，我们终究一生都是在具体的个体上，我们看见了我们看不见的美好和责任。我们把我们的责任，把我们的幸福放在具体的人身上，虽然具体的人是带刺的，具体的人并不一定有我们想象中那么美好，但是正是因为她没有我们想象中那么美好，所以我们要和她一起来吧那个看不见的圆给画好。</p>
<p>当你找到那朵玫瑰花，请注意真正的爱，是要用时间，用真心，用责任，用牺牲 去守护。</p>
]]></content>
      <categories>
        <category>我自己</category>
      </categories>
      <tags>
        <tag>我自己</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>无问西东</title>
    <url>/posts/5dc2f86c/</url>
    <content><![CDATA[<p>如果提前了解了你所面对的人生，你是否还有勇气前来？</p>
<p>如果你明知道努力无法改变任何结果，你是否还愿意去努力？</p>
<p>What’s happened’s happened. Which is an expression of faith in the mechanics of the world. It’s not an excuse to do nothing.<br>发生过的事已经发生了。这是对这个世界运作的信念，而不是袖手旁观的借口。</p>
<p>愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵，爱你所爱，行你所行，听从你心，无问西东。</p>
<p>身边的人都很好，没有人有恶意，只是很多时候，我们都处于迷茫之中，拼了命的想找到一个明确的方向，结果到处碰壁，撞的头破血流，倒不如Follow your heart，让你的内心指引你，找到那条属于你自己的道路。</p>
<p>这句话一定要送给你：爱你所爱，行你所行，听从你心，无问西东。</p>
]]></content>
      <categories>
        <category>我自己</category>
      </categories>
      <tags>
        <tag>我自己</tag>
        <tag>思考</tag>
      </tags>
  </entry>
</search>
